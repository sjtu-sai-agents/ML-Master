{
    "title": "herbarium-2020-fgvc7",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task herbarium-2020-fgvc7 --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"herbarium-2020-fgvc7\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> json\n<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> LabelEncoder\n<span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> f1_score\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn, optim\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader, WeightedRandomSampler\n<span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, models\n<span class=\"keyword\">from</span> torch.cuda.amp <span class=\"keyword\">import</span> autocast, GradScaler\n<span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm\n\n<span class=\"comment\"># Configuration</span>\nBATCH_SIZE = <span class=\"number\">128</span>\nIMG_SIZE = <span class=\"number\">224</span>\nNUM_EPOCHS = <span class=\"number\">3</span>\nNUM_WORKERS = <span class=\"number\">4</span>\n\n<span class=\"comment\"># Load training metadata</span>\n<span class=\"keyword\">with</span> open(<span class=\"string\">&quot;</span><span class=\"string\">input/nybg2020/train/metadata.json</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">as</span> f:\n    train_meta = json.load(f)\n\n<span class=\"comment\"># Create mappings and encode labels</span>\nimage_to_label = {a[<span class=\"string\">&quot;</span><span class=\"string\">image_id</span><span class=\"string\">&quot;</span>]: a[<span class=\"string\">&quot;</span><span class=\"string\">category_id</span><span class=\"string\">&quot;</span>] <span class=\"keyword\">for</span> a in train_meta[<span class=\"string\">&quot;</span><span class=\"string\">annotations</span><span class=\"string\">&quot;</span>]}\nimage_paths = [\n    os.path.join(<span class=\"string\">&quot;</span><span class=\"string\">input/nybg2020/train</span><span class=\"string\">&quot;</span>, img[<span class=\"string\">&quot;</span><span class=\"string\">file_name</span><span class=\"string\">&quot;</span>])\n    <span class=\"keyword\">for</span> img in train_meta[<span class=\"string\">&quot;</span><span class=\"string\">images</span><span class=\"string\">&quot;</span>]\n]\noriginal_labels = [image_to_label[img[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>]] <span class=\"keyword\">for</span> img in train_meta[<span class=\"string\">&quot;</span><span class=\"string\">images</span><span class=\"string\">&quot;</span>]]\n\n<span class=\"comment\"># Encode labels to contiguous integers</span>\nle = LabelEncoder()\nencoded_labels = le.fit_transform(original_labels)\nnum_classes = len(le.classes_)\n\n<span class=\"comment\"># Class-aware stratified split</span>\ndf = pd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">path</span><span class=\"string\">&quot;</span>: image_paths, <span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>: encoded_labels})\ntrain_paths, val_paths = [], []\ntrain_labels, val_labels = [], []\n\n<span class=\"keyword\">for</span> label, group in df.groupby(<span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>):\n    <span class=\"keyword\">if</span> len(group) == <span class=\"number\">1</span>:\n        train_paths.extend(group[<span class=\"string\">&quot;</span><span class=\"string\">path</span><span class=\"string\">&quot;</span>].tolist())\n        train_labels.extend(group[<span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>].tolist())\n    <span class=\"keyword\">else</span>:\n        g_train, g_val = train_test_split(\n            group, test_size=<span class=\"number\">0.2</span>, stratify=group[<span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>], random_state=<span class=\"number\">42</span>\n        )\n        train_paths.extend(g_train[<span class=\"string\">&quot;</span><span class=\"string\">path</span><span class=\"string\">&quot;</span>].tolist())\n        train_labels.extend(g_train[<span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>].tolist())\n        val_paths.extend(g_val[<span class=\"string\">&quot;</span><span class=\"string\">path</span><span class=\"string\">&quot;</span>].tolist())\n        val_labels.extend(g_val[<span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>].tolist())\n\n\n<span class=\"comment\"># Dataset class</span>\n<span class=\"keyword\">class</span> <span class=\"class\">HerbariumDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, paths, labels, transform=<span class=\"keyword\">None</span>):\n        self.paths = paths\n        self.labels = labels\n        self.transform = transform\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.paths)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        img = Image.open(self.paths[idx]).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">if</span> self.transform:\n            img = self.transform(img)\n        <span class=\"keyword\">return</span> img, self.labels[idx]\n\n\n<span class=\"comment\"># Transforms</span>\ntrain_transform = transforms.Compose(\n    [\n        transforms.RandomResizedCrop(IMG_SIZE),\n        transforms.RandomHorizontalFlip(),\n        transforms.ColorJitter(<span class=\"number\">0.2</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.2</span>),\n        transforms.ToTensor(),\n        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\nval_transform = transforms.Compose(\n    [\n        transforms.Resize(<span class=\"number\">256</span>),\n        transforms.CenterCrop(IMG_SIZE),\n        transforms.ToTensor(),\n        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\n<span class=\"comment\"># Datasets</span>\ntrain_dataset = HerbariumDataset(train_paths, train_labels, train_transform)\nval_dataset = HerbariumDataset(val_paths, val_labels, val_transform)\n\n<span class=\"comment\"># Class balancing</span>\nclass_counts = np.bincount(train_labels)\nweights = <span class=\"number\">1.0</span> / class_counts[train_labels]\nsampler = WeightedRandomSampler(weights, len(weights), replacement=<span class=\"keyword\">True</span>)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    sampler=sampler,\n    num_workers=NUM_WORKERS,\n    pin_memory=<span class=\"keyword\">True</span>,\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE * <span class=\"number\">2</span>,\n    shuffle=<span class=\"keyword\">False</span>,\n    num_workers=NUM_WORKERS,\n    pin_memory=<span class=\"keyword\">True</span>,\n)\n\n<span class=\"comment\"># Model setup</span>\nmodel = models.efficientnet_b0(pretrained=<span class=\"keyword\">True</span>)\nmodel.classifier[<span class=\"number\">1</span>] = nn.Linear(model.classifier[<span class=\"number\">1</span>].in_features, num_classes)\nmodel = model.cuda()\n\n<span class=\"comment\"># Training setup</span>\noptimizer = optim.AdamW(model.parameters(), lr=<span class=\"number\">1e-4</span>, weight_decay=<span class=\"number\">1e-4</span>)\ncriterion = nn.CrossEntropyLoss(label_smoothing=<span class=\"number\">0.1</span>)\nscaler = GradScaler()\nbest_f1 = <span class=\"number\">0</span>\n\n<span class=\"comment\"># Training loop</span>\n<span class=\"keyword\">for</span> epoch in range(NUM_EPOCHS):\n    model.train()\n    <span class=\"keyword\">for</span> images, labels in tqdm(train_loader, desc=<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>):\n        images, labels = images.cuda(), labels.cuda()\n        <span class=\"keyword\">with</span> autocast():\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n    <span class=\"comment\"># Validation</span>\n    model.eval()\n    all_preds, all_labels = [], []\n    <span class=\"keyword\">for</span> images, labels in tqdm(val_loader, desc=<span class=\"string\">&quot;</span><span class=\"string\">Validating</span><span class=\"string\">&quot;</span>):\n        images = images.cuda()\n        <span class=\"keyword\">with</span> torch.no_grad(), autocast():\n            outputs = model(images)\n        preds = outputs.argmax(<span class=\"number\">1</span>).cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(labels.numpy())\n\n    val_f1 = f1_score(all_labels, all_preds, average=<span class=\"string\">&quot;</span><span class=\"string\">macro</span><span class=\"string\">&quot;</span>)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Validation F1: </span><span class=\"string\">{</span>val_f1<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n    <span class=\"keyword\">if</span> val_f1 &gt; best_f1:\n        best_f1 = val_f1\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Load best model</span>\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>))\n\n<span class=\"comment\"># Test prediction</span>\n<span class=\"keyword\">with</span> open(<span class=\"string\">&quot;</span><span class=\"string\">input/nybg2020/test/metadata.json</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">as</span> f:\n    test_meta = json.load(f)\n\ntest_paths = [\n    os.path.join(<span class=\"string\">&quot;</span><span class=\"string\">input/nybg2020/test</span><span class=\"string\">&quot;</span>, img[<span class=\"string\">&quot;</span><span class=\"string\">file_name</span><span class=\"string\">&quot;</span>]) <span class=\"keyword\">for</span> img in test_meta[<span class=\"string\">&quot;</span><span class=\"string\">images</span><span class=\"string\">&quot;</span>]\n]\ntest_ids = [img[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>] <span class=\"keyword\">for</span> img in test_meta[<span class=\"string\">&quot;</span><span class=\"string\">images</span><span class=\"string\">&quot;</span>]]\n\ntest_dataset = HerbariumDataset(test_paths, [<span class=\"number\">0</span>] * len(test_paths), val_transform)\ntest_loader = DataLoader(\n    test_dataset, batch_size=BATCH_SIZE * <span class=\"number\">2</span>, shuffle=<span class=\"keyword\">False</span>, num_workers=NUM_WORKERS\n)\n\nmodel.eval()\nencoded_preds = []\n<span class=\"keyword\">for</span> images, _ in tqdm(test_loader, desc=<span class=\"string\">&quot;</span><span class=\"string\">Testing</span><span class=\"string\">&quot;</span>):\n    images = images.cuda()\n    <span class=\"keyword\">with</span> torch.no_grad(), autocast():\n        outputs = model(images)\n    encoded_preds.extend(outputs.argmax(<span class=\"number\">1</span>).cpu().numpy())\n\n<span class=\"comment\"># Decode predictions to original category IDs</span>\noriginal_preds = le.inverse_transform(encoded_preds)\n\n<span class=\"comment\"># Save submission</span>\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\npd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>: test_ids, <span class=\"string\">&quot;</span><span class=\"string\">Predicted</span><span class=\"string\">&quot;</span>: original_preds}).to_csv(\n    <span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>\n)\n\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Final Validation F1: </span><span class=\"string\">{</span>best_f1<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n"
}
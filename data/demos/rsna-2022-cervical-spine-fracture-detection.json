{
    "title": "rsna-2022-cervical-spine-fracture-detection",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task rsna-2022-cervical-spine-fracture-detection --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"rsna-2022-cervical-spine-fracture-detection\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> pydicom\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim\n<span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms\n<span class=\"keyword\">from</span> torchvision.models <span class=\"keyword\">import</span> efficientnet_b0\n<span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm\n\n<span class=\"comment\"># Config</span>\nIMG_SIZE = <span class=\"number\">224</span>\nN_SLICES = <span class=\"number\">32</span>\nBATCH_SIZE = <span class=\"number\">16</span>\nEPOCHS = <span class=\"number\">10</span>\nLR = <span class=\"number\">1e-4</span>\nWEIGHTS = [<span class=\"number\">1.0</span>] * <span class=\"number\">7</span> + [<span class=\"number\">2.0</span>]\nFOCAL_ALPHA = <span class=\"number\">0.25</span>\nFOCAL_GAMMA = <span class=\"number\">2.0</span>\n\n\n<span class=\"comment\"># Focal Loss with weighting</span>\n<span class=\"keyword\">class</span> <span class=\"class\">WeightedFocalLoss</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, alpha=FOCAL_ALPHA, gamma=FOCAL_GAMMA, weight=WEIGHTS):\n        super().<span class=\"function\">__init__</span>()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.weight = torch.tensor(weight)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, inputs, targets):\n        BCE_loss = F.binary_cross_entropy_with_logits(\n            inputs, targets, reduction=<span class=\"string\">&quot;</span><span class=\"string\">none</span><span class=\"string\">&quot;</span>, weight=self.weight.to(inputs.device)\n        )\n        pt = torch.exp(-BCE_loss)\n        focal_loss = self.alpha * (<span class=\"number\">1</span> - pt) ** self.gamma * BCE_loss\n        <span class=\"keyword\">return</span> focal_loss.mean()\n\n\n<span class=\"comment\"># DICOM preprocessing</span>\n<span class=\"keyword\">def</span> <span class=\"function\">load_dicom</span>(path):\n    dicom = pydicom.dcmread(path)\n    data = dicom.pixel_array.astype(np.float32)\n    <span class=\"keyword\">return</span> data * dicom.RescaleSlope + dicom.RescaleIntercept\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">apply_window</span>(img, center=<span class=\"number\">400</span>, width=<span class=\"number\">1800</span>):\n    img = np.clip(img, center - width // <span class=\"number\">2</span>, center + width // <span class=\"number\">2</span>)\n    <span class=\"keyword\">return</span> (img - (center - width // <span class=\"number\">2</span>)) / width\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">CervicalDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, root_dir, mode=<span class=\"string\">&quot;</span><span class=\"string\">train</span><span class=\"string\">&quot;</span>):\n        self.studies = df[<span class=\"string\">&quot;</span><span class=\"string\">StudyInstanceUID</span><span class=\"string\">&quot;</span>].unique()\n        self.labels = df.set_index(<span class=\"string\">&quot;</span><span class=\"string\">StudyInstanceUID</span><span class=\"string\">&quot;</span>)\n        self.root_dir = root_dir\n        self.mode = mode\n\n        <span class=\"keyword\">if</span> mode == <span class=\"string\">&quot;</span><span class=\"string\">train</span><span class=\"string\">&quot;</span>:\n            self.transform = transforms.Compose(\n                [\n                    transforms.ToTensor(),\n                    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n                    transforms.RandomAffine(degrees=<span class=\"number\">10</span>, translate=(<span class=\"number\">0.1</span>, <span class=\"number\">0.1</span>)),\n                    transforms.ColorJitter(brightness=<span class=\"number\">0.1</span>, contrast=<span class=\"number\">0.1</span>),\n                    transforms.Normalize(mean=[<span class=\"number\">0.485</span>], std=[<span class=\"number\">0.229</span>]),\n                ]\n            )\n        <span class=\"keyword\">else</span>:\n            self.transform = transforms.Compose(\n                [\n                    transforms.ToTensor(),\n                    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n                    transforms.Normalize(mean=[<span class=\"number\">0.485</span>], std=[<span class=\"number\">0.229</span>]),\n                ]\n            )\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.studies)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        study_id = self.studies[idx]\n        study_path = os.path.join(self.root_dir, study_id)\n        slices = sorted(os.listdir(study_path), key=<span class=\"keyword\">lambda</span> x: int(x.split(<span class=\"string\">&quot;</span><span class=\"string\">.</span><span class=\"string\">&quot;</span>)[<span class=\"number\">0</span>]))\n\n        <span class=\"comment\"># Select middle slices</span>\n        <span class=\"keyword\">if</span> len(slices) &gt; N_SLICES:\n            start = (len(slices) - N_SLICES) // <span class=\"number\">2</span>\n            selected_slices = slices[start : start + N_SLICES]\n        <span class=\"keyword\">else</span>:\n            selected_slices = slices\n\n        images = []\n        <span class=\"keyword\">for</span> fn in selected_slices:\n            img = load_dicom(os.path.join(study_path, fn))\n            img = apply_window(img)\n            img = self.transform(img).repeat(<span class=\"number\">3</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>)  <span class=\"comment\"># RGB</span>\n            images.append(img)\n\n        <span class=\"comment\"># Pad if needed</span>\n        <span class=\"keyword\">if</span> len(images) &lt; N_SLICES:\n            images += [torch.zeros_like(images[<span class=\"number\">0</span>])] * (N_SLICES - len(images))\n\n        stack = torch.stack(images)\n\n        <span class=\"keyword\">if</span> self.mode == <span class=\"string\">&quot;</span><span class=\"string\">train</span><span class=\"string\">&quot;</span>:\n            labels = self.labels.loc[study_id][\n                [<span class=\"string\">&quot;</span><span class=\"string\">C1</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">C2</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">C3</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">C4</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">C5</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">C6</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">C7</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">patient_overall</span><span class=\"string\">&quot;</span>]\n            ].values\n            <span class=\"keyword\">return</span> stack, torch.FloatTensor(labels)\n        <span class=\"keyword\">return</span> stack, study_id\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">SpineModel</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self):\n        super().<span class=\"function\">__init__</span>()\n        self.backbone = efficientnet_b0(pretrained=<span class=\"keyword\">True</span>)\n        self.backbone.classifier = nn.Identity()\n        self.transformer = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=<span class=\"number\">1280</span>, nhead=<span class=\"number\">8</span>), num_layers=<span class=\"number\">2</span>\n        )\n        self.heads = nn.ModuleList([nn.Linear(<span class=\"number\">1280</span>, <span class=\"number\">1</span>) <span class=\"keyword\">for</span> _ in range(<span class=\"number\">8</span>)])\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, x):\n        batch_size = x.size(<span class=\"number\">0</span>)\n        features = [self.backbone(x[:, i]) <span class=\"keyword\">for</span> i in range(N_SLICES)]\n        features = torch.stack(features)\n        features = self.transformer(features)\n        pooled = features.mean(dim=<span class=\"number\">0</span>)\n        <span class=\"keyword\">return</span> torch.cat([head(pooled) <span class=\"keyword\">for</span> head in self.heads], dim=<span class=\"number\">1</span>)\n\n\n<span class=\"comment\"># Data prep</span>\ndf = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/train.csv</span><span class=\"string\">&quot;</span>)\ntrain_ids, val_ids = train_test_split(\n    df[<span class=\"string\">&quot;</span><span class=\"string\">StudyInstanceUID</span><span class=\"string\">&quot;</span>], test_size=<span class=\"number\">0.2</span>, random_state=<span class=\"number\">42</span>\n)\ntrain_df, val_df = (\n    df[df.StudyInstanceUID.isin(train_ids)],\n    df[df.StudyInstanceUID.isin(val_ids)],\n)\n\ntrain_ds = CervicalDataset(train_df, <span class=\"string\">&quot;</span><span class=\"string\">./input/train_images</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">train</span><span class=\"string\">&quot;</span>)\nval_ds = CervicalDataset(val_df, <span class=\"string\">&quot;</span><span class=\"string\">./input/train_images</span><span class=\"string\">&quot;</span>)\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">4</span>)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, num_workers=<span class=\"number\">4</span>)\n\n<span class=\"comment\"># Model setup</span>\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\nmodel = SpineModel().to(device)\ncriterion = WeightedFocalLoss()\noptimizer = optim.Adam(model.parameters(), lr=LR)\n\n<span class=\"comment\"># Training loop</span>\nbest_val_loss = float(<span class=\"string\">&quot;</span><span class=\"string\">inf</span><span class=\"string\">&quot;</span>)\n<span class=\"keyword\">for</span> epoch in range(EPOCHS):\n    model.train()\n    train_loss = <span class=\"number\">0</span>\n    <span class=\"keyword\">for</span> inputs, labels in tqdm(train_loader, desc=<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>):\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * inputs.size(<span class=\"number\">0</span>)\n    train_loss /= len(train_ds)\n\n    model.eval()\n    val_loss = <span class=\"number\">0</span>\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            val_loss += criterion(outputs, labels).item() * inputs.size(<span class=\"number\">0</span>)\n    val_loss /= len(val_ds)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">: Train Loss </span><span class=\"string\">{</span>train_loss<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">, Val Loss </span><span class=\"string\">{</span>val_loss<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n    <span class=\"keyword\">if</span> val_loss &lt; best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">./working/best_model.pth</span><span class=\"string\">&quot;</span>)\n\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Best Validation Loss: </span><span class=\"string\">{</span>best_val_loss<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Generate submission</span>\ntest_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/test.csv</span><span class=\"string\">&quot;</span>)\ntest_studies = test_df[<span class=\"string\">&quot;</span><span class=\"string\">StudyInstanceUID</span><span class=\"string\">&quot;</span>].unique()\ntest_ds = CervicalDataset(\n    pd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">StudyInstanceUID</span><span class=\"string\">&quot;</span>: test_studies}), <span class=\"string\">&quot;</span><span class=\"string\">./input/test_images</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">test</span><span class=\"string\">&quot;</span>\n)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers=<span class=\"number\">4</span>)\n\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">./working/best_model.pth</span><span class=\"string\">&quot;</span>))\nmodel.eval()\npreds = []\nstudy_ids = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> batch, sids in tqdm(test_loader):\n        outputs = torch.sigmoid(model(batch.to(device))).cpu().numpy()\n        preds.extend(outputs)\n        study_ids.extend(sids)\n\nsubmission = []\n<span class=\"keyword\">for</span> sid, pred in zip(study_ids, preds):\n    <span class=\"keyword\">for</span> i, loc in enumerate(\n        [<span class=\"string\">&quot;</span><span class=\"string\">C1</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">C2</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">C3</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">C4</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">C5</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">C6</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">C7</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">patient_overall</span><span class=\"string\">&quot;</span>]\n    ):\n        submission.append({<span class=\"string\">&quot;</span><span class=\"string\">row_id</span><span class=\"string\">&quot;</span>: <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">{</span>sid<span class=\"string\">}</span><span class=\"string\">_</span><span class=\"string\">{</span>loc<span class=\"string\">}</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">fractured</span><span class=\"string\">&quot;</span>: pred[i]})\n\npd.DataFrame(submission).to_csv(<span class=\"string\">&quot;</span><span class=\"string\">./submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\n"
}
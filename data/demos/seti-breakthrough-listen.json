{
    "title": "seti-breakthrough-listen",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task seti-breakthrough-listen --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"seti-breakthrough-listen\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> roc_auc_score\n<span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, models\n<span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm\n\nBATCH_SIZE = <span class=\"number\">32</span>\nEPOCHS = <span class=\"number\">15</span>\nIMG_SIZE = <span class=\"number\">256</span>\nTRAIN_PATH = <span class=\"string\">&quot;</span><span class=\"string\">./input/train</span><span class=\"string\">&quot;</span>\nTEST_PATH = <span class=\"string\">&quot;</span><span class=\"string\">./input/test</span><span class=\"string\">&quot;</span>\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">ChannelAttention</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, in_channels, ratio=<span class=\"number\">8</span>):\n        super().<span class=\"function\">__init__</span>()\n        self.avg_pool = nn.AdaptiveAvgPool2d(<span class=\"number\">1</span>)\n        self.max_pool = nn.AdaptiveMaxPool2d(<span class=\"number\">1</span>)\n        self.fc = nn.Sequential(\n            nn.Linear(in_channels, in_channels // ratio),\n            nn.ReLU(),\n            nn.Linear(in_channels // ratio, in_channels),\n            nn.Sigmoid(),\n        )\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, x):\n        avg_out = self.fc(self.avg_pool(x).squeeze())\n        max_out = self.fc(self.max_pool(x).squeeze())\n        out = avg_out + max_out\n        <span class=\"keyword\">return</span> x * out.unsqueeze(-<span class=\"number\">1</span>).unsqueeze(-<span class=\"number\">1</span>)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">SETIModel</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, backbone=<span class=\"string\">&quot;</span><span class=\"string\">efficientnet_b4</span><span class=\"string\">&quot;</span>):\n        super().<span class=\"function\">__init__</span>()\n        self.backbone = models.__dict__[backbone](pretrained=<span class=\"keyword\">True</span>)\n        original_conv = self.backbone.features[<span class=\"number\">0</span>][<span class=\"number\">0</span>]\n        self.backbone.features[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = nn.Conv2d(\n            <span class=\"number\">6</span>,\n            original_conv.out_channels,\n            kernel_size=original_conv.kernel_size,\n            stride=original_conv.stride,\n            padding=original_conv.padding,\n            bias=<span class=\"keyword\">False</span>,\n        )\n        self.attention = ChannelAttention(<span class=\"number\">6</span>)\n        self.position_weights = nn.Parameter(torch.ones(<span class=\"number\">6</span>))\n        self.classifier = nn.Linear(self.backbone.classifier[<span class=\"number\">1</span>].in_features, <span class=\"number\">1</span>)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, x):\n        bs = x.size(<span class=\"number\">0</span>)\n        x = self.attention(x)\n        x = x * self.position_weights.view(<span class=\"number\">1</span>, <span class=\"number\">6</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>)\n        x = self.backbone.features(x)\n        x = F.adaptive_avg_pool2d(x, (<span class=\"number\">1</span>, <span class=\"number\">1</span>)).view(bs, -<span class=\"number\">1</span>)\n        <span class=\"keyword\">return</span> self.classifier(x)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">SETIDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, root, transform=<span class=\"keyword\">None</span>):\n        self.df = df\n        self.root = root\n        self.transform = transform\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.df)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        id = self.df.iloc[idx][<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>]\n        file = os.path.join(self.root, id[<span class=\"number\">0</span>], <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">{</span>id<span class=\"string\">}</span><span class=\"string\">.npy</span><span class=\"string\">&quot;</span>)\n        arr = np.load(file).astype(np.float32)\n        img = arr.transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)\n        img = transforms.functional.to_tensor(img)\n        <span class=\"keyword\">if</span> self.transform:\n            img = self.transform(img)\n        <span class=\"keyword\">return</span> img, self.df.iloc[idx].get(<span class=\"string\">&quot;</span><span class=\"string\">target</span><span class=\"string\">&quot;</span>, <span class=\"number\">0</span>)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">compute_stats</span>(dataset):\n    loader = DataLoader(dataset, batch_size=<span class=\"number\">256</span>, num_workers=<span class=\"number\">4</span>, shuffle=<span class=\"keyword\">False</span>)\n    mean = torch.zeros(<span class=\"number\">6</span>)\n    std = torch.zeros(<span class=\"number\">6</span>)\n    <span class=\"keyword\">for</span> images, _ in loader:\n        batch = images.size(<span class=\"number\">0</span>)\n        images = images.view(batch, <span class=\"number\">6</span>, -<span class=\"number\">1</span>)\n        mean += images.mean(<span class=\"number\">2</span>).sum(<span class=\"number\">0</span>)\n        std += images.std(<span class=\"number\">2</span>).sum(<span class=\"number\">0</span>)\n    mean /= len(dataset)\n    std /= len(dataset)\n    <span class=\"keyword\">return</span> mean.tolist(), std.tolist()\n\n\n<span class=\"comment\"># Data preparation</span>\ndf = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/train_labels.csv</span><span class=\"string\">&quot;</span>)\ntrain_df, val_df = train_test_split(df, test_size=<span class=\"number\">0.1</span>, stratify=df[<span class=\"string\">&quot;</span><span class=\"string\">target</span><span class=\"string\">&quot;</span>])\n\nstats_ds = SETIDataset(\n    train_df,\n    TRAIN_PATH,\n    transform=transforms.Compose(\n        [\n            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        ]\n    ),\n)\nmean, std = compute_stats(stats_ds)\n\ntrain_tfms = transforms.Compose(\n    [\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.Normalize(mean, std),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomApply([transforms.RandomRotation(<span class=\"number\">20</span>)], p=<span class=\"number\">0.5</span>),\n        transforms.RandomApply([transforms.GaussianBlur(<span class=\"number\">3</span>)], p=<span class=\"number\">0.3</span>),\n    ]\n)\n\nval_tfms = transforms.Compose(\n    [\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.Normalize(mean, std),\n    ]\n)\n\ntrain_ds = SETIDataset(train_df, TRAIN_PATH, train_tfms)\nval_ds = SETIDataset(val_df, TRAIN_PATH, val_tfms)\n\ntrain_loader = DataLoader(\n    train_ds,\n    batch_size=BATCH_SIZE,\n    shuffle=<span class=\"keyword\">True</span>,\n    num_workers=<span class=\"number\">4</span>,\n    pin_memory=<span class=\"keyword\">True</span>,\n    drop_last=<span class=\"keyword\">True</span>,\n)\nval_loader = DataLoader(\n    val_ds, batch_size=BATCH_SIZE * <span class=\"number\">2</span>, num_workers=<span class=\"number\">4</span>, pin_memory=<span class=\"keyword\">True</span>\n)\n\nmodel = SETIModel().to(device)\nopt = torch.optim.AdamW(model.parameters(), lr=<span class=\"number\">3e-4</span>, weight_decay=<span class=\"number\">1e-5</span>)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    opt, max_lr=<span class=\"number\">3e-4</span>, steps_per_epoch=len(train_loader), epochs=EPOCHS\n)\ncriterion = nn.BCEWithLogitsLoss()\n\nbest_auc = <span class=\"number\">0</span>\n<span class=\"keyword\">for</span> epoch in range(EPOCHS):\n    model.train()\n    <span class=\"keyword\">for</span> x, y in tqdm(train_loader, desc=<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>):\n        x, y = x.to(device), y.float().to(device)\n        opt.zero_grad()\n        loss = criterion(model(x).squeeze(), y)\n        loss.backward()\n        opt.step()\n        scheduler.step()\n\n    model.eval()\n    preds, tgts = [], []\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> x, y in val_loader:\n            x, y = x.to(device), y.cpu()\n            out = model(x).squeeze().sigmoid().cpu()\n            preds.append(out)\n            tgts.append(y)\n    auc = roc_auc_score(torch.cat(tgts), torch.cat(preds))\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Val AUC: </span><span class=\"string\">{</span>auc<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n    <span class=\"keyword\">if</span> auc &gt; best_auc:\n        best_auc = auc\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>)\n\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Best Validation AUC: </span><span class=\"string\">{</span>best_auc<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n\n<span class=\"comment\"># Inference</span>\n<span class=\"keyword\">class</span> <span class=\"class\">TestDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, root):\n        self.ids = []\n        <span class=\"keyword\">for</span> d in os.listdir(root):\n            dir_path = os.path.join(root, d)\n            <span class=\"keyword\">if</span> os.path.isdir(dir_path):\n                self.ids += [f.split(<span class=\"string\">&quot;</span><span class=\"string\">.</span><span class=\"string\">&quot;</span>)[<span class=\"number\">0</span>] <span class=\"keyword\">for</span> f in os.listdir(dir_path)]\n        self.transform = val_tfms\n        self.root = root\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.ids)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        id = self.ids[idx]\n        file = os.path.join(self.root, id[<span class=\"number\">0</span>], <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">{</span>id<span class=\"string\">}</span><span class=\"string\">.npy</span><span class=\"string\">&quot;</span>)\n        arr = np.load(file).astype(np.float32)\n        img = arr.transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)\n        img = transforms.functional.to_tensor(img)\n        <span class=\"keyword\">return</span> self.transform(img), id\n\n\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>, map_location=device))\nmodel.eval()\n\ntest_ds = TestDataset(TEST_PATH)\ntest_loader = DataLoader(test_ds, batch_size=<span class=\"number\">64</span>, num_workers=<span class=\"number\">4</span>)\n\nids, preds = [], []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> x, batch_ids in tqdm(test_loader):\n        x = x.to(device)\n        out = model(x).squeeze().sigmoid().cpu().tolist()\n        preds.extend(out)\n        ids.extend(batch_ids)\n\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">./submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\npd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>: ids, <span class=\"string\">&quot;</span><span class=\"string\">target</span><span class=\"string\">&quot;</span>: preds}).to_csv(\n    <span class=\"string\">&quot;</span><span class=\"string\">./submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>\n)\nprint(<span class=\"string\">&quot;</span><span class=\"string\">Submission created!</span><span class=\"string\">&quot;</span>)\n"
}
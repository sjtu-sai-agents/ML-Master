{
    "title": "dogs-vs-cats-redux-kernels-edition",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task dogs-vs-cats-redux-kernels-edition --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"dogs-vs-cats-redux-kernels-edition\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn\n<span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span> T\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image\n<span class=\"keyword\">import</span> os\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">import</span> timm\n<span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm\n\n<span class=\"comment\"># Configuration</span>\nBATCH_SIZE = <span class=\"number\">64</span>\nIMG_SIZE = <span class=\"number\">224</span>\nLR = <span class=\"number\">3e-5</span>\nEPOCHS = <span class=\"number\">5</span>\nNUM_WORKERS = <span class=\"number\">8</span>\nSEED = <span class=\"number\">42</span>\ntorch.manual_seed(SEED)\n\n\n<span class=\"comment\"># Dataset class</span>\n<span class=\"keyword\">class</span> <span class=\"class\">CatDogDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, filenames, labels, transform=<span class=\"keyword\">None</span>, mode=<span class=\"string\">&quot;</span><span class=\"string\">train</span><span class=\"string\">&quot;</span>):\n        self.filenames = filenames\n        self.labels = labels\n        self.transform = transform\n        self.mode = mode\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.filenames)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        img = Image.open(self.filenames[idx]).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">if</span> self.transform:\n            img = self.transform(img)\n        <span class=\"keyword\">if</span> self.mode == <span class=\"string\">&quot;</span><span class=\"string\">train</span><span class=\"string\">&quot;</span>:\n            <span class=\"keyword\">return</span> img, self.labels[idx]\n        <span class=\"keyword\">return</span> img\n\n\n<span class=\"comment\"># Prepare data</span>\ntrain_dir = <span class=\"string\">&quot;</span><span class=\"string\">./input/train</span><span class=\"string\">&quot;</span>\ntest_dir = <span class=\"string\">&quot;</span><span class=\"string\">./input/test</span><span class=\"string\">&quot;</span>\n\nfilenames = []\nlabels = []\n<span class=\"keyword\">for</span> f in os.listdir(train_dir):\n    filenames.append(os.path.join(train_dir, f))\n    labels.append(<span class=\"number\">1</span> <span class=\"keyword\">if</span> <span class=\"string\">&quot;</span><span class=\"string\">dog</span><span class=\"string\">&quot;</span> in f <span class=\"keyword\">else</span> <span class=\"number\">0</span>)\n\nX_train, X_val, y_train, y_val = train_test_split(\n    filenames, labels, test_size=<span class=\"number\">0.2</span>, random_state=SEED, stratify=labels\n)\n\n<span class=\"comment\"># Data augmentations</span>\ntrain_transform = T.Compose(\n    [\n        T.RandomResizedCrop(IMG_SIZE, scale=(<span class=\"number\">0.6</span>, <span class=\"number\">1.0</span>), ratio=(<span class=\"number\">0.75</span>, <span class=\"number\">1.33</span>)),\n        T.RandomHorizontalFlip(p=<span class=\"number\">0.5</span>),\n        T.ColorJitter(brightness=<span class=\"number\">0.2</span>, contrast=<span class=\"number\">0.2</span>, saturation=<span class=\"number\">0.2</span>, hue=<span class=\"number\">0.1</span>),\n        T.ToTensor(),\n        T.Normalize(mean=[<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], std=[<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\nval_transform = T.Compose(\n    [\n        T.Resize((IMG_SIZE, IMG_SIZE)),\n        T.ToTensor(),\n        T.Normalize(mean=[<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], std=[<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\n<span class=\"comment\"># Create datasets</span>\ntrain_ds = CatDogDataset(X_train, y_train, train_transform)\nval_ds = CatDogDataset(X_val, y_val, val_transform)\n\n<span class=\"comment\"># Dataloaders</span>\ntrain_loader = DataLoader(\n    train_ds,\n    batch_size=BATCH_SIZE,\n    shuffle=<span class=\"keyword\">True</span>,\n    num_workers=NUM_WORKERS,\n    pin_memory=<span class=\"keyword\">True</span>,\n)\nval_loader = DataLoader(\n    val_ds, batch_size=BATCH_SIZE, shuffle=<span class=\"keyword\">False</span>, num_workers=NUM_WORKERS\n)\n\n<span class=\"comment\"># ConvNeXt-Large model</span>\nmodel = timm.create_model(<span class=\"string\">&quot;</span><span class=\"string\">convnext_large</span><span class=\"string\">&quot;</span>, pretrained=<span class=\"keyword\">True</span>, num_classes=<span class=\"number\">0</span>)\nhead = nn.Sequential(\n    nn.Linear(<span class=\"number\">1536</span>, <span class=\"number\">256</span>), nn.ReLU(), nn.Dropout(<span class=\"number\">0.2</span>), nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">1</span>)\n)\nmodel = nn.Sequential(model, head).cuda()\n\n<span class=\"comment\"># Training setup</span>\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=<span class=\"number\">0.01</span>)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, EPOCHS)\n\n<span class=\"comment\"># Training loop</span>\nbest_val_loss = float(<span class=\"string\">&quot;</span><span class=\"string\">inf</span><span class=\"string\">&quot;</span>)\n<span class=\"keyword\">for</span> epoch in range(EPOCHS):\n    model.train()\n    train_loss = <span class=\"number\">0</span>\n    <span class=\"keyword\">for</span> images, labels in tqdm(train_loader):\n        images, labels = images.cuda(), labels.float().cuda()\n\n        optimizer.zero_grad()\n        outputs = model(images).squeeze()\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * images.size(<span class=\"number\">0</span>)\n\n    <span class=\"comment\"># Validation</span>\n    model.eval()\n    val_loss = <span class=\"number\">0</span>\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> images, labels in val_loader:\n            images, labels = images.cuda(), labels.float().cuda()\n            outputs = model(images).squeeze()\n            val_loss += criterion(outputs, labels).item() * images.size(<span class=\"number\">0</span>)\n\n    <span class=\"comment\"># Calculate metrics</span>\n    train_loss /= len(train_loader.dataset)\n    val_loss /= len(val_loader.dataset)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">/</span><span class=\"string\">{</span>EPOCHS<span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Train Loss: </span><span class=\"string\">{</span>train_loss<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\"> | Val Loss: </span><span class=\"string\">{</span>val_loss<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n    <span class=\"keyword\">if</span> val_loss &lt; best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">./working/best_model.pth</span><span class=\"string\">&quot;</span>)\n\n    scheduler.step()\n\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Best Validation Log Loss: </span><span class=\"string\">{</span>best_val_loss<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Test Time Augmentation (TTA)</span>\ntest_files = [os.path.join(test_dir, f) <span class=\"keyword\">for</span> f in os.listdir(test_dir)]\ntest_ds = CatDogDataset(test_files, <span class=\"keyword\">None</span>, val_transform, mode=<span class=\"string\">&quot;</span><span class=\"string\">test</span><span class=\"string\">&quot;</span>)\ntest_loader = DataLoader(\n    test_ds, batch_size=BATCH_SIZE, shuffle=<span class=\"keyword\">False</span>, num_workers=NUM_WORKERS\n)\n\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">./working/best_model.pth</span><span class=\"string\">&quot;</span>))\nmodel.eval()\npreds = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> images in tqdm(test_loader):\n        images = images.cuda()\n        <span class=\"comment\"># Original prediction</span>\n        outputs = model(images).squeeze()\n        <span class=\"comment\"># Horizontal flip TTA</span>\n        flipped_images = torch.flip(images, [<span class=\"number\">3</span>])\n        flipped_outputs = model(flipped_images).squeeze()\n        <span class=\"comment\"># Average probabilities</span>\n        avg_probs = (torch.sigmoid(outputs) + torch.sigmoid(flipped_outputs)) / <span class=\"number\">2</span>\n        preds.extend(avg_probs.cpu().numpy())\n\n<span class=\"comment\"># Create submission</span>\nsubmission = pd.DataFrame(\n    {<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>: [int(os.path.basename(f).split(<span class=\"string\">&quot;</span><span class=\"string\">.</span><span class=\"string\">&quot;</span>)[<span class=\"number\">0</span>]) <span class=\"keyword\">for</span> f in test_files], <span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>: preds}\n).sort_values(<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>)\nsubmission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">./submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\nprint(<span class=\"string\">&quot;</span><span class=\"string\">Submission saved!</span><span class=\"string\">&quot;</span>)\n"
}
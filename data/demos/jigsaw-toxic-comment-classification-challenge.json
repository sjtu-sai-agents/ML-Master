{
    "title": "jigsaw-toxic-comment-classification-challenge",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task jigsaw-toxic-comment-classification-challenge --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"jigsaw-toxic-comment-classification-challenge\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">from</span> transformers <span class=\"keyword\">import</span> AutoTokenizer, AutoModelForSequenceClassification\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> roc_auc_score\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">CommentDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.texts)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        text = str(self.texts[idx])\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=<span class=\"keyword\">True</span>,\n            max_length=self.max_len,\n            truncation=<span class=\"keyword\">True</span>,\n            padding=<span class=\"string\">&quot;</span><span class=\"string\">max_length</span><span class=\"string\">&quot;</span>,\n            return_attention_mask=<span class=\"keyword\">True</span>,\n            return_tensors=<span class=\"string\">&quot;</span><span class=\"string\">pt</span><span class=\"string\">&quot;</span>,\n        )\n        <span class=\"keyword\">return</span> {\n            <span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>: encoding[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>].flatten(),\n            <span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>: encoding[<span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>].flatten(),\n            <span class=\"string\">&quot;</span><span class=\"string\">labels</span><span class=\"string\">&quot;</span>: torch.tensor(self.labels[idx], dtype=torch.float),\n        }\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">compute_auc</span>(model, dataloader, device):\n    model.eval()\n    predictions, true_labels = [], []\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> batch in dataloader:\n            input_ids = batch[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>].to(device)\n            attention_mask = batch[<span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>].to(device)\n            labels = batch[<span class=\"string\">&quot;</span><span class=\"string\">labels</span><span class=\"string\">&quot;</span>].to(device)\n            outputs = model(input_ids, attention_mask)\n            preds = torch.sigmoid(outputs.logits)\n            predictions.append(preds.cpu())\n            true_labels.append(labels.cpu())\n    predictions = np.concatenate([p.numpy() <span class=\"keyword\">for</span> p in predictions])\n    true_labels = np.concatenate([l.numpy() <span class=\"keyword\">for</span> l in true_labels])\n    auc_scores = [roc_auc_score(true_labels[:, i], predictions[:, i]) <span class=\"keyword\">for</span> i in range(<span class=\"number\">6</span>)]\n    <span class=\"keyword\">return</span> np.mean(auc_scores)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">main</span>():\n    train_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/train.csv</span><span class=\"string\">&quot;</span>)\n    test_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/test.csv</span><span class=\"string\">&quot;</span>)\n\n    <span class=\"comment\"># Prepare data</span>\n    train_texts = train_df[<span class=\"string\">&quot;</span><span class=\"string\">comment_text</span><span class=\"string\">&quot;</span>].values\n    train_labels = train_df.iloc[:, <span class=\"number\">2</span>:<span class=\"number\">8</span>].values\n    train_texts, val_texts, train_labels, val_labels = train_test_split(\n        train_texts,\n        train_labels,\n        test_size=<span class=\"number\">0.2</span>,\n        random_state=<span class=\"number\">42</span>,\n        stratify=train_df[<span class=\"string\">&quot;</span><span class=\"string\">toxic</span><span class=\"string\">&quot;</span>],\n    )\n\n    <span class=\"comment\"># Correct model initialization</span>\n    model_name = <span class=\"string\">&quot;</span><span class=\"string\">unitary/toxic-bert</span><span class=\"string\">&quot;</span>\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=<span class=\"number\">6</span>)\n    model = model.to(torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span>))\n\n    <span class=\"comment\"># Class weights</span>\n    pos_counts = train_df.iloc[:, <span class=\"number\">2</span>:<span class=\"number\">8</span>].sum(axis=<span class=\"number\">0</span>)\n    class_weights = (len(train_df) - pos_counts) / pos_counts\n    class_weights = torch.tensor(class_weights.values, dtype=torch.float).cuda()\n\n    <span class=\"comment\"># Dataloaders</span>\n    max_len = <span class=\"number\">256</span>\n    train_dataset = CommentDataset(train_texts, train_labels, tokenizer, max_len)\n    val_dataset = CommentDataset(val_texts, val_labels, tokenizer, max_len)\n    train_loader = DataLoader(train_dataset, batch_size=<span class=\"number\">16</span>, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">4</span>)\n    val_loader = DataLoader(val_dataset, batch_size=<span class=\"number\">64</span>, num_workers=<span class=\"number\">4</span>)\n\n    <span class=\"comment\"># Training</span>\n    optimizer = optim.AdamW(model.parameters(), lr=<span class=\"number\">2e-5</span>)\n    loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n    best_auc = <span class=\"number\">0</span>\n\n    <span class=\"keyword\">for</span> epoch in range(<span class=\"number\">3</span>):\n        model.train()\n        <span class=\"keyword\">for</span> batch in train_loader:\n            optimizer.zero_grad()\n            input_ids = batch[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>].cuda()\n            attention_mask = batch[<span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>].cuda()\n            labels = batch[<span class=\"string\">&quot;</span><span class=\"string\">labels</span><span class=\"string\">&quot;</span>].cuda()\n            outputs = model(input_ids, attention_mask)\n            loss = loss_fn(outputs.logits, labels)\n            loss.backward()\n            optimizer.step()\n\n        val_auc = compute_auc(model, val_loader, <span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span>)\n        print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\"> Val AUC: </span><span class=\"string\">{</span>val_auc<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">if</span> val_auc &gt; best_auc:\n            best_auc = val_auc\n            torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">./working/best_model.pt</span><span class=\"string\">&quot;</span>)\n\n    <span class=\"comment\"># Test predictions</span>\n    model.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">./working/best_model.pt</span><span class=\"string\">&quot;</span>))\n    test_dataset = CommentDataset(\n        test_df[<span class=\"string\">&quot;</span><span class=\"string\">comment_text</span><span class=\"string\">&quot;</span>].values, np.zeros((len(test_df), <span class=\"number\">6</span>)), tokenizer, max_len\n    )\n    test_loader = DataLoader(test_dataset, batch_size=<span class=\"number\">64</span>, num_workers=<span class=\"number\">4</span>)\n\n    model.eval()\n    predictions = []\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> batch in test_loader:\n            input_ids = batch[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>].cuda()\n            attention_mask = batch[<span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>].cuda()\n            outputs = model(input_ids, attention_mask)\n            preds = torch.sigmoid(outputs.logits)\n            predictions.append(preds.cpu().numpy())\n\n    submission = pd.DataFrame(\n        np.concatenate(predictions),\n        columns=[\n            <span class=\"string\">&quot;</span><span class=\"string\">toxic</span><span class=\"string\">&quot;</span>,\n            <span class=\"string\">&quot;</span><span class=\"string\">severe_toxic</span><span class=\"string\">&quot;</span>,\n            <span class=\"string\">&quot;</span><span class=\"string\">obscene</span><span class=\"string\">&quot;</span>,\n            <span class=\"string\">&quot;</span><span class=\"string\">threat</span><span class=\"string\">&quot;</span>,\n            <span class=\"string\">&quot;</span><span class=\"string\">insult</span><span class=\"string\">&quot;</span>,\n            <span class=\"string\">&quot;</span><span class=\"string\">identity_hate</span><span class=\"string\">&quot;</span>,\n        ],\n    )\n    submission.insert(<span class=\"number\">0</span>, <span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>, test_df[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>].values)\n    submission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">./submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Final Validation AUC: </span><span class=\"string\">{</span>best_auc<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n\n<span class=\"keyword\">if</span> __name__ == <span class=\"string\">&quot;</span><span class=\"string\">__main__</span><span class=\"string\">&quot;</span>:\n    main()\n"
}
{
    "title": "lmsys-chatbot-arena",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task lmsys-chatbot-arena --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"lmsys-chatbot-arena\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">from</span> sentence_transformers <span class=\"keyword\">import</span> CrossEncoder, SentenceTransformer\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> log_loss\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader, TensorDataset\n<span class=\"keyword\">from</span> torch.optim.lr_scheduler <span class=\"keyword\">import</span> ReduceLROnPlateau\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">extract_text</span>(s):\n    s = str(s).strip()\n    <span class=\"keyword\">if</span> not s or s.lower() == <span class=\"string\">&quot;</span><span class=\"string\">nan</span><span class=\"string\">&quot;</span>:\n        <span class=\"keyword\">return</span> <span class=\"string\">&quot;</span><span class=\"string\">&quot;</span>\n    <span class=\"keyword\">if</span> s.startswith(<span class=\"string\">&#x27;</span><span class=\"string\">[</span><span class=\"string\">&quot;</span><span class=\"string\">&#x27;</span>) and s.endswith(<span class=\"string\">&#x27;</span><span class=\"string\">&quot;</span><span class=\"string\">]</span><span class=\"string\">&#x27;</span>):\n        <span class=\"keyword\">return</span> s[<span class=\"number\">2</span>:-<span class=\"number\">2</span>].replace(<span class=\"string\">&#x27;</span><span class=\"string\">\\\\</span><span class=\"string\">&quot;</span><span class=\"string\">&#x27;</span>, <span class=\"string\">&#x27;</span><span class=\"string\">&quot;</span><span class=\"string\">&#x27;</span>)\n    <span class=\"keyword\">if</span> s.startswith(<span class=\"string\">&quot;</span><span class=\"string\">[</span><span class=\"string\">&#x27;</span><span class=\"string\">&quot;</span>) and s.endswith(<span class=\"string\">&quot;</span><span class=\"string\">&#x27;</span><span class=\"string\">]</span><span class=\"string\">&quot;</span>):\n        <span class=\"keyword\">return</span> s[<span class=\"number\">2</span>:-<span class=\"number\">2</span>].replace(<span class=\"string\">&quot;</span><span class=\"string\">\\\\</span><span class=\"string\">&#x27;</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">&#x27;</span><span class=\"string\">&quot;</span>)\n    <span class=\"keyword\">return</span> s\n\n\n<span class=\"comment\"># Load and augment data</span>\ntrain = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/train.csv</span><span class=\"string\">&quot;</span>)\ntest = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/test.csv</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Create augmented training data</span>\naugmented = train.copy()\naugmented[<span class=\"string\">&quot;</span><span class=\"string\">response_a</span><span class=\"string\">&quot;</span>], augmented[<span class=\"string\">&quot;</span><span class=\"string\">response_b</span><span class=\"string\">&quot;</span>] = (\n    train[<span class=\"string\">&quot;</span><span class=\"string\">response_b</span><span class=\"string\">&quot;</span>],\n    train[<span class=\"string\">&quot;</span><span class=\"string\">response_a</span><span class=\"string\">&quot;</span>],\n)\naugmented[<span class=\"string\">&quot;</span><span class=\"string\">winner_model_a</span><span class=\"string\">&quot;</span>], augmented[<span class=\"string\">&quot;</span><span class=\"string\">winner_model_b</span><span class=\"string\">&quot;</span>] = (\n    train[<span class=\"string\">&quot;</span><span class=\"string\">winner_model_b</span><span class=\"string\">&quot;</span>],\n    train[<span class=\"string\">&quot;</span><span class=\"string\">winner_model_a</span><span class=\"string\">&quot;</span>],\n)\ntrain = pd.concat([train, augmented], ignore_index=<span class=\"keyword\">True</span>)\n\n<span class=\"comment\"># Preprocess text</span>\n<span class=\"keyword\">for</span> df in [train, test]:\n    <span class=\"keyword\">for</span> col in [<span class=\"string\">&quot;</span><span class=\"string\">prompt</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">response_a</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">response_b</span><span class=\"string\">&quot;</span>]:\n        df[col] = df[col].apply(extract_text).str.strip().replace(<span class=\"string\">&quot;</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">[EMPTY]</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Feature generation</span>\ncross_encoder = CrossEncoder(\n    <span class=\"string\">&quot;</span><span class=\"string\">cross-encoder/stsb-roberta-large</span><span class=\"string\">&quot;</span>, device=<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span>, max_length=<span class=\"number\">512</span>\n)\nsentence_model = SentenceTransformer(\n    <span class=\"string\">&quot;</span><span class=\"string\">sentence-transformers/all-mpnet-base-v2</span><span class=\"string\">&quot;</span>, device=<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span>\n)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">batch_predict</span>(model, pairs, batch_size=<span class=\"number\">256</span>):\n    <span class=\"keyword\">return</span> model.predict(pairs, batch_size=batch_size, show_progress_bar=<span class=\"keyword\">True</span>)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">get_cross_features</span>(prompts, resps_a, resps_b):\n    <span class=\"keyword\">return</span> np.column_stack(\n        [\n            batch_predict(cross_encoder, list(zip(resps_a, resps_b))),\n            batch_predict(cross_encoder, list(zip(resps_b, resps_a))),\n            batch_predict(cross_encoder, list(zip(prompts, resps_a))),\n            batch_predict(cross_encoder, list(zip(prompts, resps_b))),\n        ]\n    )\n\n\nprint(<span class=\"string\">&quot;</span><span class=\"string\">Generating features...</span><span class=\"string\">&quot;</span>)\ntrain_cross = get_cross_features(train.prompt, train.response_a, train.response_b)\ntest_cross = get_cross_features(test.prompt, test.response_a, test.response_b)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">safe_embed</span>(texts, model):\n    <span class=\"keyword\">return</span> (\n        model.encode(\n            [t <span class=\"keyword\">if</span> t.strip() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">[EMPTY]</span><span class=\"string\">&quot;</span> <span class=\"keyword\">for</span> t in texts],\n            batch_size=<span class=\"number\">256</span>,\n            show_progress_bar=<span class=\"keyword\">True</span>,\n            convert_to_tensor=<span class=\"keyword\">True</span>,\n        )\n        .cpu()\n        .numpy()\n    )\n\n\ntrain_emb = np.hstack(\n    [\n        safe_embed(train.prompt, sentence_model),\n        safe_embed(train.response_a, sentence_model),\n        safe_embed(train.response_b, sentence_model),\n    ]\n)\ntest_emb = np.hstack(\n    [\n        safe_embed(test.prompt, sentence_model),\n        safe_embed(test.response_a, sentence_model),\n        safe_embed(test.response_b, sentence_model),\n    ]\n)\n\nX = np.hstack([train_emb, train_cross])\nX_test = np.hstack([test_emb, test_cross])\ny = np.argmax(train[[<span class=\"string\">&quot;</span><span class=\"string\">winner_model_a</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">winner_model_b</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">winner_tie</span><span class=\"string\">&quot;</span>]].values, axis=<span class=\"number\">1</span>)\n\n<span class=\"comment\"># Dynamic class weighting</span>\nclass_counts = np.bincount(y)\nclass_weights = <span class=\"number\">1.0</span> / np.sqrt(class_counts)  <span class=\"comment\"># Smooth weighting</span>\nclass_weights = torch.tensor(\n    class_weights / class_weights.sum() * len(class_counts), dtype=torch.float32\n).cuda()\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">PreferenceModel</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, input_size):\n        super().<span class=\"function\">__init__</span>()\n        self.net = nn.Sequential(\n            nn.BatchNorm1d(input_size),\n            nn.Linear(input_size, <span class=\"number\">1536</span>),\n            nn.GELU(),\n            nn.Dropout(<span class=\"number\">0.6</span>),\n            nn.Linear(<span class=\"number\">1536</span>, <span class=\"number\">768</span>),\n            nn.GELU(),\n            nn.Dropout(<span class=\"number\">0.4</span>),\n            nn.Linear(<span class=\"number\">768</span>, <span class=\"number\">3</span>),\n        )\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, x):\n        <span class=\"keyword\">return</span> self.net(x)\n\n\n<span class=\"comment\"># Prepare data</span>\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=<span class=\"number\">0.2</span>, stratify=y, random_state=<span class=\"number\">42</span>\n)\ntrain_dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\nval_dataset = TensorDataset(torch.FloatTensor(X_val), torch.LongTensor(y_val))\n\n<span class=\"comment\"># Training setup</span>\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span>)\nmodel = PreferenceModel(X.shape[<span class=\"number\">1</span>]).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=<span class=\"number\">2e-4</span>, weight_decay=<span class=\"number\">1e-5</span>)\nscheduler = ReduceLROnPlateau(optimizer, <span class=\"string\">&quot;</span><span class=\"string\">min</span><span class=\"string\">&quot;</span>, patience=<span class=\"number\">2</span>, factor=<span class=\"number\">0.5</span>)\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\n\ntrain_loader = DataLoader(train_dataset, batch_size=<span class=\"number\">1024</span>, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">8</span>)\nval_loader = DataLoader(val_dataset, batch_size=<span class=\"number\">2048</span>, num_workers=<span class=\"number\">8</span>)\n\n<span class=\"comment\"># Training loop</span>\nbest_loss = float(<span class=\"string\">&quot;</span><span class=\"string\">inf</span><span class=\"string\">&quot;</span>)\n<span class=\"keyword\">for</span> epoch in range(<span class=\"number\">50</span>):\n    model.train()\n    <span class=\"keyword\">for</span> inputs, targets in train_loader:\n        optimizer.zero_grad()\n        outputs = model(inputs.to(device))\n        loss = criterion(outputs, targets.to(device))\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), <span class=\"number\">1.0</span>)\n        optimizer.step()\n\n    model.eval()\n    val_loss, total = <span class=\"number\">0</span>, <span class=\"number\">0</span>\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> inputs, targets in val_loader:\n            outputs = model(inputs.to(device))\n            val_loss += criterion(outputs, targets.to(device)).item() * inputs.size(<span class=\"number\">0</span>)\n            total += inputs.size(<span class=\"number\">0</span>)\n    val_loss /= total\n    scheduler.step(val_loss)\n\n    <span class=\"keyword\">if</span> val_loss &lt; best_loss:\n        best_loss = val_loss\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>)\n    <span class=\"keyword\">else</span>:\n        <span class=\"keyword\">if</span> epoch - scheduler.last_epoch &gt; <span class=\"number\">4</span>:\n            <span class=\"keyword\">break</span>\n\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">: Val Loss </span><span class=\"string\">{</span>val_loss<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Load best model</span>\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>))\nmodel.eval()\n<span class=\"keyword\">with</span> torch.no_grad():\n    val_probs = (\n        torch.softmax(model(torch.FloatTensor(X_val).to(device)), dim=<span class=\"number\">1</span>).cpu().numpy()\n    )\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Validation Log Loss: </span><span class=\"string\">{</span>log_loss(y_val, val_probs)<span class=\"string\">:</span><span class=\"string\">.5f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Generate submission</span>\n<span class=\"keyword\">with</span> torch.no_grad():\n    test_probs = (\n        torch.softmax(model(torch.FloatTensor(X_test).to(device)), dim=<span class=\"number\">1</span>).cpu().numpy()\n    )\n\npd.DataFrame(\n    {\n        <span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>: test.id,\n        <span class=\"string\">&quot;</span><span class=\"string\">winner_model_a</span><span class=\"string\">&quot;</span>: test_probs[:, <span class=\"number\">0</span>],\n        <span class=\"string\">&quot;</span><span class=\"string\">winner_model_b</span><span class=\"string\">&quot;</span>: test_probs[:, <span class=\"number\">1</span>],\n        <span class=\"string\">&quot;</span><span class=\"string\">winner_tie</span><span class=\"string\">&quot;</span>: test_probs[:, <span class=\"number\">2</span>],\n    }\n).to_csv(<span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\n"
}
{
    "title": "tweet-sentiment-extraction",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task tweet-sentiment-extraction --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"tweet-sentiment-extraction\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">from</span> transformers <span class=\"keyword\">import</span> DebertaV2TokenizerFast, DebertaV2ForQuestionAnswering, AdamW\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm\n<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> csv\n\n<span class=\"comment\"># Configuration</span>\nmodel_name = <span class=\"string\">&quot;</span><span class=\"string\">microsoft/deberta-v3-base</span><span class=\"string\">&quot;</span>\nmax_length = <span class=\"number\">128</span>\nbatch_size = <span class=\"number\">16</span>\nepochs = <span class=\"number\">3</span>\nmax_span_length = <span class=\"number\">20</span>  <span class=\"comment\"># 95th percentile of training data</span>\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Data preparation with improved cleaning</span>\ntrain_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/train.csv</span><span class=\"string\">&quot;</span>, keep_default_na=<span class=\"keyword\">False</span>)\ntrain_df = train_df[(train_df[<span class=\"string\">&quot;</span><span class=\"string\">text</span><span class=\"string\">&quot;</span>] != <span class=\"string\">&quot;</span><span class=\"string\">&quot;</span>) &amp; (train_df[<span class=\"string\">&quot;</span><span class=\"string\">selected_text</span><span class=\"string\">&quot;</span>] != <span class=\"string\">&quot;</span><span class=\"string\">&quot;</span>)]\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">clean_text</span>(text):\n    <span class=\"keyword\">return</span> str(text).strip(<span class=\"string\">&#x27;</span><span class=\"string\">&quot;</span><span class=\"string\">&#x27;</span>).strip()\n\n\ntrain_df[<span class=\"string\">&quot;</span><span class=\"string\">text</span><span class=\"string\">&quot;</span>] = train_df[<span class=\"string\">&quot;</span><span class=\"string\">text</span><span class=\"string\">&quot;</span>].apply(clean_text)\ntrain_df[<span class=\"string\">&quot;</span><span class=\"string\">selected_text</span><span class=\"string\">&quot;</span>] = train_df[<span class=\"string\">&quot;</span><span class=\"string\">selected_text</span><span class=\"string\">&quot;</span>].apply(clean_text)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">is_valid_row</span>(row):\n    text = row[<span class=\"string\">&quot;</span><span class=\"string\">text</span><span class=\"string\">&quot;</span>].lower()\n    selected = row[<span class=\"string\">&quot;</span><span class=\"string\">selected_text</span><span class=\"string\">&quot;</span>].lower()\n    <span class=\"keyword\">return</span> selected in text or text in selected  <span class=\"comment\"># Handle reversed cases</span>\n\n\nvalid_mask = train_df.apply(is_valid_row, axis=<span class=\"number\">1</span>)\ntrain_df = train_df[valid_mask].copy()\n\ntrain_df, val_df = train_test_split(\n    train_df, test_size=<span class=\"number\">0.1</span>, stratify=train_df[<span class=\"string\">&quot;</span><span class=\"string\">sentiment</span><span class=\"string\">&quot;</span>], random_state=<span class=\"number\">42</span>\n)\n\ntokenizer = DebertaV2TokenizerFast.from_pretrained(model_name)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">QADataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, tokenizer):\n        self.df = df\n        self.tokenizer = tokenizer\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.df)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        row = self.df.iloc[idx]\n        text = row[<span class=\"string\">&quot;</span><span class=\"string\">text</span><span class=\"string\">&quot;</span>]\n        selected = row[<span class=\"string\">&quot;</span><span class=\"string\">selected_text</span><span class=\"string\">&quot;</span>]\n        original_idx = row.name\n\n        start_char = text.lower().find(selected.lower())\n        <span class=\"keyword\">if</span> start_char == -<span class=\"number\">1</span>:\n            start_char = <span class=\"number\">0</span>\n        end_char = start_char + len(selected) - <span class=\"number\">1</span>\n\n        inputs = self.tokenizer(\n            row[<span class=\"string\">&quot;</span><span class=\"string\">sentiment</span><span class=\"string\">&quot;</span>],\n            text,\n            max_length=max_length,\n            padding=<span class=\"string\">&quot;</span><span class=\"string\">max_length</span><span class=\"string\">&quot;</span>,\n            truncation=<span class=\"string\">&quot;</span><span class=\"string\">only_second</span><span class=\"string\">&quot;</span>,\n            return_offsets_mapping=<span class=\"keyword\">True</span>,\n            return_tensors=<span class=\"string\">&quot;</span><span class=\"string\">pt</span><span class=\"string\">&quot;</span>,\n        )\n\n        offset_mapping = inputs[<span class=\"string\">&quot;</span><span class=\"string\">offset_mapping</span><span class=\"string\">&quot;</span>].squeeze().tolist()\n        sequence_ids = inputs.sequence_ids()\n\n        <span class=\"keyword\">try</span>:\n            context_start = sequence_ids.index(<span class=\"number\">1</span>)\n            context_end = len(sequence_ids) - sequence_ids[::-<span class=\"number\">1</span>].index(<span class=\"number\">1</span>) - <span class=\"number\">1</span>\n        <span class=\"keyword\">except</span> ValueError:\n            context_start, context_end = <span class=\"number\">0</span>, len(sequence_ids) - <span class=\"number\">1</span>\n\n        start_token, end_token = context_start, context_start\n        <span class=\"keyword\">for</span> i in range(context_start, context_end + <span class=\"number\">1</span>):\n            <span class=\"keyword\">if</span> offset_mapping[i][<span class=\"number\">0</span>] &lt;= start_char &lt; offset_mapping[i][<span class=\"number\">1</span>]:\n                start_token = i\n                <span class=\"keyword\">break</span>\n        <span class=\"keyword\">for</span> i in range(context_end, context_start - <span class=\"number\">1</span>, -<span class=\"number\">1</span>):\n            <span class=\"keyword\">if</span> offset_mapping[i][<span class=\"number\">0</span>] &lt;= end_char &lt; offset_mapping[i][<span class=\"number\">1</span>]:\n                end_token = i\n                <span class=\"keyword\">break</span>\n\n        <span class=\"keyword\">return</span> {\n            <span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>: inputs[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>].squeeze(),\n            <span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>: inputs[<span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>].squeeze(),\n            <span class=\"string\">&quot;</span><span class=\"string\">start_positions</span><span class=\"string\">&quot;</span>: torch.tensor(start_token),\n            <span class=\"string\">&quot;</span><span class=\"string\">end_positions</span><span class=\"string\">&quot;</span>: torch.tensor(end_token),\n            <span class=\"string\">&quot;</span><span class=\"string\">original_idx</span><span class=\"string\">&quot;</span>: original_idx,\n            <span class=\"string\">&quot;</span><span class=\"string\">offset_mapping</span><span class=\"string\">&quot;</span>: inputs[<span class=\"string\">&quot;</span><span class=\"string\">offset_mapping</span><span class=\"string\">&quot;</span>].squeeze(),\n            <span class=\"string\">&quot;</span><span class=\"string\">original_text</span><span class=\"string\">&quot;</span>: text,\n        }\n\n\nmodel = DebertaV2ForQuestionAnswering.from_pretrained(model_name).to(device)\noptimizer = AdamW(model.parameters(), lr=<span class=\"number\">2e-5</span>)\n\ntrain_loader = DataLoader(\n    QADataset(train_df, tokenizer), batch_size=batch_size, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">4</span>\n)\n\n<span class=\"keyword\">for</span> epoch in range(epochs):\n    model.train()\n    total_loss = <span class=\"number\">0</span>\n    <span class=\"keyword\">for</span> batch in tqdm(train_loader, desc=<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>):\n        inputs = {\n            k: v.to(device)\n            <span class=\"keyword\">for</span> k, v in batch.items()\n            <span class=\"keyword\">if</span> k in [<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>]\n        }\n        targets = {\n            k: v.to(device)\n            <span class=\"keyword\">for</span> k, v in batch.items()\n            <span class=\"keyword\">if</span> k in [<span class=\"string\">&quot;</span><span class=\"string\">start_positions</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">end_positions</span><span class=\"string\">&quot;</span>]\n        }\n\n        outputs = model(\n            **inputs,\n            start_positions=targets[<span class=\"string\">&quot;</span><span class=\"string\">start_positions</span><span class=\"string\">&quot;</span>],\n            end_positions=targets[<span class=\"string\">&quot;</span><span class=\"string\">end_positions</span><span class=\"string\">&quot;</span>],\n        )\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        total_loss += loss.item()\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Train loss: </span><span class=\"string\">{</span>total_loss/len(train_loader)<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">jaccard</span>(str1, str2):\n    a = set(str1.lower().split())\n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    <span class=\"keyword\">return</span> len(c) / (len(a) + len(b) - len(c)) <span class=\"keyword\">if</span> a or b <span class=\"keyword\">else</span> <span class=\"number\">0.0</span>\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">optimal_span</span>(start_logits, end_logits, max_span=max_span_length):\n    n = len(start_logits)\n    best_score = -float(<span class=\"string\">&quot;</span><span class=\"string\">inf</span><span class=\"string\">&quot;</span>)\n    best_pair = (<span class=\"number\">0</span>, <span class=\"number\">0</span>)\n\n    <span class=\"comment\"># Create DP table</span>\n    dp = np.zeros((n, n))\n    <span class=\"keyword\">for</span> i in range(n):\n        <span class=\"keyword\">for</span> j in range(i, min(i + max_span, n)):\n            <span class=\"keyword\">if</span> j &gt;= i:\n                dp[i][j] = start_logits[i] + end_logits[j]\n                <span class=\"keyword\">if</span> dp[i][j] &gt; best_score:\n                    best_score = dp[i][j]\n                    best_pair = (i, j)\n    <span class=\"keyword\">return</span> best_pair\n\n\nval_loader = DataLoader(QADataset(val_df, tokenizer), batch_size=<span class=\"number\">32</span>, num_workers=<span class=\"number\">4</span>)\nmodel.eval()\nscores = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> batch in tqdm(val_loader, desc=<span class=\"string\">&quot;</span><span class=\"string\">Validating</span><span class=\"string\">&quot;</span>):\n        inputs = {\n            k: v.to(device)\n            <span class=\"keyword\">for</span> k, v in batch.items()\n            <span class=\"keyword\">if</span> k in [<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>]\n        }\n        outputs = model(**inputs)\n\n        start_logits = outputs.start_logits.cpu().numpy()\n        end_logits = outputs.end_logits.cpu().numpy()\n\n        <span class=\"keyword\">for</span> i in range(len(batch[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>])):\n            original_idx = batch[<span class=\"string\">&quot;</span><span class=\"string\">original_idx</span><span class=\"string\">&quot;</span>][i].item()\n            row = val_df.loc[original_idx]\n            sentiment = row[<span class=\"string\">&quot;</span><span class=\"string\">sentiment</span><span class=\"string\">&quot;</span>]\n            original_text = row[<span class=\"string\">&quot;</span><span class=\"string\">text</span><span class=\"string\">&quot;</span>]\n            true_text = row[<span class=\"string\">&quot;</span><span class=\"string\">selected_text</span><span class=\"string\">&quot;</span>]\n\n            <span class=\"keyword\">if</span> sentiment == <span class=\"string\">&quot;</span><span class=\"string\">neutral</span><span class=\"string\">&quot;</span>:\n                pred_text = original_text\n            <span class=\"keyword\">else</span>:\n                offsets = batch[<span class=\"string\">&quot;</span><span class=\"string\">offset_mapping</span><span class=\"string\">&quot;</span>][i].tolist()\n                start, end = optimal_span(start_logits[i], end_logits[i])\n\n                start = min(max(start, <span class=\"number\">0</span>), len(offsets) - <span class=\"number\">1</span>)\n                end = min(max(end, start), len(offsets) - <span class=\"number\">1</span>)\n\n                pred_text = original_text[offsets[start][<span class=\"number\">0</span>] : offsets[end][<span class=\"number\">1</span>]]\n\n            scores.append(jaccard(pred_text, true_text))\n\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Validation Jaccard: </span><span class=\"string\">{</span>np.mean(scores)<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">TestDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, tokenizer):\n        self.df = df\n        self.tokenizer = tokenizer\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.df)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        row = self.df.iloc[idx]\n        inputs = self.tokenizer(\n            row[<span class=\"string\">&quot;</span><span class=\"string\">sentiment</span><span class=\"string\">&quot;</span>],\n            clean_text(row[<span class=\"string\">&quot;</span><span class=\"string\">text</span><span class=\"string\">&quot;</span>]),\n            max_length=max_length,\n            padding=<span class=\"string\">&quot;</span><span class=\"string\">max_length</span><span class=\"string\">&quot;</span>,\n            truncation=<span class=\"string\">&quot;</span><span class=\"string\">only_second</span><span class=\"string\">&quot;</span>,\n            return_offsets_mapping=<span class=\"keyword\">True</span>,\n            return_tensors=<span class=\"string\">&quot;</span><span class=\"string\">pt</span><span class=\"string\">&quot;</span>,\n        )\n        <span class=\"keyword\">return</span> {\n            <span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>: inputs[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>].squeeze(),\n            <span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>: inputs[<span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>].squeeze(),\n            <span class=\"string\">&quot;</span><span class=\"string\">offset_mapping</span><span class=\"string\">&quot;</span>: inputs[<span class=\"string\">&quot;</span><span class=\"string\">offset_mapping</span><span class=\"string\">&quot;</span>].squeeze(),\n            <span class=\"string\">&quot;</span><span class=\"string\">text</span><span class=\"string\">&quot;</span>: clean_text(row[<span class=\"string\">&quot;</span><span class=\"string\">text</span><span class=\"string\">&quot;</span>]),\n            <span class=\"string\">&quot;</span><span class=\"string\">sentiment</span><span class=\"string\">&quot;</span>: row[<span class=\"string\">&quot;</span><span class=\"string\">sentiment</span><span class=\"string\">&quot;</span>],\n        }\n\n\ntest_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/test.csv</span><span class=\"string\">&quot;</span>, keep_default_na=<span class=\"keyword\">False</span>)\ntest_df[<span class=\"string\">&quot;</span><span class=\"string\">text</span><span class=\"string\">&quot;</span>] = test_df[<span class=\"string\">&quot;</span><span class=\"string\">text</span><span class=\"string\">&quot;</span>].apply(clean_text)\ntest_loader = DataLoader(TestDataset(test_df, tokenizer), batch_size=<span class=\"number\">32</span>, num_workers=<span class=\"number\">4</span>)\npredictions = []\n\nmodel.eval()\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> batch in tqdm(test_loader, desc=<span class=\"string\">&quot;</span><span class=\"string\">Testing</span><span class=\"string\">&quot;</span>):\n        inputs = {\n            k: v.to(device)\n            <span class=\"keyword\">for</span> k, v in batch.items()\n            <span class=\"keyword\">if</span> k in [<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>]\n        }\n        outputs = model(**inputs)\n\n        start_logits = outputs.start_logits.cpu().numpy()\n        end_logits = outputs.end_logits.cpu().numpy()\n\n        <span class=\"keyword\">for</span> i in range(len(batch[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>])):\n            text = batch[<span class=\"string\">&quot;</span><span class=\"string\">text</span><span class=\"string\">&quot;</span>][i]\n            sentiment = batch[<span class=\"string\">&quot;</span><span class=\"string\">sentiment</span><span class=\"string\">&quot;</span>][i]\n\n            <span class=\"keyword\">if</span> sentiment == <span class=\"string\">&quot;</span><span class=\"string\">neutral</span><span class=\"string\">&quot;</span>:\n                pred_text = text\n            <span class=\"keyword\">else</span>:\n                offsets = batch[<span class=\"string\">&quot;</span><span class=\"string\">offset_mapping</span><span class=\"string\">&quot;</span>][i].tolist()\n                start, end = optimal_span(start_logits[i], end_logits[i])\n\n                start = min(max(start, <span class=\"number\">0</span>), len(offsets) - <span class=\"number\">1</span>)\n                end = min(max(end, start), len(offsets) - <span class=\"number\">1</span>)\n\n                pred_text = text[offsets[start][<span class=\"number\">0</span>] : offsets[end][<span class=\"number\">1</span>]]\n\n            predictions.append(pred_text.strip() or text)\n\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">./submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\nsubmission_df = pd.DataFrame(\n    {<span class=\"string\">&quot;</span><span class=\"string\">textID</span><span class=\"string\">&quot;</span>: test_df[<span class=\"string\">&quot;</span><span class=\"string\">textID</span><span class=\"string\">&quot;</span>], <span class=\"string\">&quot;</span><span class=\"string\">selected_text</span><span class=\"string\">&quot;</span>: predictions}\n)\nsubmission_df.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">./submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>, quoting=csv.QUOTE_ALL)\nprint(<span class=\"string\">&quot;</span><span class=\"string\">Submission saved to submission.csv</span><span class=\"string\">&quot;</span>)\n"
}
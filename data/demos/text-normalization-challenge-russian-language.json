{
    "title": "text-normalization-challenge-russian-language",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task text-normalization-challenge-russian-language --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"text-normalization-challenge-russian-language\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> sys\n<span class=\"keyword\">import</span> subprocess\n<span class=\"keyword\">import</span> csv\n<span class=\"keyword\">from</span> collections <span class=\"keyword\">import</span> defaultdict\n\n<span class=\"comment\"># Install num2words if missing</span>\n<span class=\"keyword\">try</span>:\n    <span class=\"keyword\">from</span> num2words <span class=\"keyword\">import</span> num2words\n<span class=\"keyword\">except</span> ImportError:\n    subprocess.check_call([sys.executable, <span class=\"string\">&quot;</span><span class=\"string\">-m</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">pip</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">install</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">num2words==0.5.10</span><span class=\"string\">&quot;</span>])\n    <span class=\"keyword\">from</span> num2words <span class=\"keyword\">import</span> num2words\n\n<span class=\"comment\"># Build lookup table</span>\nlookup = defaultdict(<span class=\"keyword\">lambda</span>: defaultdict(int))\nchunk_size = <span class=\"number\">100000</span>\n\n<span class=\"keyword\">for</span> chunk in pd.read_csv(\n    <span class=\"string\">&quot;</span><span class=\"string\">input/ru_train.csv</span><span class=\"string\">&quot;</span>, chunksize=chunk_size, usecols=[<span class=\"string\">&quot;</span><span class=\"string\">before</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">after</span><span class=\"string\">&quot;</span>]\n):\n    chunk[<span class=\"string\">&quot;</span><span class=\"string\">after</span><span class=\"string\">&quot;</span>] = chunk[<span class=\"string\">&quot;</span><span class=\"string\">after</span><span class=\"string\">&quot;</span>].where(chunk[<span class=\"string\">&quot;</span><span class=\"string\">after</span><span class=\"string\">&quot;</span>] != <span class=\"string\">&quot;</span><span class=\"string\">&lt;self&gt;</span><span class=\"string\">&quot;</span>, chunk[<span class=\"string\">&quot;</span><span class=\"string\">before</span><span class=\"string\">&quot;</span>])\n    chunk = chunk.dropna(subset=[<span class=\"string\">&quot;</span><span class=\"string\">after</span><span class=\"string\">&quot;</span>])\n    <span class=\"keyword\">for</span> before, after in zip(chunk[<span class=\"string\">&quot;</span><span class=\"string\">before</span><span class=\"string\">&quot;</span>], chunk[<span class=\"string\">&quot;</span><span class=\"string\">after</span><span class=\"string\">&quot;</span>]):\n        lookup[before][after] += <span class=\"number\">1</span>\n\nfinal_lookup = {}\n<span class=\"keyword\">for</span> before, counts in lookup.items():\n    final_lookup[before] = max(counts.items(), key=<span class=\"keyword\">lambda</span> x: x[<span class=\"number\">1</span>])[<span class=\"number\">0</span>]\n\n\n<span class=\"comment\"># Normalization function</span>\n<span class=\"keyword\">def</span> <span class=\"function\">normalize_token</span>(token):\n    token = str(token).strip()\n    <span class=\"keyword\">return</span> final_lookup.get(token, _handle_unknown_token(token))\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">_handle_unknown_token</span>(token):\n    clean_token = token.replace(<span class=\"string\">&quot;</span><span class=\"string\">,</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">&quot;</span>).replace(<span class=\"string\">&quot;</span><span class=\"string\">.</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">&quot;</span>).strip()\n    <span class=\"keyword\">if</span> clean_token.isdigit():\n        <span class=\"keyword\">try</span>:\n            num = float(clean_token)\n            <span class=\"keyword\">return</span> num2words(num, lang=<span class=\"string\">&quot;</span><span class=\"string\">ru</span><span class=\"string\">&quot;</span>, to=<span class=\"string\">&quot;</span><span class=\"string\">cardinal</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">except</span>:\n            <span class=\"keyword\">pass</span>\n    <span class=\"keyword\">return</span> token\n\n\n<span class=\"comment\"># Process test data</span>\ntest_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/ru_test_2.csv</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Create submission DataFrame</span>\nsubmission = pd.DataFrame(\n    {\n        <span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>: test_df[<span class=\"string\">&quot;</span><span class=\"string\">sentence_id</span><span class=\"string\">&quot;</span>].astype(str)\n        + <span class=\"string\">&quot;</span><span class=\"string\">_</span><span class=\"string\">&quot;</span>\n        + test_df[<span class=\"string\">&quot;</span><span class=\"string\">token_id</span><span class=\"string\">&quot;</span>].astype(str),\n        <span class=\"string\">&quot;</span><span class=\"string\">after</span><span class=\"string\">&quot;</span>: test_df[<span class=\"string\">&quot;</span><span class=\"string\">before</span><span class=\"string\">&quot;</span>].apply(normalize_token),\n    }\n)\n\n<span class=\"comment\"># Ensure string types</span>\nsubmission[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>] = submission[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>].astype(str)\nsubmission[<span class=\"string\">&quot;</span><span class=\"string\">after</span><span class=\"string\">&quot;</span>] = submission[<span class=\"string\">&quot;</span><span class=\"string\">after</span><span class=\"string\">&quot;</span>].astype(str)\n\n<span class=\"comment\"># Save submission using csv module to avoid pandas version issues</span>\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\n<span class=\"keyword\">with</span> open(<span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">w</span><span class=\"string\">&quot;</span>, encoding=<span class=\"string\">&quot;</span><span class=\"string\">utf-8</span><span class=\"string\">&quot;</span>, newline=<span class=\"string\">&quot;</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">as</span> f:\n    writer = csv.writer(f)\n    writer.writerow([<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">after</span><span class=\"string\">&quot;</span>])\n    <span class=\"keyword\">for</span> row in submission.itertuples(index=<span class=\"keyword\">False</span>):\n        writer.writerow([row.id, row.after])\n\n<span class=\"comment\"># Generate validation metric</span>\ntrain_sample = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/ru_train.csv</span><span class=\"string\">&quot;</span>, nrows=<span class=\"number\">10000</span>)\ntrain_sample[<span class=\"string\">&quot;</span><span class=\"string\">pred</span><span class=\"string\">&quot;</span>] = train_sample[<span class=\"string\">&quot;</span><span class=\"string\">before</span><span class=\"string\">&quot;</span>].apply(normalize_token)\naccuracy = (train_sample[<span class=\"string\">&quot;</span><span class=\"string\">after</span><span class=\"string\">&quot;</span>] == train_sample[<span class=\"string\">&quot;</span><span class=\"string\">pred</span><span class=\"string\">&quot;</span>]).mean()\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Validation Accuracy: </span><span class=\"string\">{</span>accuracy<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n"
}
{
    "title": "imet-2020-fgvc7",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task imet-2020-fgvc7 --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"imet-2020-fgvc7\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn\n<span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms\n<span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> f1_score\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">import</span> timm\n<span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm\n\n<span class=\"comment\"># Optimized configuration</span>\nBATCH_SIZE = <span class=\"number\">32</span>\nIMG_SIZE = <span class=\"number\">256</span>\nLR = <span class=\"number\">3e-4</span>\nEPOCHS = <span class=\"number\">10</span>\nPATIENCE = <span class=\"number\">2</span>\nTHRESHOLD = <span class=\"number\">0.2</span>\nNUM_CLASSES = <span class=\"number\">3474</span>\n\n<span class=\"comment\"># Data preparation</span>\ntrain_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/train.csv</span><span class=\"string\">&quot;</span>)\ntrain_df[<span class=\"string\">&quot;</span><span class=\"string\">attribute_ids</span><span class=\"string\">&quot;</span>] = train_df[<span class=\"string\">&quot;</span><span class=\"string\">attribute_ids</span><span class=\"string\">&quot;</span>].apply(\n    <span class=\"keyword\">lambda</span> x: list(map(int, x.split()))\n)\nall_labels = sorted(set([l <span class=\"keyword\">for</span> labels in train_df[<span class=\"string\">&quot;</span><span class=\"string\">attribute_ids</span><span class=\"string\">&quot;</span>] <span class=\"keyword\">for</span> l in labels]))\nlabel_map = {l: i <span class=\"keyword\">for</span> i, l in enumerate(all_labels)}\n\n\n<span class=\"comment\"># Dataset class with caching</span>\n<span class=\"keyword\">class</span> <span class=\"class\">ArtDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, root_dir, transform=<span class=\"keyword\">None</span>):\n        self.df = df.reset_index(drop=<span class=\"keyword\">True</span>)\n        self.root_dir = root_dir\n        self.transform = transform\n        self.label_matrix = self._build_label_matrix()\n\n    <span class=\"keyword\">def</span> <span class=\"function\">_build_label_matrix</span>(self):\n        matrix = np.zeros((len(self.df), NUM_CLASSES), dtype=np.float32)\n        <span class=\"keyword\">for</span> idx, labels in enumerate(self.df[<span class=\"string\">&quot;</span><span class=\"string\">attribute_ids</span><span class=\"string\">&quot;</span>]):\n            <span class=\"keyword\">for</span> l in labels:\n                <span class=\"keyword\">if</span> l in label_map:\n                    matrix[idx, label_map[l]] = <span class=\"number\">1.0</span>\n        <span class=\"keyword\">return</span> matrix\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.df)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        img_path = os.path.join(self.root_dir, self.df.iloc[idx][<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>] + <span class=\"string\">&quot;</span><span class=\"string\">.png</span><span class=\"string\">&quot;</span>)\n        image = Image.open(img_path).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">if</span> self.transform:\n            image = self.transform(image)\n        <span class=\"keyword\">return</span> image, self.label_matrix[idx]\n\n\n<span class=\"comment\"># Optimized transforms</span>\ntrain_transform = transforms.Compose(\n    [\n        transforms.Resize(IMG_SIZE),\n        transforms.RandomResizedCrop(IMG_SIZE),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\nval_transform = transforms.Compose(\n    [\n        transforms.Resize(IMG_SIZE),\n        transforms.CenterCrop(IMG_SIZE),\n        transforms.ToTensor(),\n        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\n<span class=\"comment\"># Split data</span>\ntrain, valid = train_test_split(train_df, test_size=<span class=\"number\">0.1</span>, random_state=<span class=\"number\">42</span>)\ntrain_ds = ArtDataset(train, <span class=\"string\">&quot;</span><span class=\"string\">./input/train</span><span class=\"string\">&quot;</span>, train_transform)\nvalid_ds = ArtDataset(valid, <span class=\"string\">&quot;</span><span class=\"string\">./input/train</span><span class=\"string\">&quot;</span>, val_transform)\n\ntrain_loader = DataLoader(\n    train_ds,\n    batch_size=BATCH_SIZE,\n    shuffle=<span class=\"keyword\">True</span>,\n    num_workers=<span class=\"number\">4</span>,\n    pin_memory=<span class=\"keyword\">True</span>,\n    persistent_workers=<span class=\"keyword\">True</span>,\n)\nvalid_loader = DataLoader(\n    valid_ds, batch_size=BATCH_SIZE * <span class=\"number\">2</span>, num_workers=<span class=\"number\">4</span>, pin_memory=<span class=\"keyword\">True</span>\n)\n\n<span class=\"comment\"># Efficient model with AMP</span>\nmodel = timm.create_model(\n    <span class=\"string\">&quot;</span><span class=\"string\">tf_efficientnet_b4</span><span class=\"string\">&quot;</span>, pretrained=<span class=\"keyword\">True</span>, num_classes=NUM_CLASSES\n)\nmodel = model.cuda()\noptimizer = optim.AdamW(model.parameters(), lr=LR)\ncriterion = nn.BCEWithLogitsLoss()\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, <span class=\"string\">&quot;</span><span class=\"string\">max</span><span class=\"string\">&quot;</span>, patience=<span class=\"number\">1</span>)\nscaler = torch.cuda.amp.GradScaler()\n\n<span class=\"comment\"># Training loop with early stopping</span>\nbest_f1 = <span class=\"number\">0</span>\nno_improve = <span class=\"number\">0</span>\n<span class=\"keyword\">for</span> epoch in range(EPOCHS):\n    model.train()\n    train_loss = <span class=\"number\">0</span>\n    pbar = tqdm(train_loader, desc=<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n    <span class=\"keyword\">for</span> images, labels in pbar:\n        images, labels = images.cuda(), labels.cuda()\n\n        <span class=\"keyword\">with</span> torch.cuda.amp.autocast():\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n\n        train_loss += loss.item()\n        pbar.set_postfix(loss=loss.item())\n\n    <span class=\"comment\"># Validation</span>\n    model.eval()\n    valid_preds = []\n    valid_true = []\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> images, labels in valid_loader:\n            images = images.cuda()\n            outputs = torch.sigmoid(model(images)).cpu().numpy()\n            valid_preds.append(outputs)\n            valid_true.append(labels.numpy())\n\n    valid_preds = (np.concatenate(valid_preds) &gt; THRESHOLD).astype(int)\n    valid_true = np.concatenate(valid_true)\n    micro_f1 = f1_score(valid_true, valid_preds, average=<span class=\"string\">&quot;</span><span class=\"string\">micro</span><span class=\"string\">&quot;</span>)\n\n    print(\n        <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\"> | Train Loss: </span><span class=\"string\">{</span>train_loss/len(train_loader)<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\"> | Val F1: </span><span class=\"string\">{</span>micro_f1<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>\n    )\n\n    scheduler.step(micro_f1)\n\n    <span class=\"keyword\">if</span> micro_f1 &gt; best_f1:\n        best_f1 = micro_f1\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">./working/best_model.pth</span><span class=\"string\">&quot;</span>)\n        no_improve = <span class=\"number\">0</span>\n    <span class=\"keyword\">else</span>:\n        no_improve += <span class=\"number\">1</span>\n        <span class=\"keyword\">if</span> no_improve &gt;= PATIENCE:\n            print(<span class=\"string\">&quot;</span><span class=\"string\">Early stopping</span><span class=\"string\">&quot;</span>)\n            <span class=\"keyword\">break</span>\n\n<span class=\"comment\"># Test inference</span>\ntest_files = [f[:-<span class=\"number\">4</span>] <span class=\"keyword\">for</span> f in os.listdir(<span class=\"string\">&quot;</span><span class=\"string\">./input/test</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">if</span> f.endswith(<span class=\"string\">&quot;</span><span class=\"string\">.png</span><span class=\"string\">&quot;</span>)]\ntest_df = pd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>: test_files})\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">TestDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, root_dir, transform=<span class=\"keyword\">None</span>):\n        self.df = df\n        self.root_dir = root_dir\n        self.transform = transform\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.df)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        img_path = os.path.join(self.root_dir, self.df.iloc[idx][<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>] + <span class=\"string\">&quot;</span><span class=\"string\">.png</span><span class=\"string\">&quot;</span>)\n        image = Image.open(img_path).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">if</span> self.transform:\n            image = self.transform(image)\n        <span class=\"keyword\">return</span> image\n\n\ntest_ds = TestDataset(test_df, <span class=\"string\">&quot;</span><span class=\"string\">./input/test</span><span class=\"string\">&quot;</span>, val_transform)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE * <span class=\"number\">2</span>, num_workers=<span class=\"number\">4</span>)\n\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">./working/best_model.pth</span><span class=\"string\">&quot;</span>))\nmodel.eval()\n\npreds = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> images in tqdm(test_loader):\n        images = images.cuda()\n        outputs = torch.sigmoid(model(images)).cpu().numpy()\n        preds.append(outputs)\n\npreds = np.concatenate(preds)\npred_labels = []\n<span class=\"keyword\">for</span> p in preds:\n    indices = np.where(p &gt; THRESHOLD)[<span class=\"number\">0</span>]\n    labels = [all_labels[i] <span class=\"keyword\">for</span> i in indices]\n    pred_labels.append(<span class=\"string\">&quot;</span><span class=\"string\"> </span><span class=\"string\">&quot;</span>.join(map(str, labels)))\n\nsubmission = pd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>: test_df[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>], <span class=\"string\">&quot;</span><span class=\"string\">attribute_ids</span><span class=\"string\">&quot;</span>: pred_labels})\nsubmission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">./submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\n\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Final Validation Micro F1: </span><span class=\"string\">{</span>best_f1<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n"
}
{
    "title": "hotel-id-2021-fgvc8",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task hotel-id-2021-fgvc8 --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"hotel-id-2021-fgvc8\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, models\n<span class=\"keyword\">from</span> torchvision.models <span class=\"keyword\">import</span> efficientnet_b4, EfficientNet_B4_Weights\n<span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image\n<span class=\"keyword\">import</span> os\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">import</span> faiss\n<span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm\n\n<span class=\"comment\"># Prepare data with hotel filtering</span>\noriginal_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/train.csv</span><span class=\"string\">&quot;</span>)\noriginal_df[<span class=\"string\">&quot;</span><span class=\"string\">image_path</span><span class=\"string\">&quot;</span>] = original_df.apply(\n    <span class=\"keyword\">lambda</span> r: <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">input/train_images/</span><span class=\"string\">{</span>r.chain<span class=\"string\">}</span><span class=\"string\">/</span><span class=\"string\">{</span>r.image<span class=\"string\">}</span><span class=\"string\">&quot;</span>, axis=<span class=\"number\">1</span>\n)\n\ncounts = original_df[<span class=\"string\">&quot;</span><span class=\"string\">hotel_id</span><span class=\"string\">&quot;</span>].value_counts()\nvalid_hotels = counts[counts &gt;= <span class=\"number\">2</span>].index\ndf_filtered = original_df[original_df[<span class=\"string\">&quot;</span><span class=\"string\">hotel_id</span><span class=\"string\">&quot;</span>].isin(valid_hotels)].copy()\n\nhotel_ids = df_filtered[<span class=\"string\">&quot;</span><span class=\"string\">hotel_id</span><span class=\"string\">&quot;</span>].unique()\nhotel_id_to_idx = {hid: idx <span class=\"keyword\">for</span> idx, hid in enumerate(hotel_ids)}\nidx_to_hotel = {v: k <span class=\"keyword\">for</span> k, v in hotel_id_to_idx.items()}\ndf_filtered[<span class=\"string\">&quot;</span><span class=\"string\">hotel_idx</span><span class=\"string\">&quot;</span>] = df_filtered[<span class=\"string\">&quot;</span><span class=\"string\">hotel_id</span><span class=\"string\">&quot;</span>].map(hotel_id_to_idx)\n\ntrain_df, val_df = train_test_split(\n    df_filtered, test_size=<span class=\"number\">0.2</span>, stratify=df_filtered[<span class=\"string\">&quot;</span><span class=\"string\">hotel_idx</span><span class=\"string\">&quot;</span>], random_state=<span class=\"number\">42</span>\n)\n\n<span class=\"comment\"># Enhanced transforms with augmentation</span>\ntrain_transform = transforms.Compose(\n    [\n        transforms.RandomResizedCrop(<span class=\"number\">224</span>, scale=(<span class=\"number\">0.6</span>, <span class=\"number\">1.0</span>)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ColorJitter(<span class=\"number\">0.3</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.1</span>),\n        transforms.RandomRotation(<span class=\"number\">15</span>),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], std=[<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\nval_transform = transforms.Compose(\n    [\n        transforms.Resize(<span class=\"number\">256</span>),\n        transforms.CenterCrop(<span class=\"number\">224</span>),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], std=[<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">HotelDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, transform=<span class=\"keyword\">None</span>):\n        self.df = df\n        self.transform = transform\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.df)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(row[<span class=\"string\">&quot;</span><span class=\"string\">image_path</span><span class=\"string\">&quot;</span>]).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">if</span> self.transform:\n            img = self.transform(img)\n        <span class=\"keyword\">return</span> img, row[<span class=\"string\">&quot;</span><span class=\"string\">hotel_idx</span><span class=\"string\">&quot;</span>]\n\n\ntrain_loader = DataLoader(\n    HotelDataset(train_df, train_transform),\n    batch_size=<span class=\"number\">32</span>,\n    shuffle=<span class=\"keyword\">True</span>,\n    num_workers=<span class=\"number\">8</span>,\n    pin_memory=<span class=\"keyword\">True</span>,\n)\nval_loader = DataLoader(\n    HotelDataset(val_df, val_transform),\n    batch_size=<span class=\"number\">64</span>,\n    shuffle=<span class=\"keyword\">False</span>,\n    num_workers=<span class=\"number\">8</span>,\n    pin_memory=<span class=\"keyword\">True</span>,\n)\n\nmodel = efficientnet_b4(weights=EfficientNet_B4_Weights.IMAGENET1K_V1)\nmodel.classifier = nn.Linear(model.classifier[<span class=\"number\">1</span>].in_features, len(hotel_ids))\nmodel = model.cuda()\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=<span class=\"number\">0.1</span>)\noptimizer = optim.AdamW(model.parameters(), lr=<span class=\"number\">1e-4</span>, weight_decay=<span class=\"number\">1e-5</span>)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, <span class=\"string\">&quot;</span><span class=\"string\">max</span><span class=\"string\">&quot;</span>, patience=<span class=\"number\">2</span>, factor=<span class=\"number\">0.5</span>\n)\n\nbest_map = <span class=\"number\">0</span>\n<span class=\"keyword\">for</span> epoch in range(<span class=\"number\">5</span>):  <span class=\"comment\"># Increased epochs</span>\n    model.train()\n    <span class=\"keyword\">for</span> imgs, labels in tqdm(train_loader, desc=<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>):\n        imgs, labels = imgs.cuda(), labels.cuda()\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n    model.eval()\n    all_preds, all_true = [], []\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> imgs, labels in val_loader:\n            outputs = model(imgs.cuda())\n            probs = torch.softmax(outputs, <span class=\"number\">1</span>)\n            _, top5 = torch.topk(probs, <span class=\"number\">5</span>, dim=<span class=\"number\">1</span>)\n            all_preds.extend(\n                [[idx_to_hotel[i.item()] <span class=\"keyword\">for</span> i in row] <span class=\"keyword\">for</span> row in top5.cpu()]\n            )\n            all_true.extend(labels.tolist())\n\n    map_sum = <span class=\"number\">0</span>\n    <span class=\"keyword\">for</span> true_idx, pred in zip(all_true, all_preds):\n        true_hid = idx_to_hotel[true_idx]\n        <span class=\"keyword\">for</span> k, p in enumerate(pred[:<span class=\"number\">5</span>], <span class=\"number\">1</span>):\n            <span class=\"keyword\">if</span> p == true_hid:\n                map_sum += <span class=\"number\">1</span> / k\n                <span class=\"keyword\">break</span>\n    val_map = map_sum / len(all_true)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Val MAP@5: </span><span class=\"string\">{</span>val_map<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n    <span class=\"keyword\">if</span> val_map &gt; best_map:\n        best_map = val_map\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>)\n    scheduler.step(val_map)\n\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Best Validation MAP@5: </span><span class=\"string\">{</span>best_map<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Generate submission</span>\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>))\nmodel.eval()\nembedding_model = nn.Sequential(model.features, model.avgpool, nn.Flatten()).cuda()\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">EmbeddingDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, transform=<span class=\"keyword\">None</span>):\n        self.df = df\n        self.transform = transform\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.df)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(row[<span class=\"string\">&quot;</span><span class=\"string\">image_path</span><span class=\"string\">&quot;</span>]).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">if</span> self.transform:\n            img = self.transform(img)\n        <span class=\"keyword\">return</span> img\n\n\n<span class=\"comment\"># Generate embeddings with validation transform</span>\ntrain_embeddings = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> imgs in tqdm(\n        DataLoader(\n            EmbeddingDataset(original_df, val_transform), batch_size=<span class=\"number\">128</span>, num_workers=<span class=\"number\">8</span>\n        ),\n        desc=<span class=\"string\">&quot;</span><span class=\"string\">Embedding</span><span class=\"string\">&quot;</span>,\n    ):\n        train_embeddings.append(embedding_model(imgs.cuda()).cpu().numpy())\ntrain_embeddings = np.concatenate(train_embeddings)\nhotel_ids_all = original_df[<span class=\"string\">&quot;</span><span class=\"string\">hotel_id</span><span class=\"string\">&quot;</span>].values\n\nindex = faiss.IndexFlatIP(train_embeddings.shape[<span class=\"number\">1</span>])\nfaiss.normalize_L2(train_embeddings)\nindex.add(train_embeddings)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">TestDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, img_dir, transform=<span class=\"keyword\">None</span>):\n        self.img_paths = [\n            os.path.join(img_dir, f) <span class=\"keyword\">for</span> f in os.listdir(img_dir) <span class=\"keyword\">if</span> f.endswith(<span class=\"string\">&quot;</span><span class=\"string\">.jpg</span><span class=\"string\">&quot;</span>)\n        ]\n        self.transform = transform\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.img_paths)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        img = Image.open(self.img_paths[idx]).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">if</span> self.transform:\n            img = self.transform(img)\n        <span class=\"keyword\">return</span> img, os.path.basename(self.img_paths[idx])\n\n\ntest_dataset = TestDataset(<span class=\"string\">&quot;</span><span class=\"string\">input/test_images</span><span class=\"string\">&quot;</span>, val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=<span class=\"number\">128</span>, num_workers=<span class=\"number\">8</span>)\n\ntest_embeddings, test_names = [], []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> imgs, names in tqdm(test_loader, desc=<span class=\"string\">&quot;</span><span class=\"string\">Testing</span><span class=\"string\">&quot;</span>):\n        test_embeddings.append(embedding_model(imgs.cuda()).cpu().numpy())\n        test_names.extend(names)\ntest_embeddings = np.concatenate(test_embeddings)\nfaiss.normalize_L2(test_embeddings)\n\nD, I = index.search(test_embeddings, <span class=\"number\">100</span>)\nsubmission = []\n<span class=\"keyword\">for</span> name, neighbors in zip(test_names, I):\n    seen = set()\n    preds = []\n    <span class=\"keyword\">for</span> idx in neighbors:\n        hid = hotel_ids_all[idx]\n        <span class=\"keyword\">if</span> hid not in seen:\n            preds.append(str(hid))\n            seen.add(hid)\n            <span class=\"keyword\">if</span> len(preds) == <span class=\"number\">5</span>:\n                <span class=\"keyword\">break</span>\n    submission.append([name, <span class=\"string\">&quot;</span><span class=\"string\"> </span><span class=\"string\">&quot;</span>.join(preds)])\n\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\npd.DataFrame(submission, columns=[<span class=\"string\">&quot;</span><span class=\"string\">image</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">hotel_id</span><span class=\"string\">&quot;</span>]).to_csv(\n    <span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>\n)\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Submission saved with </span><span class=\"string\">{</span>len(submission)<span class=\"string\">}</span><span class=\"string\"> predictions</span><span class=\"string\">&quot;</span>)\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Final Validation MAP@5: </span><span class=\"string\">{</span>best_map<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n"
}
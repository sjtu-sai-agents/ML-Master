{
    "title": "cdiscount-image-classification-challenge",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task cdiscount-image-classification-challenge --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"cdiscount-image-classification-challenge\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> bson\n<span class=\"keyword\">import</span> io\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image\n<span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim\n<span class=\"keyword\">from</span> torchvision.models <span class=\"keyword\">import</span> resnet50\n\n<span class=\"comment\"># Configuration</span>\nBATCH_SIZE = <span class=\"number\">256</span>\nFEATURE_DIM = <span class=\"number\">2048</span>\nDEVICE = <span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>\n\n<span class=\"comment\"># Feature extraction model</span>\nfeature_extractor = resnet50(pretrained=<span class=\"keyword\">True</span>)\nfeature_extractor = nn.Sequential(*list(feature_extractor.children())[:-<span class=\"number\">1</span>])\nfeature_extractor.eval().to(DEVICE)\n\n<span class=\"comment\"># Image preprocessing</span>\ntransform = transforms.Compose(\n    [\n        transforms.Resize((<span class=\"number\">224</span>, <span class=\"number\">224</span>)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], std=[<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">process_bson</span>(bson_path, is_train=<span class=\"keyword\">True</span>):\n    features, labels, ids = [], [], []\n    <span class=\"keyword\">with</span> open(bson_path, <span class=\"string\">&quot;</span><span class=\"string\">rb</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">as</span> f:\n        data = bson.decode_file_iter(f)\n        batch_images, batch_info = [], []\n\n        <span class=\"keyword\">for</span> idx, item in enumerate(data):\n            img = Image.open(io.BytesIO(item[<span class=\"string\">&quot;</span><span class=\"string\">imgs</span><span class=\"string\">&quot;</span>][<span class=\"number\">0</span>][<span class=\"string\">&quot;</span><span class=\"string\">picture</span><span class=\"string\">&quot;</span>]))\n            img = transform(img).unsqueeze(<span class=\"number\">0</span>)\n            batch_images.append(img)\n\n            <span class=\"keyword\">if</span> is_train:\n                batch_info.append(item[<span class=\"string\">&quot;</span><span class=\"string\">category_id</span><span class=\"string\">&quot;</span>])\n            <span class=\"keyword\">else</span>:\n                batch_info.append(item[<span class=\"string\">&quot;</span><span class=\"string\">_id</span><span class=\"string\">&quot;</span>])\n\n            <span class=\"keyword\">if</span> len(batch_images) == BATCH_SIZE or (idx + <span class=\"number\">1</span>) % <span class=\"number\">100000</span> == <span class=\"number\">0</span>:\n                <span class=\"keyword\">with</span> torch.no_grad():\n                    features_batch = (\n                        feature_extractor(torch.cat(batch_images).to(DEVICE))\n                        .squeeze()\n                        .cpu()\n                        .numpy()\n                    )\n\n                <span class=\"comment\"># Ensure 2D shape</span>\n                features_batch = features_batch.reshape(-<span class=\"number\">1</span>, FEATURE_DIM)\n                features.append(features_batch)\n                batch_images = []\n\n                <span class=\"keyword\">if</span> is_train:\n                    labels.extend(batch_info)\n                <span class=\"keyword\">else</span>:\n                    ids.extend(batch_info)\n                batch_info = []\n\n        <span class=\"keyword\">if</span> batch_images:\n            <span class=\"keyword\">with</span> torch.no_grad():\n                features_batch = (\n                    feature_extractor(torch.cat(batch_images).to(DEVICE))\n                    .squeeze()\n                    .cpu()\n                    .numpy()\n                )\n\n            features_batch = features_batch.reshape(-<span class=\"number\">1</span>, FEATURE_DIM)\n            features.append(features_batch)\n            <span class=\"keyword\">if</span> is_train:\n                labels.extend(batch_info)\n            <span class=\"keyword\">else</span>:\n                ids.extend(batch_info)\n\n    <span class=\"keyword\">return</span> (np.concatenate(features), np.array(labels) <span class=\"keyword\">if</span> is_train <span class=\"keyword\">else</span> np.array(ids))\n\n\n<span class=\"comment\"># Process training data</span>\nprint(<span class=\"string\">&quot;</span><span class=\"string\">Processing training data...</span><span class=\"string\">&quot;</span>)\ntrain_features, train_labels = process_bson(<span class=\"string\">&quot;</span><span class=\"string\">input/train.bson</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Create label mapping</span>\nunique_categories = np.unique(train_labels)\nNUM_CLASSES = len(unique_categories)\nlabel_to_idx = {cat: idx <span class=\"keyword\">for</span> idx, cat in enumerate(unique_categories)}\ntrain_labels_indices = np.array([label_to_idx[cat] <span class=\"keyword\">for</span> cat in train_labels])\n\n<span class=\"comment\"># Split validation set</span>\nval_size = int(<span class=\"number\">0.1</span> * len(train_labels_indices))\nrand_idx = np.random.permutation(len(train_labels_indices))\nval_features = train_features[rand_idx[:val_size]]\nval_labels = train_labels_indices[rand_idx[:val_size]]\ntrain_features_split = train_features[rand_idx[val_size:]]\ntrain_labels_split = train_labels_indices[rand_idx[val_size:]]\n\n<span class=\"comment\"># Define classifier</span>\nclassifier = nn.Linear(FEATURE_DIM, NUM_CLASSES).to(DEVICE)\noptimizer = optim.Adam(classifier.parameters(), lr=<span class=\"number\">0.001</span>)\ncriterion = nn.CrossEntropyLoss()\n\n<span class=\"comment\"># Create data loaders</span>\ntrain_loader = DataLoader(\n    list(\n        zip(\n            torch.FloatTensor(train_features_split),\n            torch.LongTensor(train_labels_split),\n        )\n    ),\n    batch_size=<span class=\"number\">1024</span>,\n    shuffle=<span class=\"keyword\">True</span>,\n    num_workers=<span class=\"number\">4</span>,\n)\nval_loader = DataLoader(\n    list(zip(torch.FloatTensor(val_features), torch.LongTensor(val_labels))),\n    batch_size=<span class=\"number\">1024</span>,\n    num_workers=<span class=\"number\">4</span>,\n)\n\n<span class=\"comment\"># Train classifier</span>\nprint(<span class=\"string\">&quot;</span><span class=\"string\">Training classifier...</span><span class=\"string\">&quot;</span>)\nbest_acc = <span class=\"number\">0.0</span>\n<span class=\"keyword\">for</span> epoch in range(<span class=\"number\">5</span>):\n    classifier.train()\n    <span class=\"keyword\">for</span> X, y in train_loader:\n        X, y = X.to(DEVICE), y.to(DEVICE)\n        optimizer.zero_grad()\n        loss = criterion(classifier(X), y)\n        loss.backward()\n        optimizer.step()\n\n    <span class=\"comment\"># Validate</span>\n    classifier.eval()\n    correct, total = <span class=\"number\">0</span>, <span class=\"number\">0</span>\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> X, y in val_loader:\n            X, y = X.to(DEVICE), y.to(DEVICE)\n            outputs = classifier(X)\n            _, predicted = torch.max(outputs, <span class=\"number\">1</span>)\n            correct += (predicted == y).sum().item()\n            total += y.size(<span class=\"number\">0</span>)\n    val_acc = correct / total\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">: Val Acc = </span><span class=\"string\">{</span>val_acc<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n    <span class=\"keyword\">if</span> val_acc &gt; best_acc:\n        best_acc = val_acc\n        torch.save(classifier.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">working/best_model.pth</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Load best model</span>\nclassifier.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">working/best_model.pth</span><span class=\"string\">&quot;</span>))\n\n<span class=\"comment\"># Process test data</span>\nprint(<span class=\"string\">&quot;</span><span class=\"string\">Processing test data...</span><span class=\"string\">&quot;</span>)\ntest_features, test_ids = process_bson(<span class=\"string\">&quot;</span><span class=\"string\">input/test.bson</span><span class=\"string\">&quot;</span>, is_train=<span class=\"keyword\">False</span>)\n\n<span class=\"comment\"># Generate predictions</span>\nclassifier.eval()\ntest_tensor = torch.FloatTensor(test_features).to(DEVICE)\n<span class=\"keyword\">with</span> torch.no_grad():\n    test_preds = classifier(test_tensor).argmax(dim=<span class=\"number\">1</span>).cpu().numpy()\n\n<span class=\"comment\"># Map predictions to original category IDs</span>\nidx_to_label = {v: k <span class=\"keyword\">for</span> k, v in label_to_idx.items()}\ntest_preds_labels = [idx_to_label[idx] <span class=\"keyword\">for</span> idx in test_preds]\n\n<span class=\"comment\"># Create submission</span>\nsubmission = pd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">_id</span><span class=\"string\">&quot;</span>: test_ids, <span class=\"string\">&quot;</span><span class=\"string\">category_id</span><span class=\"string\">&quot;</span>: test_preds_labels})\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\nsubmission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Best Validation Accuracy: </span><span class=\"string\">{</span>best_acc<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\nprint(<span class=\"string\">&quot;</span><span class=\"string\">Submission file created successfully!</span><span class=\"string\">&quot;</span>)\n"
}
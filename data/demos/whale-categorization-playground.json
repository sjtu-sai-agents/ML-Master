{
    "title": "whale-categorization-playground",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task whale-categorization-playground --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"whale-categorization-playground\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> math\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms\n<span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> GroupShuffleSplit\n<span class=\"keyword\">import</span> timm\n<span class=\"keyword\">import</span> faiss\n\ntorch.manual_seed(<span class=\"number\">42</span>)\nnp.random.seed(<span class=\"number\">42</span>)\n\n<span class=\"comment\"># Data preparation with GroupShuffleSplit</span>\ntrain_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/train.csv</span><span class=\"string\">&quot;</span>)\ntrain_df[<span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>] = train_df[<span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>].astype(str)\n\ncounts = train_df[<span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>].value_counts()\nsingle_sample = counts[counts == <span class=\"number\">1</span>].index\nmulti_sample = counts[counts &gt; <span class=\"number\">1</span>].index\n\ndf_multi = train_df[train_df[<span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>].isin(multi_sample)]\ndf_single = train_df[train_df[<span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>].isin(single_sample)]\n\n<span class=\"comment\"># Split df_multi using group split on IDs</span>\nsplitter = GroupShuffleSplit(n_splits=<span class=\"number\">1</span>, test_size=<span class=\"number\">0.2</span>, random_state=<span class=\"number\">42</span>)\ntrain_idx, val_idx = next(splitter.split(df_multi, groups=df_multi[<span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>]))\ntrain_multi = df_multi.iloc[train_idx]\nval_data = df_multi.iloc[val_idx]\n\ntrain_data = pd.concat([train_multi, df_single])\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">WhaleDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, img_dir, transform=<span class=\"keyword\">None</span>):\n        self.df = df.reset_index(drop=<span class=\"keyword\">True</span>)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.classes = df[<span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>].unique()\n        self.class_to_idx = {cls: idx <span class=\"keyword\">for</span> idx, cls in enumerate(self.classes)}\n        self.labels = [self.class_to_idx[cls] <span class=\"keyword\">for</span> cls in df[<span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>]]\n        self.idx_to_class = {v: k <span class=\"keyword\">for</span> k, v in self.class_to_idx.items()}\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.df)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        img_name = self.df.iloc[idx][<span class=\"string\">&quot;</span><span class=\"string\">Image</span><span class=\"string\">&quot;</span>]\n        image = Image.open(os.path.join(self.img_dir, img_name)).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        label = self.labels[idx]\n        <span class=\"keyword\">if</span> self.transform:\n            image = self.transform(image)\n        <span class=\"keyword\">return</span> image, label\n\n\ntrain_transform = transforms.Compose(\n    [\n        transforms.Resize((<span class=\"number\">256</span>, <span class=\"number\">256</span>)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(<span class=\"number\">15</span>),\n        transforms.ToTensor(),\n        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\nval_transform = transforms.Compose(\n    [\n        transforms.Resize((<span class=\"number\">256</span>, <span class=\"number\">256</span>)),\n        transforms.ToTensor(),\n        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\ntrain_dataset = WhaleDataset(train_data, <span class=\"string\">&quot;</span><span class=\"string\">./input/train/</span><span class=\"string\">&quot;</span>, train_transform)\ntrain_loader = DataLoader(train_dataset, <span class=\"number\">32</span>, <span class=\"keyword\">True</span>, num_workers=<span class=\"number\">4</span>)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">ArcMarginProduct</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, in_features, out_features, s=<span class=\"number\">30</span>, m=<span class=\"number\">0.5</span>):\n        super().<span class=\"function\">__init__</span>()\n        self.s = s\n        self.m = m\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, embeddings, labels):\n        cosine = F.linear(F.normalize(embeddings), F.normalize(self.weight))\n        sine = torch.sqrt(<span class=\"number\">1.0</span> - torch.pow(cosine, <span class=\"number\">2</span>))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        phi = torch.where(cosine &gt; self.th, phi, cosine - self.mm)\n        one_hot = torch.zeros_like(cosine)\n        one_hot.scatter_(<span class=\"number\">1</span>, labels.view(-<span class=\"number\">1</span>, <span class=\"number\">1</span>), <span class=\"number\">1</span>)\n        <span class=\"keyword\">return</span> self.s * (one_hot * phi + (<span class=\"number\">1</span> - one_hot) * cosine)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">WhaleModel</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, num_classes):\n        super().<span class=\"function\">__init__</span>()\n        self.backbone = timm.create_model(\n            <span class=\"string\">&quot;</span><span class=\"string\">efficientnet_b4</span><span class=\"string\">&quot;</span>, pretrained=<span class=\"keyword\">True</span>, num_classes=<span class=\"number\">0</span>\n        )\n        self.embedding = nn.Linear(self.backbone.num_features, <span class=\"number\">512</span>)\n        self.arcface = ArcMarginProduct(<span class=\"number\">512</span>, num_classes)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, x, labels=<span class=\"keyword\">None</span>):\n        features = self.backbone(x)\n        embeddings = self.embedding(features)\n        <span class=\"keyword\">return</span> self.arcface(embeddings, labels) <span class=\"keyword\">if</span> labels is not <span class=\"keyword\">None</span> <span class=\"keyword\">else</span> embeddings\n\n\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\nmodel = WhaleModel(len(train_dataset.classes)).to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=<span class=\"number\">1e-4</span>)\ncriterion = nn.CrossEntropyLoss()\n\n<span class=\"comment\"># Training loop</span>\n<span class=\"keyword\">for</span> epoch in range(<span class=\"number\">10</span>):\n    model.train()\n    <span class=\"keyword\">for</span> images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        loss = criterion(model(images, labels), labels)\n        loss.backward()\n        optimizer.step()\n\n<span class=\"comment\"># Generate training embeddings for validation</span>\nmodel.eval()\ntrain_embeddings, train_labels = [], []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> images, labels in DataLoader(train_dataset, <span class=\"number\">32</span>, num_workers=<span class=\"number\">4</span>):\n        embeddings = model(images.to(device)).cpu().numpy()\n        train_embeddings.append(embeddings)\n        train_labels.extend([train_dataset.idx_to_class[l] <span class=\"keyword\">for</span> l in labels.numpy()])\ntrain_embeddings = np.concatenate(train_embeddings)\nfaiss.normalize_L2(train_embeddings)\nindex = faiss.IndexFlatIP(<span class=\"number\">512</span>)\nindex.add(train_embeddings)\n\n<span class=\"comment\"># Validation with FAISS search</span>\nval_dataset = WhaleDataset(val_data, <span class=\"string\">&quot;</span><span class=\"string\">./input/train/</span><span class=\"string\">&quot;</span>, val_transform)\nval_loader = DataLoader(val_dataset, <span class=\"number\">32</span>, num_workers=<span class=\"number\">4</span>)\n\nmap5 = <span class=\"number\">0.0</span>\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> images, labels in val_loader:\n        images = images.to(device)\n        embeddings = model(images).cpu().numpy()\n        faiss.normalize_L2(embeddings)\n        _, I = index.search(embeddings, <span class=\"number\">50</span>)\n        <span class=\"keyword\">for</span> i in range(len(images)):\n            candidates = [train_labels[idx] <span class=\"keyword\">for</span> idx in I[i]]\n            counts = {}\n            <span class=\"keyword\">for</span> c in candidates:\n                counts[c] = counts.get(c, <span class=\"number\">0</span>) + <span class=\"number\">1</span>\n            preds = sorted(counts, key=<span class=\"keyword\">lambda</span> x: (-counts[x], x))[:<span class=\"number\">5</span>]\n            preds += [<span class=\"string\">&quot;</span><span class=\"string\">new_whale</span><span class=\"string\">&quot;</span>] * (<span class=\"number\">5</span> - len(preds))\n            <span class=\"comment\"># All val IDs are unseen, correct answer is &#x27;new_whale&#x27;</span>\n            <span class=\"keyword\">try</span>:\n                pos = preds.index(<span class=\"string\">&quot;</span><span class=\"string\">new_whale</span><span class=\"string\">&quot;</span>) + <span class=\"number\">1</span>\n                map5 += <span class=\"number\">1</span> / pos\n            <span class=\"keyword\">except</span>:\n                <span class=\"keyword\">pass</span>\nmap5 /= len(val_dataset)\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Validation MAP@5: </span><span class=\"string\">{</span>map5<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Generate submission</span>\ntest_dir = <span class=\"string\">&quot;</span><span class=\"string\">./input/test/</span><span class=\"string\">&quot;</span>\nsubmission = []\ntest_transform = val_transform\n<span class=\"keyword\">for</span> img_name in os.listdir(test_dir):\n    img_path = os.path.join(test_dir, img_name)\n    image = Image.open(img_path).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n    image = test_transform(image).unsqueeze(<span class=\"number\">0</span>).to(device)\n    <span class=\"keyword\">with</span> torch.no_grad():\n        embedding = model(image).cpu().numpy()\n    faiss.normalize_L2(embedding)\n    _, I = index.search(embedding, <span class=\"number\">50</span>)\n    candidates = [train_labels[i] <span class=\"keyword\">for</span> i in I[<span class=\"number\">0</span>]]\n    counts = {}\n    <span class=\"keyword\">for</span> c in candidates:\n        counts[c] = counts.get(c, <span class=\"number\">0</span>) + <span class=\"number\">1</span>\n    preds = sorted(counts, key=<span class=\"keyword\">lambda</span> x: (-counts[x], x))[:<span class=\"number\">5</span>]\n    preds += [<span class=\"string\">&quot;</span><span class=\"string\">new_whale</span><span class=\"string\">&quot;</span>] * (<span class=\"number\">5</span> - len(preds))\n    submission.append([img_name, <span class=\"string\">&quot;</span><span class=\"string\"> </span><span class=\"string\">&quot;</span>.join(preds[:<span class=\"number\">5</span>])])\n\npd.DataFrame(submission, columns=[<span class=\"string\">&quot;</span><span class=\"string\">Image</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>]).to_csv(\n    <span class=\"string\">&quot;</span><span class=\"string\">./submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>\n)\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Submission saved. Final Val MAP@5: </span><span class=\"string\">{</span>map5<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n"
}
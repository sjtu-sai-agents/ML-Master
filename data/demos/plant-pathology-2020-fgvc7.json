{
    "title": "plant-pathology-2020-fgvc7",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task plant-pathology-2020-fgvc7 --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"plant-pathology-2020-fgvc7\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> roc_auc_score\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn, optim\n<span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader, Dataset\n<span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, models\n<span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image\n<span class=\"keyword\">from</span> torch.cuda.amp <span class=\"keyword\">import</span> autocast, GradScaler\n<span class=\"keyword\">import</span> warnings\n\nwarnings.filterwarnings(<span class=\"string\">&quot;</span><span class=\"string\">ignore</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Configuration</span>\nBATCH_SIZE = <span class=\"number\">16</span>\nIMG_SIZE = <span class=\"number\">480</span>\nEPOCHS = <span class=\"number\">20</span>\nSEED = <span class=\"number\">42</span>\ntorch.manual_seed(SEED)\n\n<span class=\"comment\"># Data preparation</span>\ntrain_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/train.csv</span><span class=\"string\">&quot;</span>)\ntrain_df[<span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>] = train_df[\n    [<span class=\"string\">&quot;</span><span class=\"string\">healthy</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">multiple_diseases</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">rust</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">scab</span><span class=\"string\">&quot;</span>]\n].values.argmax(axis=<span class=\"number\">1</span>)\n\n<span class=\"comment\"># Calculate class weights for Focal Loss</span>\nclass_counts = train_df[<span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>].value_counts().sort_index().values\nalpha = <span class=\"number\">1.0</span> / class_counts\nalpha = alpha / alpha.sum()  <span class=\"comment\"># Normalize weights</span>\n\ntrain_ids, val_ids, train_labels, val_labels = train_test_split(\n    train_df[<span class=\"string\">&quot;</span><span class=\"string\">image_id</span><span class=\"string\">&quot;</span>],\n    train_df[<span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>],\n    test_size=<span class=\"number\">0.15</span>,\n    stratify=train_df[<span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>],\n    random_state=SEED,\n)\n\n<span class=\"comment\"># Enhanced augmentations</span>\ntrain_transform = transforms.Compose(\n    [\n        transforms.RandomResizedCrop(IMG_SIZE, scale=(<span class=\"number\">0.7</span>, <span class=\"number\">1.0</span>)),\n        transforms.RandomHorizontalFlip(p=<span class=\"number\">0.5</span>),\n        transforms.RandomVerticalFlip(p=<span class=\"number\">0.5</span>),\n        transforms.RandomRotation(<span class=\"number\">45</span>),\n        transforms.ColorJitter(brightness=<span class=\"number\">0.3</span>, contrast=<span class=\"number\">0.3</span>, saturation=<span class=\"number\">0.3</span>, hue=<span class=\"number\">0.1</span>),\n        transforms.GaussianBlur(kernel_size=<span class=\"number\">5</span>, sigma=(<span class=\"number\">0.1</span>, <span class=\"number\">2.0</span>)),\n        transforms.ToTensor(),\n        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\nval_transform = transforms.Compose(\n    [\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">PlantDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, image_ids, labels, img_dir, transform=<span class=\"keyword\">None</span>):\n        self.image_ids = image_ids\n        self.labels = labels\n        self.img_dir = img_dir\n        self.transform = transform\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.image_ids)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        img_path = os.path.join(self.img_dir, <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">{</span>self.image_ids.iloc[idx]<span class=\"string\">}</span><span class=\"string\">.jpg</span><span class=\"string\">&quot;</span>)\n        image = Image.open(img_path).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        label = self.labels.iloc[idx]\n        <span class=\"keyword\">if</span> self.transform:\n            image = self.transform(image)\n        <span class=\"keyword\">return</span> image, label\n\n\n<span class=\"comment\"># Datasets and loaders</span>\ntrain_dataset = PlantDataset(train_ids, train_labels, <span class=\"string\">&quot;</span><span class=\"string\">input/images</span><span class=\"string\">&quot;</span>, train_transform)\nval_dataset = PlantDataset(val_ids, val_labels, <span class=\"string\">&quot;</span><span class=\"string\">input/images</span><span class=\"string\">&quot;</span>, val_transform)\ntrain_loader = DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">4</span>, pin_memory=<span class=\"keyword\">True</span>\n)\nval_loader = DataLoader(\n    val_dataset, batch_size=BATCH_SIZE, shuffle=<span class=\"keyword\">False</span>, num_workers=<span class=\"number\">4</span>, pin_memory=<span class=\"keyword\">True</span>\n)\n\n\n<span class=\"comment\"># Focal Loss implementation</span>\n<span class=\"keyword\">class</span> <span class=\"class\">FocalLoss</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, alpha=<span class=\"keyword\">None</span>, gamma=<span class=\"number\">2</span>, reduction=<span class=\"string\">&quot;</span><span class=\"string\">mean</span><span class=\"string\">&quot;</span>):\n        super().<span class=\"function\">__init__</span>()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction=<span class=\"string\">&quot;</span><span class=\"string\">none</span><span class=\"string\">&quot;</span>)\n        pt = torch.exp(-ce_loss)\n        focal_loss = (\n            (self.alpha[targets] <span class=\"keyword\">if</span> self.alpha is not <span class=\"keyword\">None</span> <span class=\"keyword\">else</span> <span class=\"number\">1</span>)\n            * (<span class=\"number\">1</span> - pt) ** self.gamma\n            * ce_loss\n        )\n        <span class=\"keyword\">if</span> self.reduction == <span class=\"string\">&quot;</span><span class=\"string\">mean</span><span class=\"string\">&quot;</span>:\n            <span class=\"keyword\">return</span> focal_loss.mean()\n        <span class=\"keyword\">return</span> focal_loss.sum()\n\n\n<span class=\"comment\"># Model setup</span>\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\nmodel = models.efficientnet_b7(pretrained=<span class=\"keyword\">True</span>)\nnum_ftrs = model.classifier[<span class=\"number\">1</span>].in_features\nmodel.classifier = nn.Linear(num_ftrs, <span class=\"number\">4</span>)\nmodel = model.to(device)\n\n<span class=\"comment\"># Convert alpha to tensor</span>\nalpha_tensor = torch.tensor(alpha, dtype=torch.float32).to(device)\ncriterion = FocalLoss(alpha=alpha_tensor, gamma=<span class=\"number\">2</span>)\noptimizer = optim.AdamW(model.parameters(), lr=<span class=\"number\">1e-4</span>, weight_decay=<span class=\"number\">1e-5</span>)\nscheduler = optim.lr_scheduler.OneCycleLR(\n    optimizer, max_lr=<span class=\"number\">3e-4</span>, total_steps=EPOCHS * len(train_loader)\n)\nscaler = GradScaler()\n\n<span class=\"comment\"># Training loop</span>\nbest_auc = <span class=\"number\">0.0</span>\n<span class=\"keyword\">for</span> epoch in range(EPOCHS):\n    model.train()\n    <span class=\"keyword\">for</span> batch_idx, (images, labels) in enumerate(train_loader):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        <span class=\"keyword\">with</span> autocast():\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()\n\n    <span class=\"comment\"># Validation</span>\n    model.eval()\n    val_preds, val_targets = [], []\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> images, labels in val_loader:\n            images = images.to(device)\n            outputs = model(images)\n            val_preds.append(torch.softmax(outputs, <span class=\"number\">1</span>).cpu())\n            val_targets.append(labels)\n\n    val_preds = torch.cat(val_preds).numpy()\n    val_targets = torch.cat(val_targets).numpy()\n\n    auc_scores = []\n    <span class=\"keyword\">for</span> i in range(<span class=\"number\">4</span>):\n        auc_scores.append(roc_auc_score((val_targets == i), val_preds[:, i]))\n    mean_auc = np.mean(auc_scores)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">/</span><span class=\"string\">{</span>EPOCHS<span class=\"string\">}</span><span class=\"string\"> | Val AUC: </span><span class=\"string\">{</span>mean_auc<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n    <span class=\"keyword\">if</span> mean_auc &gt; best_auc:\n        best_auc = mean_auc\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>)\n\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">\\n</span><span class=\"string\">Best Validation AUC: </span><span class=\"string\">{</span>best_auc<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># TTA Prediction</span>\ntest_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/test.csv</span><span class=\"string\">&quot;</span>)\ntest_dataset = PlantDataset(\n    test_df[<span class=\"string\">&quot;</span><span class=\"string\">image_id</span><span class=\"string\">&quot;</span>], pd.Series([<span class=\"number\">0</span>] * len(test_df)), <span class=\"string\">&quot;</span><span class=\"string\">input/images</span><span class=\"string\">&quot;</span>, val_transform\n)\ntest_loader = DataLoader(\n    test_dataset, batch_size=BATCH_SIZE, shuffle=<span class=\"keyword\">False</span>, num_workers=<span class=\"number\">4</span>, pin_memory=<span class=\"keyword\">True</span>\n)\n\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>))\nmodel.eval()\ntest_preds = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> images, _ in test_loader:\n        images = images.to(device)\n        outputs = model(images)\n        preds = torch.softmax(outputs, <span class=\"number\">1</span>)\n        h_flip = torch.flip(images, [<span class=\"number\">3</span>])\n        outputs_h = model(h_flip)\n        preds_h = torch.softmax(outputs_h, <span class=\"number\">1</span>)\n        v_flip = torch.flip(images, [<span class=\"number\">2</span>])\n        outputs_v = model(v_flip)\n        preds_v = torch.softmax(outputs_v, <span class=\"number\">1</span>)\n        avg_preds = (preds + preds_h + preds_v) / <span class=\"number\">3</span>\n        test_preds.append(avg_preds.cpu())\n\ntest_preds = torch.cat(test_preds).numpy()\nsubmission = pd.DataFrame(\n    {\n        <span class=\"string\">&quot;</span><span class=\"string\">image_id</span><span class=\"string\">&quot;</span>: test_df[<span class=\"string\">&quot;</span><span class=\"string\">image_id</span><span class=\"string\">&quot;</span>],\n        <span class=\"string\">&quot;</span><span class=\"string\">healthy</span><span class=\"string\">&quot;</span>: test_preds[:, <span class=\"number\">0</span>],\n        <span class=\"string\">&quot;</span><span class=\"string\">multiple_diseases</span><span class=\"string\">&quot;</span>: test_preds[:, <span class=\"number\">1</span>],\n        <span class=\"string\">&quot;</span><span class=\"string\">rust</span><span class=\"string\">&quot;</span>: test_preds[:, <span class=\"number\">2</span>],\n        <span class=\"string\">&quot;</span><span class=\"string\">scab</span><span class=\"string\">&quot;</span>: test_preds[:, <span class=\"number\">3</span>],\n    }\n)\nsubmission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\n"
}
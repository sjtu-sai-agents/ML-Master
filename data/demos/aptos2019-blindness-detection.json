{
    "title": "aptos2019-blindness-detection",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task aptos2019-blindness-detection --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"aptos2019-blindness-detection\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">import</span> albumentations <span class=\"keyword\">as</span> A\n<span class=\"keyword\">from</span> albumentations.pytorch <span class=\"keyword\">import</span> ToTensorV2\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> cohen_kappa_score\n<span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image\n<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> timm\n\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\nBATCH_SIZE = <span class=\"number\">32</span>\nIMG_SIZE = <span class=\"number\">512</span>\nEPOCHS = <span class=\"number\">20</span>\n\n<span class=\"comment\"># Data preparation</span>\ntrain_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/train.csv</span><span class=\"string\">&quot;</span>)\ntest_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/test.csv</span><span class=\"string\">&quot;</span>)\ntrain_df, val_df = train_test_split(\n    train_df, test_size=<span class=\"number\">0.1</span>, stratify=train_df[<span class=\"string\">&quot;</span><span class=\"string\">diagnosis</span><span class=\"string\">&quot;</span>], random_state=<span class=\"number\">42</span>\n)\n\n<span class=\"comment\"># Class weights calculation</span>\npos_weights = []\n<span class=\"keyword\">for</span> k in range(<span class=\"number\">4</span>):\n    pos = (train_df[<span class=\"string\">&quot;</span><span class=\"string\">diagnosis</span><span class=\"string\">&quot;</span>] &gt; k).sum()\n    neg = len(train_df) - pos\n    pos_weights.append(neg / (pos + <span class=\"number\">1e-7</span>))\npos_weights = torch.tensor(pos_weights, dtype=torch.float32).to(device)\n\n<span class=\"comment\"># Augmentations</span>\ntrain_transform = A.Compose(\n    [\n        A.Resize(IMG_SIZE, IMG_SIZE),\n        A.HorizontalFlip(p=<span class=\"number\">0.5</span>),\n        A.VerticalFlip(p=<span class=\"number\">0.5</span>),\n        A.RandomRotate90(p=<span class=\"number\">0.5</span>),\n        A.ShiftScaleRotate(shift_limit=<span class=\"number\">0.1</span>, scale_limit=<span class=\"number\">0.1</span>, rotate_limit=<span class=\"number\">20</span>, p=<span class=\"number\">0.5</span>),\n        A.RandomBrightnessContrast(p=<span class=\"number\">0.5</span>, brightness_limit=<span class=\"number\">0.2</span>, contrast_limit=<span class=\"number\">0.2</span>),\n        A.HueSaturationValue(\n            p=<span class=\"number\">0.5</span>, hue_shift_limit=<span class=\"number\">10</span>, sat_shift_limit=<span class=\"number\">20</span>, val_shift_limit=<span class=\"number\">10</span>\n        ),\n        A.CoarseDropout(p=<span class=\"number\">0.5</span>, max_holes=<span class=\"number\">8</span>, max_height=<span class=\"number\">32</span>, max_width=<span class=\"number\">32</span>),\n        A.Normalize(mean=[<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], std=[<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n        ToTensorV2(),\n    ]\n)\n\ntest_transform = A.Compose(\n    [\n        A.Resize(IMG_SIZE, IMG_SIZE),\n        A.Normalize(mean=[<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], std=[<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n        ToTensorV2(),\n    ]\n)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">RetinaDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, img_dir, transform=<span class=\"keyword\">None</span>, is_test=<span class=\"keyword\">False</span>):\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.df)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        img_name = <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">{</span>self.img_dir<span class=\"string\">}</span><span class=\"string\">/</span><span class=\"string\">{</span>self.df.iloc[idx][<span class=\"string\">&#x27;</span><span class=\"string\">id_code</span><span class=\"string\">&#x27;</span>]<span class=\"string\">}</span><span class=\"string\">.png</span><span class=\"string\">&quot;</span>\n        image = np.array(Image.open(img_name).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>))\n\n        <span class=\"keyword\">if</span> self.transform:\n            augmented = self.transform(image=image)\n            image = augmented[<span class=\"string\">&quot;</span><span class=\"string\">image</span><span class=\"string\">&quot;</span>]\n\n        <span class=\"keyword\">if</span> self.is_test:\n            <span class=\"keyword\">return</span> image\n\n        label = self.df.iloc[idx][<span class=\"string\">&quot;</span><span class=\"string\">diagnosis</span><span class=\"string\">&quot;</span>]\n        targets = torch.tensor([label &gt; k <span class=\"keyword\">for</span> k in range(<span class=\"number\">4</span>)], dtype=torch.float32)\n        <span class=\"keyword\">return</span> image, targets, label\n\n\n<span class=\"comment\"># Data loading</span>\ntrain_dataset = RetinaDataset(train_df, <span class=\"string\">&quot;</span><span class=\"string\">./input/train_images</span><span class=\"string\">&quot;</span>, train_transform)\nval_dataset = RetinaDataset(val_df, <span class=\"string\">&quot;</span><span class=\"string\">./input/train_images</span><span class=\"string\">&quot;</span>, test_transform)\ntest_dataset = RetinaDataset(\n    test_df, <span class=\"string\">&quot;</span><span class=\"string\">./input/test_images</span><span class=\"string\">&quot;</span>, test_transform, is_test=<span class=\"keyword\">True</span>\n)\n\ntrain_loader = DataLoader(\n    train_dataset, BATCH_SIZE, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">8</span>, pin_memory=<span class=\"keyword\">True</span>\n)\nval_loader = DataLoader(val_dataset, BATCH_SIZE, num_workers=<span class=\"number\">8</span>, pin_memory=<span class=\"keyword\">True</span>)\ntest_loader = DataLoader(test_dataset, BATCH_SIZE, num_workers=<span class=\"number\">8</span>, pin_memory=<span class=\"keyword\">True</span>)\n\n<span class=\"comment\"># Model setup</span>\nmodel = timm.create_model(<span class=\"string\">&quot;</span><span class=\"string\">tf_efficientnet_b4</span><span class=\"string\">&quot;</span>, pretrained=<span class=\"keyword\">True</span>, num_classes=<span class=\"number\">4</span>)\nmodel = model.to(device)\n\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\noptimizer = torch.optim.AdamW(model.parameters(), lr=<span class=\"number\">3e-4</span>, weight_decay=<span class=\"number\">1e-4</span>)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer, max_lr=<span class=\"number\">3e-4</span>, total_steps=EPOCHS * len(train_loader)\n)\n\n<span class=\"comment\"># Training loop</span>\nbest_kappa = -<span class=\"number\">1</span>\n<span class=\"keyword\">for</span> epoch in range(EPOCHS):\n    model.train()\n    <span class=\"keyword\">for</span> images, targets, _ in train_loader:\n        images, targets = images.to(device), targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), <span class=\"number\">5.0</span>)\n        optimizer.step()\n        scheduler.step()\n\n    model.eval()\n    val_preds, val_true = [], []\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> images, _, labels in val_loader:\n            outputs = model(images.to(device))\n            preds = (torch.sigmoid(outputs) &gt;= <span class=\"number\">0.5</span>).sum(<span class=\"number\">1</span>)\n            val_preds.extend(preds.cpu().numpy())\n            val_true.extend(labels.numpy())\n\n    kappa = cohen_kappa_score(val_true, val_preds, weights=<span class=\"string\">&quot;</span><span class=\"string\">quadratic</span><span class=\"string\">&quot;</span>)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">/</span><span class=\"string\">{</span>EPOCHS<span class=\"string\">}</span><span class=\"string\"> | Val Kappa: </span><span class=\"string\">{</span>kappa<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n    <span class=\"keyword\">if</span> kappa &gt; best_kappa:\n        best_kappa = kappa\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">./working/best_model.pth</span><span class=\"string\">&quot;</span>)\n\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Best Validation Kappa: </span><span class=\"string\">{</span>best_kappa<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Threshold optimization</span>\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">./working/best_model.pth</span><span class=\"string\">&quot;</span>))\nmodel.eval()\n\nval_outputs = []\nval_true = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> images, _, labels in val_loader:\n        images = images.to(device)\n        outputs = model(images)\n        val_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n        val_true.append(labels.numpy())\n\nval_outputs = np.concatenate(val_outputs)\nval_true = np.concatenate(val_true)\n\nbest_thresholds = []\n<span class=\"keyword\">for</span> k in range(<span class=\"number\">4</span>):\n    y_true = (val_true &gt; k).astype(int)\n    y_scores = val_outputs[:, k]\n\n    best_t = <span class=\"number\">0.5</span>\n    best_kappa = -<span class=\"number\">1</span>\n    <span class=\"keyword\">for</span> t in np.linspace(<span class=\"number\">0.1</span>, <span class=\"number\">0.9</span>, <span class=\"number\">81</span>):\n        y_pred = (y_scores &gt;= t).astype(int)\n        kappa = cohen_kappa_score(y_true, y_pred)\n        <span class=\"keyword\">if</span> kappa &gt; best_kappa:\n            best_kappa = kappa\n            best_t = t\n    best_thresholds.append(best_t)\n    print(\n        <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Optimal threshold for task </span><span class=\"string\">{</span>k<span class=\"string\">}</span><span class=\"string\">: </span><span class=\"string\">{</span>best_t<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\"> (binary kappa=</span><span class=\"string\">{</span>best_kappa<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">)</span><span class=\"string\">&quot;</span>\n    )\n\n<span class=\"comment\"># Generate submission with optimized thresholds</span>\ntest_preds = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> images in test_loader:\n        images = images.to(device)\n        outputs = model(images)\n        outputs = torch.sigmoid(outputs).cpu().numpy()\n        preds = (outputs &gt;= best_thresholds).sum(axis=<span class=\"number\">1</span>)\n        test_preds.extend(preds)\n\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">./submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\nsubmission = pd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">id_code</span><span class=\"string\">&quot;</span>: test_df.id_code, <span class=\"string\">&quot;</span><span class=\"string\">diagnosis</span><span class=\"string\">&quot;</span>: test_preds})\nsubmission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">./submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\nprint(<span class=\"string\">&quot;</span><span class=\"string\">Submission file created with optimized thresholds</span><span class=\"string\">&quot;</span>)\n"
}
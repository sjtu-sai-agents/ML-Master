{
    "title": "ventilator-pressure-prediction",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task ventilator-pressure-prediction --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"ventilator-pressure-prediction\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n\n\n<span class=\"comment\"># Model architecture fix</span>\n<span class=\"keyword\">class</span> <span class=\"class\">LSTMRegressor</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, input_size, hidden_size, num_layers):\n        super().<span class=\"function\">__init__</span>()\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=<span class=\"keyword\">True</span>)\n        self.linear = nn.Linear(hidden_size, <span class=\"number\">1</span>)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, x):\n        out, _ = self.lstm(x)  <span class=\"comment\"># Extract sequence outputs</span>\n        <span class=\"keyword\">return</span> self.linear(out)  <span class=\"comment\"># Apply linear layer to each timestep</span>\n\n\n<span class=\"comment\"># Data preprocessing with improved normalization</span>\n<span class=\"keyword\">def</span> <span class=\"function\">normalize_group</span>(df_group):\n    df_group = df_group.copy()\n    df_group[<span class=\"string\">&quot;</span><span class=\"string\">u_in_cumsum</span><span class=\"string\">&quot;</span>] = df_group[<span class=\"string\">&quot;</span><span class=\"string\">u_in</span><span class=\"string\">&quot;</span>].cumsum()\n    eps = <span class=\"number\">1e-7</span>\n\n    <span class=\"comment\"># Normalize time-varying features per breath</span>\n    <span class=\"keyword\">for</span> col in [<span class=\"string\">&quot;</span><span class=\"string\">u_in</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">u_in_cumsum</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">time_step</span><span class=\"string\">&quot;</span>]:\n        min_val = df_group[col].min()\n        max_val = df_group[col].max()\n        df_group[col] = (df_group[col] - min_val) / (max_val - min_val + eps)\n\n    <span class=\"comment\"># Normalize static features using global stats</span>\n    df_group[<span class=\"string\">&quot;</span><span class=\"string\">R</span><span class=\"string\">&quot;</span>] = (df_group[<span class=\"string\">&quot;</span><span class=\"string\">R</span><span class=\"string\">&quot;</span>] - <span class=\"number\">5</span>) / (<span class=\"number\">50</span> - <span class=\"number\">5</span>)\n    df_group[<span class=\"string\">&quot;</span><span class=\"string\">C</span><span class=\"string\">&quot;</span>] = (df_group[<span class=\"string\">&quot;</span><span class=\"string\">C</span><span class=\"string\">&quot;</span>] - <span class=\"number\">10</span>) / (<span class=\"number\">50</span> - <span class=\"number\">10</span>)\n    <span class=\"keyword\">return</span> df_group\n\n\n<span class=\"comment\"># Load and preprocess data</span>\ntrain_df = (\n    pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/train.csv</span><span class=\"string\">&quot;</span>)\n    .groupby(<span class=\"string\">&quot;</span><span class=\"string\">breath_id</span><span class=\"string\">&quot;</span>)\n    .apply(normalize_group)\n    .reset_index(drop=<span class=\"keyword\">True</span>)\n)\ntest_df = (\n    pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/test.csv</span><span class=\"string\">&quot;</span>)\n    .groupby(<span class=\"string\">&quot;</span><span class=\"string\">breath_id</span><span class=\"string\">&quot;</span>)\n    .apply(normalize_group)\n    .reset_index(drop=<span class=\"keyword\">True</span>)\n)\n\n\n<span class=\"comment\"># Dataset class remains same</span>\n<span class=\"keyword\">class</span> <span class=\"class\">VentilatorDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, is_train=<span class=\"keyword\">True</span>):\n        self.breath_groups = [g <span class=\"keyword\">for</span> _, g in df.groupby(<span class=\"string\">&quot;</span><span class=\"string\">breath_id</span><span class=\"string\">&quot;</span>)]\n        self.is_train = is_train\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.breath_groups)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        group = self.breath_groups[idx]\n        features = torch.FloatTensor(\n            group[[<span class=\"string\">&quot;</span><span class=\"string\">u_in</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">u_out</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">time_step</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">u_in_cumsum</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">R</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">C</span><span class=\"string\">&quot;</span>]].values\n        )\n        <span class=\"keyword\">if</span> self.is_train:\n            <span class=\"keyword\">return</span> features, torch.FloatTensor(group[<span class=\"string\">&quot;</span><span class=\"string\">pressure</span><span class=\"string\">&quot;</span>].values)\n        <span class=\"keyword\">return</span> features\n\n\n<span class=\"comment\"># Initialize model and training params</span>\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\nmodel = LSTMRegressor(input_size=<span class=\"number\">6</span>, hidden_size=<span class=\"number\">256</span>, num_layers=<span class=\"number\">3</span>).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=<span class=\"number\">0.001</span>)\nloss_fn = nn.L1Loss()\n\n<span class=\"comment\"># Create train/val split</span>\nbreath_ids = train_df[<span class=\"string\">&quot;</span><span class=\"string\">breath_id</span><span class=\"string\">&quot;</span>].unique()\ntrain_breath_ids, val_breath_ids = train_test_split(\n    breath_ids, test_size=<span class=\"number\">0.2</span>, random_state=<span class=\"number\">42</span>\n)\ntrain = train_df[train_df[<span class=\"string\">&quot;</span><span class=\"string\">breath_id</span><span class=\"string\">&quot;</span>].isin(train_breath_ids)]\nval = train_df[train_df[<span class=\"string\">&quot;</span><span class=\"string\">breath_id</span><span class=\"string\">&quot;</span>].isin(val_breath_ids)]\n\ntrain_loader = DataLoader(\n    VentilatorDataset(train),\n    batch_size=<span class=\"number\">128</span>,\n    shuffle=<span class=\"keyword\">True</span>,\n    num_workers=<span class=\"number\">4</span>,\n    pin_memory=<span class=\"keyword\">True</span>,\n)\nval_loader = DataLoader(\n    VentilatorDataset(val),\n    batch_size=<span class=\"number\">256</span>,\n    shuffle=<span class=\"keyword\">False</span>,\n    num_workers=<span class=\"number\">4</span>,\n    pin_memory=<span class=\"keyword\">True</span>,\n)\n\n<span class=\"comment\"># Training loop with dimension fix</span>\nbest_val = float(<span class=\"string\">&quot;</span><span class=\"string\">inf</span><span class=\"string\">&quot;</span>)\n<span class=\"keyword\">for</span> epoch in range(<span class=\"number\">15</span>):\n    model.train()\n    train_loss = <span class=\"number\">0</span>\n    <span class=\"keyword\">for</span> features, targets in train_loader:\n        features, targets = features.to(device), targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(features)\n        loss = loss_fn(outputs.squeeze(-<span class=\"number\">1</span>), targets)  <span class=\"comment\"># Fix dimension squeeze</span>\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * len(features)\n\n    <span class=\"comment\"># Validation</span>\n    model.eval()\n    val_loss = <span class=\"number\">0</span>\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> features, targets in val_loader:\n            features, targets = features.to(device), targets.to(device)\n            outputs = model(features)\n            val_loss += loss_fn(outputs.squeeze(-<span class=\"number\">1</span>), targets).item() * len(features)\n\n    avg_val = val_loss / len(val)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">: Val MAE </span><span class=\"string\">{</span>avg_val<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n    <span class=\"keyword\">if</span> avg_val &lt; best_val:\n        best_val = avg_val\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Generate submission</span>\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>))\nmodel.eval()\ntest_ds = VentilatorDataset(test_df, is_train=<span class=\"keyword\">False</span>)\ntest_loader = DataLoader(test_ds, batch_size=<span class=\"number\">256</span>, shuffle=<span class=\"keyword\">False</span>)\n\npreds = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> features in test_loader:\n        features = features.to(device)\n        preds.append(model(features).cpu().numpy().squeeze().flatten())\n\nsubmission = pd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>: test_df[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>], <span class=\"string\">&quot;</span><span class=\"string\">pressure</span><span class=\"string\">&quot;</span>: np.concatenate(preds)})\nsubmission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Best Validation MAE: </span><span class=\"string\">{</span>best_val<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">, Submission saved</span><span class=\"string\">&quot;</span>)\n"
}
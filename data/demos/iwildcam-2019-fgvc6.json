{
    "title": "iwildcam-2019-fgvc6",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task iwildcam-2019-fgvc6 --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"iwildcam-2019-fgvc6\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, models\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> f1_score\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image\n<span class=\"keyword\">import</span> os\n\n<span class=\"comment\"># Config</span>\ntorch.manual_seed(<span class=\"number\">42</span>)\nnp.random.seed(<span class=\"number\">42</span>)\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\n\n\n<span class=\"comment\"># Dataset class</span>\n<span class=\"keyword\">class</span> <span class=\"class\">WildlifeDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, img_dir, transform=<span class=\"keyword\">None</span>, is_test=<span class=\"keyword\">False</span>):\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.df)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        img_path = os.path.join(self.img_dir, self.df.iloc[idx][<span class=\"string\">&quot;</span><span class=\"string\">file_name</span><span class=\"string\">&quot;</span>])\n        img = Image.open(img_path).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">if</span> self.transform:\n            img = self.transform(img)\n        <span class=\"keyword\">return</span> (\n            (img, self.df.iloc[idx][<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>])\n            <span class=\"keyword\">if</span> self.is_test\n            <span class=\"keyword\">else</span> (img, self.df.iloc[idx][<span class=\"string\">&quot;</span><span class=\"string\">category_id</span><span class=\"string\">&quot;</span>])\n        )\n\n\n<span class=\"comment\"># Data prep</span>\ntrain_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/train.csv</span><span class=\"string\">&quot;</span>)\ntrain_df, val_df = train_test_split(\n    train_df, test_size=<span class=\"number\">0.1</span>, stratify=train_df[<span class=\"string\">&quot;</span><span class=\"string\">category_id</span><span class=\"string\">&quot;</span>], random_state=<span class=\"number\">42</span>\n)\n\n<span class=\"comment\"># Transforms</span>\nimg_size = <span class=\"number\">300</span>\ntrain_tfms = transforms.Compose(\n    [\n        transforms.Resize((img_size, img_size)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\nval_tfms = transforms.Compose(\n    [\n        transforms.Resize((img_size, img_size)),\n        transforms.ToTensor(),\n        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\n<span class=\"comment\"># Dataloaders</span>\nbatch_size = <span class=\"number\">64</span>\ntrain_ds = WildlifeDataset(train_df, <span class=\"string\">&quot;</span><span class=\"string\">input/train_images</span><span class=\"string\">&quot;</span>, train_tfms)\nval_ds = WildlifeDataset(val_df, <span class=\"string\">&quot;</span><span class=\"string\">input/train_images</span><span class=\"string\">&quot;</span>, val_tfms)\ntrain_loader = DataLoader(\n    train_ds, batch_size=batch_size, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">8</span>, pin_memory=<span class=\"keyword\">True</span>\n)\nval_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=<span class=\"number\">8</span>, pin_memory=<span class=\"keyword\">True</span>)\n\n<span class=\"comment\"># Model</span>\nmodel = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\nmodel.classifier[<span class=\"number\">1</span>] = nn.Linear(\n    model.classifier[<span class=\"number\">1</span>].in_features, <span class=\"number\">23</span>\n)  <span class=\"comment\"># 23 classes (0-22)</span>\nmodel = model.to(device)\n\n<span class=\"comment\"># Training config</span>\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=<span class=\"number\">3e-4</span>)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, <span class=\"string\">&quot;</span><span class=\"string\">max</span><span class=\"string\">&quot;</span>, patience=<span class=\"number\">2</span>)\n\n<span class=\"comment\"># Training loop</span>\nbest_f1 = <span class=\"number\">0</span>\n<span class=\"keyword\">for</span> epoch in range(<span class=\"number\">10</span>):\n    model.train()\n    running_loss = <span class=\"number\">0.0</span>\n    <span class=\"keyword\">for</span> imgs, labels in train_loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * imgs.size(<span class=\"number\">0</span>)\n\n    epoch_loss = running_loss / len(train_loader.dataset)\n\n    <span class=\"comment\"># Validation</span>\n    model.eval()\n    all_preds, all_labels = [], []\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> imgs, labels in val_loader:\n            outputs = model(imgs.to(device))\n            preds = outputs.argmax(dim=<span class=\"number\">1</span>).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.numpy())\n\n    val_f1 = f1_score(all_labels, all_preds, average=<span class=\"string\">&quot;</span><span class=\"string\">macro</span><span class=\"string\">&quot;</span>)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\"> - Loss: </span><span class=\"string\">{</span>epoch_loss<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">, Val F1: </span><span class=\"string\">{</span>val_f1<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n    <span class=\"keyword\">if</span> val_f1 &gt; best_f1:\n        best_f1 = val_f1\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>)\n\n    scheduler.step(val_f1)\n\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">\\n</span><span class=\"string\">Best Validation F1: </span><span class=\"string\">{</span>best_f1<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Test inference</span>\ntest_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/test.csv</span><span class=\"string\">&quot;</span>)\ntest_ds = WildlifeDataset(test_df, <span class=\"string\">&quot;</span><span class=\"string\">input/test_images</span><span class=\"string\">&quot;</span>, val_tfms, is_test=<span class=\"keyword\">True</span>)\ntest_loader = DataLoader(test_ds, batch_size=<span class=\"number\">64</span>, num_workers=<span class=\"number\">8</span>)\n\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>))\nmodel.eval()\npreds, ids = [], []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> imgs, img_ids in test_loader:\n        outputs = model(imgs.to(device))\n        batch_preds = outputs.argmax(dim=<span class=\"number\">1</span>).cpu().numpy()\n        preds.extend(batch_preds)\n        ids.extend(img_ids)\n\n<span class=\"comment\"># Save submission with corrected column name</span>\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\npd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>: ids, <span class=\"string\">&quot;</span><span class=\"string\">Category</span><span class=\"string\">&quot;</span>: preds}).to_csv(\n    <span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>\n)\nprint(<span class=\"string\">&quot;</span><span class=\"string\">Submission saved with correct format</span><span class=\"string\">&quot;</span>)\n"
}
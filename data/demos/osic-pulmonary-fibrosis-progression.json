{
    "title": "osic-pulmonary-fibrosis-progression",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task osic-pulmonary-fibrosis-progression --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"osic-pulmonary-fibrosis-progression\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> pydicom\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader, TensorDataset\n<span class=\"keyword\">from</span> torchvision.transforms <span class=\"keyword\">import</span> Compose, Resize, Normalize\n<span class=\"keyword\">from</span> sklearn.compose <span class=\"keyword\">import</span> ColumnTransformer\n<span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> OneHotEncoder\n<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> glob\n\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">CTFeatureExtractor</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self):\n        super().<span class=\"function\">__init__</span>()\n        self.conv_layers = nn.Sequential(\n            nn.Conv3d(<span class=\"number\">1</span>, <span class=\"number\">32</span>, <span class=\"number\">3</span>, padding=<span class=\"number\">1</span>),\n            nn.BatchNorm3d(<span class=\"number\">32</span>),\n            nn.ReLU(),\n            nn.MaxPool3d(<span class=\"number\">2</span>),\n            nn.Conv3d(<span class=\"number\">32</span>, <span class=\"number\">64</span>, <span class=\"number\">3</span>, padding=<span class=\"number\">1</span>),\n            nn.BatchNorm3d(<span class=\"number\">64</span>),\n            nn.ReLU(),\n            nn.MaxPool3d(<span class=\"number\">2</span>),\n            nn.Conv3d(<span class=\"number\">64</span>, <span class=\"number\">128</span>, <span class=\"number\">3</span>, padding=<span class=\"number\">1</span>),\n            nn.BatchNorm3d(<span class=\"number\">128</span>),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool3d(<span class=\"number\">1</span>),\n        )\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, x):\n        <span class=\"keyword\">return</span> self.conv_layers(x).flatten(<span class=\"number\">1</span>)\n\n\ntransform = Compose([Resize((<span class=\"number\">256</span>, <span class=\"number\">256</span>)), Normalize(mean=[<span class=\"number\">0.5</span>], std=[<span class=\"number\">0.5</span>])])\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">DICOMDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, patient_ids, base_path):\n        self.patients = patient_ids\n        self.base_path = base_path\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.patients)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        pid = self.patients[idx]\n        slices = []\n        <span class=\"keyword\">for</span> f in glob.glob(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">{</span>self.base_path<span class=\"string\">}</span><span class=\"string\">/</span><span class=\"string\">{</span>pid<span class=\"string\">}</span><span class=\"string\">/*.dcm</span><span class=\"string\">&quot;</span>):\n            <span class=\"keyword\">try</span>:\n                dcm = pydicom.dcmread(f)\n                img = dcm.pixel_array.astype(np.float32)\n                slope = getattr(dcm, <span class=\"string\">&quot;</span><span class=\"string\">RescaleSlope</span><span class=\"string\">&quot;</span>, <span class=\"number\">1.0</span>)\n                intercept = getattr(dcm, <span class=\"string\">&quot;</span><span class=\"string\">RescaleIntercept</span><span class=\"string\">&quot;</span>, <span class=\"number\">0.0</span>)\n                img = img * slope + intercept\n                img = np.clip(img, -<span class=\"number\">1000</span>, <span class=\"number\">400</span>)\n                img = (img + <span class=\"number\">1000</span>) / <span class=\"number\">1400</span>\n                slices.append(transform(torch.tensor(img).unsqueeze(<span class=\"number\">0</span>)))\n            <span class=\"keyword\">except</span>:\n                <span class=\"keyword\">continue</span>\n\n        volume = torch.zeros(<span class=\"number\">64</span>, <span class=\"number\">1</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>)\n        <span class=\"keyword\">if</span> len(slices) &gt; <span class=\"number\">64</span>:\n            indices = np.linspace(<span class=\"number\">0</span>, len(slices) - <span class=\"number\">1</span>, <span class=\"number\">64</span>, dtype=int)\n            volume = torch.stack([slices[i] <span class=\"keyword\">for</span> i in indices])\n        <span class=\"keyword\">elif</span> slices:\n            volume[: len(slices)] = torch.stack(slices)\n\n        <span class=\"keyword\">return</span> volume.permute(<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>), pid\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">extract_features</span>(patients, path):\n    device = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span>)\n    model = CTFeatureExtractor().to(device).eval()\n    dataset = DICOMDataset(patients, path)\n    loader = DataLoader(dataset, batch_size=<span class=\"number\">4</span>, num_workers=<span class=\"number\">8</span>, pin_memory=<span class=\"keyword\">True</span>)\n\n    features = {}\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> vol, pids in loader:\n            feats = model(vol.to(device)).cpu().numpy()\n            <span class=\"keyword\">for</span> pid, feat in zip(pids, feats):\n                features[pid] = feat\n    <span class=\"keyword\">return</span> np.array([features[pid] <span class=\"keyword\">for</span> pid in patients])\n\n\n<span class=\"comment\"># Read and preprocess data</span>\ntrain_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/train.csv</span><span class=\"string\">&quot;</span>)\ntest_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/test.csv</span><span class=\"string\">&quot;</span>)\ntest_df[<span class=\"string\">&quot;</span><span class=\"string\">Age</span><span class=\"string\">&quot;</span>] = pd.to_numeric(test_df[<span class=\"string\">&quot;</span><span class=\"string\">Age</span><span class=\"string\">&quot;</span>], errors=<span class=\"string\">&quot;</span><span class=\"string\">coerce</span><span class=\"string\">&quot;</span>)  <span class=\"comment\"># Ensure numeric</span>\ntest_df[<span class=\"string\">&quot;</span><span class=\"string\">FVC</span><span class=\"string\">&quot;</span>] = pd.to_numeric(test_df[<span class=\"string\">&quot;</span><span class=\"string\">FVC</span><span class=\"string\">&quot;</span>], errors=<span class=\"string\">&quot;</span><span class=\"string\">coerce</span><span class=\"string\">&quot;</span>)  <span class=\"comment\"># Ensure numeric</span>\n\n<span class=\"comment\"># Process baseline features</span>\ntrain_baseline = train_df.sort_values(<span class=\"string\">&quot;</span><span class=\"string\">Weeks</span><span class=\"string\">&quot;</span>).groupby(<span class=\"string\">&quot;</span><span class=\"string\">Patient</span><span class=\"string\">&quot;</span>).first().reset_index()\ntrain_baseline = train_baseline[[<span class=\"string\">&quot;</span><span class=\"string\">Patient</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">Sex</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">SmokingStatus</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">Age</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">FVC</span><span class=\"string\">&quot;</span>]]\ntrain_baseline = train_baseline.rename(columns={<span class=\"string\">&quot;</span><span class=\"string\">FVC</span><span class=\"string\">&quot;</span>: <span class=\"string\">&quot;</span><span class=\"string\">BaseFVC</span><span class=\"string\">&quot;</span>})\n\n<span class=\"comment\"># Extract CT features</span>\ntrain_ct = extract_features(train_df.Patient.unique(), <span class=\"string\">&quot;</span><span class=\"string\">input/train</span><span class=\"string\">&quot;</span>)\ntest_ct = extract_features(test_df.Patient.unique(), <span class=\"string\">&quot;</span><span class=\"string\">input/test</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Build preprocessing pipeline</span>\npreprocessor = ColumnTransformer(\n    [\n        (<span class=\"string\">&quot;</span><span class=\"string\">encoder</span><span class=\"string\">&quot;</span>, OneHotEncoder(sparse_output=<span class=\"keyword\">False</span>), [<span class=\"string\">&quot;</span><span class=\"string\">Sex</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">SmokingStatus</span><span class=\"string\">&quot;</span>]),\n        (<span class=\"string\">&quot;</span><span class=\"string\">scaler</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">passthrough</span><span class=\"string\">&quot;</span>, [<span class=\"string\">&quot;</span><span class=\"string\">Age</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">BaseFVC</span><span class=\"string\">&quot;</span>]),\n    ]\n)\npreprocessor.fit(train_baseline[[<span class=\"string\">&quot;</span><span class=\"string\">Sex</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">SmokingStatus</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">Age</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">BaseFVC</span><span class=\"string\">&quot;</span>]])\n\n<span class=\"comment\"># Prepare training data</span>\nX, y = [], []\n<span class=\"keyword\">for</span> _, row in train_df.iterrows():\n    base_row = train_baseline[train_baseline.Patient == row.Patient].iloc[<span class=\"number\">0</span>]\n    clinical = preprocessor.transform(\n        base_row[[<span class=\"string\">&quot;</span><span class=\"string\">Sex</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">SmokingStatus</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">Age</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">BaseFVC</span><span class=\"string\">&quot;</span>]].to_frame().T\n    ).flatten()\n    ct_idx = np.where(train_df.Patient.unique() == row.Patient)[<span class=\"number\">0</span>][<span class=\"number\">0</span>]\n    week_norm = (row.Weeks - train_df.Weeks.mean()) / train_df.Weeks.std()\n    X.append(np.concatenate([clinical, train_ct[ct_idx], [week_norm]]))\n    y.append(row.FVC)\n\nX = np.vstack(X).astype(np.float32)\ny = np.array(y).astype(np.float32)\n\n\n<span class=\"comment\"># Model definition</span>\n<span class=\"keyword\">class</span> <span class=\"class\">FVCModel</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, input_size):\n        super().<span class=\"function\">__init__</span>()\n        self.layers = nn.Sequential(\n            nn.Linear(input_size, <span class=\"number\">512</span>),\n            nn.BatchNorm1d(<span class=\"number\">512</span>),\n            nn.ReLU(),\n            nn.Dropout(<span class=\"number\">0.5</span>),\n            nn.Linear(<span class=\"number\">512</span>, <span class=\"number\">256</span>),\n            nn.BatchNorm1d(<span class=\"number\">256</span>),\n            nn.ReLU(),\n            nn.Dropout(<span class=\"number\">0.3</span>),\n            nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">128</span>),\n            nn.BatchNorm1d(<span class=\"number\">128</span>),\n            nn.ReLU(),\n            nn.Dropout(<span class=\"number\">0.2</span>),\n        )\n        self.output = nn.Linear(<span class=\"number\">128</span>, <span class=\"number\">2</span>)\n        self.sigma_act = nn.Softplus()\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, x):\n        features = self.layers(x)\n        out = self.output(features)\n        <span class=\"keyword\">return</span> out[:, <span class=\"number\">0</span>], <span class=\"number\">70</span> + self.sigma_act(out[:, <span class=\"number\">1</span>])\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">laplace_loss</span>(y_true, y_pred, sigma):\n    sigma_clamped = torch.clamp(sigma, min=<span class=\"number\">70</span>)\n    delta = torch.clamp(torch.abs(y_true - y_pred), max=<span class=\"number\">1000</span>)\n    <span class=\"keyword\">return</span> -torch.mean(\n        (np.sqrt(<span class=\"number\">2</span>) * delta) / sigma_clamped + torch.log(np.sqrt(<span class=\"number\">2</span>) * sigma_clamped)\n    )\n\n\n<span class=\"comment\"># Training setup</span>\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span>)\nmodel = FVCModel(X.shape[<span class=\"number\">1</span>]).to(device)\nopt = optim.AdamW(model.parameters(), lr=<span class=\"number\">1e-3</span>, weight_decay=<span class=\"number\">0.01</span>)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, <span class=\"string\">&quot;</span><span class=\"string\">min</span><span class=\"string\">&quot;</span>, patience=<span class=\"number\">3</span>, factor=<span class=\"number\">0.5</span>)\n\nsplit_idx = int(len(X) * <span class=\"number\">0.8</span>)\ntrain_dataset = TensorDataset(\n    torch.FloatTensor(X[:split_idx]), torch.FloatTensor(y[:split_idx])\n)\nval_dataset = TensorDataset(\n    torch.FloatTensor(X[split_idx:]), torch.FloatTensor(y[split_idx:])\n)\ntrain_loader = DataLoader(train_dataset, batch_size=<span class=\"number\">256</span>, shuffle=<span class=\"keyword\">True</span>)\nbest_val_loss = float(<span class=\"string\">&quot;</span><span class=\"string\">inf</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Training loop</span>\n<span class=\"keyword\">for</span> epoch in range(<span class=\"number\">50</span>):\n    model.train()\n    total_loss = <span class=\"number\">0</span>\n    <span class=\"keyword\">for</span> xb, yb in train_loader:\n        xb, yb = xb.to(device), yb.to(device)\n        opt.zero_grad()\n        pred, sigma = model(xb)\n        loss = laplace_loss(yb, pred, sigma)\n        loss.backward()\n        opt.step()\n        total_loss += loss.item()\n\n    <span class=\"keyword\">with</span> torch.no_grad():\n        val_x, val_y = val_dataset.tensors\n        val_pred, val_sigma = model(val_x.to(device))\n        val_loss = laplace_loss(val_y.to(device), val_pred, val_sigma)\n        scheduler.step(val_loss)\n\n    <span class=\"keyword\">if</span> val_loss &lt; best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Prepare test data</span>\nX_test = []\n<span class=\"keyword\">for</span> patient in test_df.Patient.unique():\n    row = test_df[test_df.Patient == patient].iloc[<span class=\"number\">0</span>]\n    test_row = (\n        row[[<span class=\"string\">&quot;</span><span class=\"string\">Sex</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">SmokingStatus</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">Age</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">FVC</span><span class=\"string\">&quot;</span>]]\n        .to_frame()\n        .T.rename(columns={<span class=\"string\">&quot;</span><span class=\"string\">FVC</span><span class=\"string\">&quot;</span>: <span class=\"string\">&quot;</span><span class=\"string\">BaseFVC</span><span class=\"string\">&quot;</span>})\n    )\n    test_row[<span class=\"string\">&quot;</span><span class=\"string\">Age</span><span class=\"string\">&quot;</span>] = test_row[<span class=\"string\">&quot;</span><span class=\"string\">Age</span><span class=\"string\">&quot;</span>].astype(float)\n    test_row[<span class=\"string\">&quot;</span><span class=\"string\">BaseFVC</span><span class=\"string\">&quot;</span>] = test_row[<span class=\"string\">&quot;</span><span class=\"string\">BaseFVC</span><span class=\"string\">&quot;</span>].astype(float)\n    clinical = preprocessor.transform(test_row).flatten()\n    ct_idx = np.where(test_df.Patient.unique() == patient)[<span class=\"number\">0</span>][<span class=\"number\">0</span>]\n    <span class=\"keyword\">for</span> week in [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>]:\n        week_norm = (week - train_df.Weeks.mean()) / train_df.Weeks.std()\n        X_test.append(np.concatenate([clinical, test_ct[ct_idx], [week_norm]]))\n\nX_test = np.vstack(X_test).astype(np.float32)\n\n<span class=\"comment\"># Generate predictions</span>\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>))\n<span class=\"keyword\">with</span> torch.no_grad():\n    test_tensor = torch.FloatTensor(X_test).to(device)\n    preds, sigmas = model(test_tensor)\n\n<span class=\"comment\"># Create submission</span>\nsubmission = []\n<span class=\"keyword\">for</span> i, patient in enumerate(test_df.Patient.unique()):\n    <span class=\"keyword\">for</span> week in [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>]:\n        submission.append(\n            {\n                <span class=\"string\">&quot;</span><span class=\"string\">Patient_Week</span><span class=\"string\">&quot;</span>: <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">{</span>patient<span class=\"string\">}</span><span class=\"string\">_</span><span class=\"string\">{</span>week<span class=\"string\">}</span><span class=\"string\">&quot;</span>,\n                <span class=\"string\">&quot;</span><span class=\"string\">FVC</span><span class=\"string\">&quot;</span>: int(preds[i * <span class=\"number\">3</span> + week - <span class=\"number\">1</span>].item()),\n                <span class=\"string\">&quot;</span><span class=\"string\">Confidence</span><span class=\"string\">&quot;</span>: int(sigmas[i * <span class=\"number\">3</span> + week - <span class=\"number\">1</span>].item()),\n            }\n        )\n\npd.DataFrame(submission).to_csv(<span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Validation metric: </span><span class=\"string\">{</span>-best_val_loss.item()<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n"
}
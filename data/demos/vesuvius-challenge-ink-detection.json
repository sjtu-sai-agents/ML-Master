{
    "title": "vesuvius-challenge-ink-detection",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task vesuvius-challenge-ink-detection --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"vesuvius-challenge-ink-detection\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">import</span> tifffile\n<span class=\"keyword\">import</span> cv2\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm\n\nDATA_PATH = <span class=\"string\">&quot;</span><span class=\"string\">./input</span><span class=\"string\">&quot;</span>\nSUBMISSION_PATH = <span class=\"string\">&quot;</span><span class=\"string\">./submission/submission.csv</span><span class=\"string\">&quot;</span>\nBATCH_SIZE = <span class=\"number\">16</span>\nEPOCHS = <span class=\"number\">5</span>\nLR = <span class=\"number\">1e-4</span>\nPATCH_SIZE = <span class=\"number\">256</span>\nTHRESHOLD = <span class=\"number\">0.4</span>\nZ_START, Z_END = <span class=\"number\">27</span>, <span class=\"number\">37</span>\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">UNet</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self):\n        super().<span class=\"function\">__init__</span>()\n        self.enc1 = self.conv_block(Z_END - Z_START, <span class=\"number\">64</span>)\n        self.enc2 = self.conv_block(<span class=\"number\">64</span>, <span class=\"number\">128</span>)\n        self.enc3 = self.conv_block(<span class=\"number\">128</span>, <span class=\"number\">256</span>)\n        self.pool = nn.MaxPool2d(<span class=\"number\">2</span>)\n        self.bottleneck = self.conv_block(<span class=\"number\">256</span>, <span class=\"number\">512</span>)\n        self.up3 = nn.ConvTranspose2d(<span class=\"number\">512</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">2</span>, stride=<span class=\"number\">2</span>)\n        self.dec3 = self.conv_block(<span class=\"number\">512</span>, <span class=\"number\">256</span>)\n        self.up2 = nn.ConvTranspose2d(<span class=\"number\">256</span>, <span class=\"number\">128</span>, kernel_size=<span class=\"number\">2</span>, stride=<span class=\"number\">2</span>)\n        self.dec2 = self.conv_block(<span class=\"number\">256</span>, <span class=\"number\">128</span>)\n        self.up1 = nn.ConvTranspose2d(<span class=\"number\">128</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">2</span>, stride=<span class=\"number\">2</span>)\n        self.dec1 = self.conv_block(<span class=\"number\">128</span>, <span class=\"number\">64</span>)\n        self.final = nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">1</span>, kernel_size=<span class=\"number\">1</span>)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">conv_block</span>(self, in_c, out_c):\n        <span class=\"keyword\">return</span> nn.Sequential(\n            nn.Conv2d(in_c, out_c, <span class=\"number\">3</span>, padding=<span class=\"number\">1</span>),\n            nn.BatchNorm2d(out_c),\n            nn.ReLU(),\n            nn.Conv2d(out_c, out_c, <span class=\"number\">3</span>, padding=<span class=\"number\">1</span>),\n            nn.BatchNorm2d(out_c),\n            nn.ReLU(),\n        )\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, x):\n        enc1 = self.enc1(x)\n        enc2 = self.enc2(self.pool(enc1))\n        enc3 = self.enc3(self.pool(enc2))\n        bottleneck = self.bottleneck(self.pool(enc3))\n        dec3 = self.up3(bottleneck)\n        dec3 = torch.cat((dec3, enc3), <span class=\"number\">1</span>)\n        dec3 = self.dec3(dec3)\n        dec2 = self.up2(dec3)\n        dec2 = torch.cat((dec2, enc2), <span class=\"number\">1</span>)\n        dec2 = self.dec2(dec2)\n        dec1 = self.up1(dec2)\n        dec1 = torch.cat((dec1, enc1), <span class=\"number\">1</span>)\n        dec1 = self.dec1(dec1)\n        <span class=\"keyword\">return</span> torch.sigmoid(self.final(dec1))\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">PapyrusDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, fragment_ids, train=<span class=\"keyword\">True</span>):\n        self.train = train\n        self.samples = []\n        <span class=\"keyword\">for</span> frag_id in fragment_ids:\n            path = os.path.join(DATA_PATH, <span class=\"string\">&quot;</span><span class=\"string\">train</span><span class=\"string\">&quot;</span>, str(frag_id))\n            mask = cv2.imread(os.path.join(path, <span class=\"string\">&quot;</span><span class=\"string\">mask.png</span><span class=\"string\">&quot;</span>), <span class=\"number\">0</span>)\n            label_img = cv2.imread(os.path.join(path, <span class=\"string\">&quot;</span><span class=\"string\">inklabels.png</span><span class=\"string\">&quot;</span>), <span class=\"number\">0</span>) / <span class=\"number\">255</span>\n            volume = []\n            <span class=\"keyword\">for</span> z in range(Z_START, Z_END):\n                img = tifffile.imread(os.path.join(path, <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">surface_volume/</span><span class=\"string\">{</span>z<span class=\"string\">:</span><span class=\"string\">02d</span><span class=\"string\">}</span><span class=\"string\">.tif</span><span class=\"string\">&quot;</span>))\n                volume.append(img)\n            volume = np.stack(volume, axis=<span class=\"number\">2</span>)\n            y_step = mask.shape[<span class=\"number\">0</span>] // PATCH_SIZE\n            x_step = mask.shape[<span class=\"number\">1</span>] // PATCH_SIZE\n            <span class=\"keyword\">for</span> y in range(y_step):\n                <span class=\"keyword\">for</span> x in range(x_step):\n                    y_start = y * PATCH_SIZE\n                    x_start = x * PATCH_SIZE\n                    <span class=\"keyword\">if</span> (\n                        mask[\n                            y_start : y_start + PATCH_SIZE,\n                            x_start : x_start + PATCH_SIZE,\n                        ].sum()\n                        &gt; <span class=\"number\">0</span>\n                    ):\n                        patch = volume[\n                            y_start : y_start + PATCH_SIZE,\n                            x_start : x_start + PATCH_SIZE,\n                        ]\n                        label = label_img[\n                            y_start : y_start + PATCH_SIZE,\n                            x_start : x_start + PATCH_SIZE,\n                        ]\n                        self.samples.append((np.moveaxis(patch, -<span class=\"number\">1</span>, <span class=\"number\">0</span>), label))\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.samples)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        x = torch.FloatTensor(self.samples[idx][<span class=\"number\">0</span>])\n        y = torch.FloatTensor(self.samples[idx][<span class=\"number\">1</span>]).unsqueeze(<span class=\"number\">0</span>)\n        <span class=\"keyword\">return</span> x, y\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">f05_loss</span>(pred, target, beta=<span class=\"number\">0.5</span>, smooth=<span class=\"number\">1e-8</span>):\n    pred = pred.flatten()\n    target = target.flatten()\n    tp = (pred * target).sum()\n    fp = (pred * (<span class=\"number\">1</span> - target)).sum()\n    fn = ((<span class=\"number\">1</span> - pred) * target).sum()\n    f05 = (<span class=\"number\">1</span> + beta**<span class=\"number\">2</span>) * tp / ((<span class=\"number\">1</span> + beta**<span class=\"number\">2</span>) * tp + beta**<span class=\"number\">2</span> * fn + fp + smooth)\n    <span class=\"keyword\">return</span> <span class=\"number\">1</span> - f05\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">dice_score</span>(pred, target, beta=<span class=\"number\">0.5</span>):\n    pred = (pred &gt; THRESHOLD).float()\n    target = target.float()\n    tp = (pred * target).sum()\n    fp = (pred * (<span class=\"number\">1</span> - target)).sum()\n    fn = ((<span class=\"number\">1</span> - pred) * target).sum()\n    <span class=\"keyword\">return</span> (<span class=\"number\">1</span> + beta**<span class=\"number\">2</span>) * tp / ((<span class=\"number\">1</span> + beta**<span class=\"number\">2</span>) * tp + beta**<span class=\"number\">2</span> * fn + fp + <span class=\"number\">1e-8</span>)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">rle_encode</span>(img):\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[<span class=\"number\">0</span>], pixels, [<span class=\"number\">0</span>]])\n    runs = np.where(pixels[<span class=\"number\">1</span>:] != pixels[:-<span class=\"number\">1</span>])[<span class=\"number\">0</span>] + <span class=\"number\">1</span>\n    runs[<span class=\"number\">1</span>::<span class=\"number\">2</span>] -= runs[::<span class=\"number\">2</span>]\n    <span class=\"keyword\">return</span> <span class=\"string\">&quot;</span><span class=\"string\"> </span><span class=\"string\">&quot;</span>.join(str(x) <span class=\"keyword\">for</span> x in runs)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">train</span>():\n    full_ds = PapyrusDataset([<span class=\"number\">1</span>, <span class=\"number\">2</span>])\n    train_ds, val_ds = train_test_split(full_ds, test_size=<span class=\"number\">0.2</span>, random_state=<span class=\"number\">42</span>)\n    train_loader = DataLoader(train_ds, BATCH_SIZE, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">4</span>)\n    val_loader = DataLoader(val_ds, BATCH_SIZE, num_workers=<span class=\"number\">4</span>)\n    model = UNet().cuda()\n    opt = torch.optim.Adam(model.parameters(), lr=LR)\n    best_score = <span class=\"number\">0</span>\n\n    <span class=\"keyword\">for</span> epoch in range(EPOCHS):\n        model.train()\n        <span class=\"keyword\">for</span> x, y in tqdm(train_loader, desc=<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Train Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>):\n            x, y = x.cuda(), y.cuda()\n            opt.zero_grad()\n            pred = model(x)\n            loss = f05_loss(pred, y) + F.binary_cross_entropy(pred, y)\n            loss.backward()\n            opt.step()\n\n        model.eval()\n        val_dice = <span class=\"number\">0</span>\n        <span class=\"keyword\">with</span> torch.no_grad():\n            <span class=\"keyword\">for</span> x, y in val_loader:\n                x, y = x.cuda(), y.cuda()\n                pred = model(x)\n                val_dice += dice_score(pred, y).item()\n        avg_dice = val_dice / len(val_loader)\n        print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\"> Val Dice: </span><span class=\"string\">{</span>avg_dice<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">if</span> avg_dice &gt; best_score:\n            best_score = avg_dice\n            torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Best Validation Dice: </span><span class=\"string\">{</span>best_score<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">predict</span>():\n    model = UNet().cuda()\n    model.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>))\n    model.eval()\n    test_frags = [\n        d\n        <span class=\"keyword\">for</span> d in os.listdir(os.path.join(DATA_PATH, <span class=\"string\">&quot;</span><span class=\"string\">test</span><span class=\"string\">&quot;</span>))\n        <span class=\"keyword\">if</span> os.path.isdir(os.path.join(DATA_PATH, <span class=\"string\">&quot;</span><span class=\"string\">test</span><span class=\"string\">&quot;</span>, d))\n    ]\n    sub = []\n\n    <span class=\"keyword\">for</span> frag_id in test_frags:\n        path = os.path.join(DATA_PATH, <span class=\"string\">&quot;</span><span class=\"string\">test</span><span class=\"string\">&quot;</span>, frag_id)\n        mask = cv2.imread(os.path.join(path, <span class=\"string\">&quot;</span><span class=\"string\">mask.png</span><span class=\"string\">&quot;</span>), <span class=\"number\">0</span>)\n        full_pred = np.zeros_like(mask, dtype=np.float32)\n        counts = np.zeros_like(mask, dtype=np.float32)\n        volume = []\n\n        <span class=\"keyword\">for</span> z in range(Z_START, Z_END):\n            img = tifffile.imread(os.path.join(path, <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">surface_volume/</span><span class=\"string\">{</span>z<span class=\"string\">:</span><span class=\"string\">02d</span><span class=\"string\">}</span><span class=\"string\">.tif</span><span class=\"string\">&quot;</span>))\n            volume.append(img)\n        volume = np.stack(volume, axis=<span class=\"number\">2</span>)\n\n        step = PATCH_SIZE // <span class=\"number\">2</span>\n        <span class=\"keyword\">for</span> y in range(<span class=\"number\">0</span>, mask.shape[<span class=\"number\">0</span>] + step, step):\n            <span class=\"keyword\">for</span> x in range(<span class=\"number\">0</span>, mask.shape[<span class=\"number\">1</span>] + step, step):\n                y_start = max(<span class=\"number\">0</span>, y)\n                x_start = max(<span class=\"number\">0</span>, x)\n                y_end = min(mask.shape[<span class=\"number\">0</span>], y_start + PATCH_SIZE)\n                x_end = min(mask.shape[<span class=\"number\">1</span>], x_start + PATCH_SIZE)\n\n                <span class=\"keyword\">if</span> y_end - y_start &lt; PATCH_SIZE or x_end - x_start &lt; PATCH_SIZE:\n                    <span class=\"keyword\">continue</span>\n                <span class=\"keyword\">if</span> mask[y_start:y_end, x_start:x_end].sum() == <span class=\"number\">0</span>:\n                    <span class=\"keyword\">continue</span>\n\n                patch = volume[y_start:y_end, x_start:x_end]\n                patch = np.moveaxis(patch, -<span class=\"number\">1</span>, <span class=\"number\">0</span>)[<span class=\"keyword\">None</span>]\n                <span class=\"keyword\">with</span> torch.no_grad():\n                    pred = (\n                        model(torch.FloatTensor(patch).cuda()).squeeze().cpu().numpy()\n                    )\n\n                full_pred[y_start:y_end, x_start:x_end] += pred\n                counts[y_start:y_end, x_start:x_end] += <span class=\"number\">1</span>\n\n        full_pred = full_pred / (counts + <span class=\"number\">1e-7</span>)  <span class=\"comment\"># Avoid division by zero</span>\n        full_pred = (full_pred &gt; THRESHOLD).astype(np.uint8) * mask\n        rle = rle_encode(full_pred)\n        sub.append({<span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>: frag_id, <span class=\"string\">&quot;</span><span class=\"string\">Predicted</span><span class=\"string\">&quot;</span>: rle})\n\n    pd.DataFrame(sub).to_csv(SUBMISSION_PATH, index=<span class=\"keyword\">False</span>)\n\n\n<span class=\"keyword\">if</span> __name__ == <span class=\"string\">&quot;</span><span class=\"string\">__main__</span><span class=\"string\">&quot;</span>:\n    train()\n    predict()\n"
}
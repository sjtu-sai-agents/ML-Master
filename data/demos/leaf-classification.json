{
    "title": "leaf-classification",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task leaf-classification --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"leaf-classification\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> StandardScaler\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader, TensorDataset\n<span class=\"keyword\">from</span> torch.optim.swa_utils <span class=\"keyword\">import</span> AveragedModel, SWALR\n<span class=\"keyword\">from</span> torch.optim.lr_scheduler <span class=\"keyword\">import</span> CosineAnnealingLR\n<span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> models, transforms\n<span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image\n\n<span class=\"comment\"># Load data</span>\ntrain_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/train.csv</span><span class=\"string\">&quot;</span>)\ntest_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/test.csv</span><span class=\"string\">&quot;</span>)\nsample_sub = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/sample_submission.csv</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Enhanced image feature extraction with EfficientNet-B4</span>\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\nweights = models.EfficientNet_B4_Weights.DEFAULT\npreprocess = weights.transforms()\neffnet = models.efficientnet_b4(weights=weights)\neffnet = nn.Sequential(effnet.features, effnet.avgpool).to(device).eval()\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">extract_features</span>(ids):\n    features = []\n    <span class=\"keyword\">for</span> idx in ids:\n        img = Image.open(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">input/images/</span><span class=\"string\">{</span>idx<span class=\"string\">}</span><span class=\"string\">.jpg</span><span class=\"string\">&quot;</span>).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        img_t = preprocess(img).unsqueeze(<span class=\"number\">0</span>).to(device)\n        <span class=\"keyword\">with</span> torch.no_grad():\n            feat = effnet(img_t).flatten().cpu().numpy()\n        features.append(feat)\n    <span class=\"keyword\">return</span> np.array(features)\n\n\ntrain_img_feats = extract_features(train_df[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>])\ntest_img_feats = extract_features(test_df[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>])\n\n<span class=\"comment\"># Merge enhanced features</span>\nfeature_cols = [<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">{</span>p<span class=\"string\">}</span><span class=\"string\">{</span>i<span class=\"string\">}</span><span class=\"string\">&quot;</span> <span class=\"keyword\">for</span> p in [<span class=\"string\">&quot;</span><span class=\"string\">margin</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">shape</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">texture</span><span class=\"string\">&quot;</span>] <span class=\"keyword\">for</span> i in range(<span class=\"number\">1</span>, <span class=\"number\">65</span>)]\ntrain_df = pd.concat(\n    [\n        train_df,\n        pd.DataFrame(train_img_feats, columns=[<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">img_</span><span class=\"string\">{</span>i<span class=\"string\">}</span><span class=\"string\">&quot;</span> <span class=\"keyword\">for</span> i in range(<span class=\"number\">1792</span>)]),\n    ],\n    axis=<span class=\"number\">1</span>,\n)\ntest_df = pd.concat(\n    [test_df, pd.DataFrame(test_img_feats, columns=[<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">img_</span><span class=\"string\">{</span>i<span class=\"string\">}</span><span class=\"string\">&quot;</span> <span class=\"keyword\">for</span> i in range(<span class=\"number\">1792</span>)])],\n    axis=<span class=\"number\">1</span>,\n)\nfeature_cols += [<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">img_</span><span class=\"string\">{</span>i<span class=\"string\">}</span><span class=\"string\">&quot;</span> <span class=\"keyword\">for</span> i in range(<span class=\"number\">1792</span>)]\n\n<span class=\"comment\"># Prepare targets</span>\nspecies = sample_sub.columns[<span class=\"number\">1</span>:].tolist()\ntrain_df[<span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>] = train_df[<span class=\"string\">&quot;</span><span class=\"string\">species</span><span class=\"string\">&quot;</span>].map({s: i <span class=\"keyword\">for</span> i, s in enumerate(species)})\n\n<span class=\"comment\"># Train/val split</span>\nX, y = train_df[feature_cols].values, train_df[<span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>].values\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=<span class=\"number\">0.2</span>, stratify=y, random_state=<span class=\"number\">42</span>\n)\n\n<span class=\"comment\"># Feature scaling with adjusted slices</span>\nscalers = [StandardScaler() <span class=\"keyword\">for</span> _ in range(<span class=\"number\">4</span>)]\nslices = [\n    (<span class=\"number\">0</span>, <span class=\"number\">64</span>),\n    (<span class=\"number\">64</span>, <span class=\"number\">128</span>),\n    (<span class=\"number\">128</span>, <span class=\"number\">192</span>),\n    (<span class=\"number\">192</span>, <span class=\"number\">1984</span>),\n]  <span class=\"comment\"># Updated for 1792 image features</span>\n\n<span class=\"keyword\">for</span> i in range(<span class=\"number\">4</span>):\n    sc = scalers[i]\n    start, end = slices[i]\n    X_train[:, start:end] = sc.fit_transform(X_train[:, start:end])\n    X_val[:, start:end] = sc.transform(X_val[:, start:end])\n    test_df[feature_cols[start:end]] = sc.transform(\n        test_df[feature_cols[start:end]].values\n    )\n\n<span class=\"comment\"># Dataset preparation</span>\ntrain_ds = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\nval_ds = TensorDataset(torch.FloatTensor(X_val), torch.LongTensor(y_val))\ntrain_loader = DataLoader(train_ds, batch_size=<span class=\"number\">256</span>, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">4</span>)\nval_loader = DataLoader(val_ds, batch_size=<span class=\"number\">256</span>, num_workers=<span class=\"number\">4</span>)\n\n\n<span class=\"comment\"># Enhanced model with transformer fusion</span>\n<span class=\"keyword\">class</span> <span class=\"class\">MultiModalNet</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, num_classes):\n        super().<span class=\"function\">__init__</span>()\n        self.margin_net = self._create_branch(<span class=\"number\">64</span>)\n        self.shape_net = self._create_branch(<span class=\"number\">64</span>)\n        self.texture_net = self._create_branch(<span class=\"number\">64</span>)\n        self.image_net = self._create_branch(<span class=\"number\">1792</span>)\n\n        self.transformer_encoder = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(\n                d_model=<span class=\"number\">256</span>,\n                nhead=<span class=\"number\">8</span>,\n                dim_feedforward=<span class=\"number\">1024</span>,\n                dropout=<span class=\"number\">0.1</span>,\n                batch_first=<span class=\"keyword\">True</span>,\n            ),\n            num_layers=<span class=\"number\">2</span>,\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Linear(<span class=\"number\">1024</span>, <span class=\"number\">512</span>),\n            nn.BatchNorm1d(<span class=\"number\">512</span>),\n            nn.GELU(),\n            nn.Dropout(<span class=\"number\">0.5</span>),\n            nn.Linear(<span class=\"number\">512</span>, num_classes),\n        )\n\n    <span class=\"keyword\">def</span> <span class=\"function\">_create_branch</span>(self, in_dim):\n        <span class=\"keyword\">return</span> nn.Sequential(\n            nn.Linear(in_dim, <span class=\"number\">256</span>),\n            nn.BatchNorm1d(<span class=\"number\">256</span>),\n            nn.GELU(),\n            nn.Dropout(<span class=\"number\">0.3</span>),\n            nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">256</span>),\n            nn.BatchNorm1d(<span class=\"number\">256</span>),\n            nn.GELU(),\n            nn.Dropout(<span class=\"number\">0.3</span>),\n        )\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, x):\n        m = self.margin_net(x[:, :<span class=\"number\">64</span>])\n        s = self.shape_net(x[:, <span class=\"number\">64</span>:<span class=\"number\">128</span>])\n        t = self.texture_net(x[:, <span class=\"number\">128</span>:<span class=\"number\">192</span>])\n        i = self.image_net(x[:, <span class=\"number\">192</span>:<span class=\"number\">1984</span>])\n\n        <span class=\"comment\"># Transformer fusion</span>\n        features = torch.stack([m, s, t, i], dim=<span class=\"number\">1</span>)  <span class=\"comment\"># [B, 4, 256]</span>\n        fused = self.transformer_encoder(features)\n        fused_flat = fused.view(fused.size(<span class=\"number\">0</span>), -<span class=\"number\">1</span>)  <span class=\"comment\"># [B, 4*256=1024]</span>\n\n        <span class=\"keyword\">return</span> self.classifier(fused_flat)\n\n\n<span class=\"comment\"># Training setup</span>\nmodel = MultiModalNet(len(species)).to(device)\nswa_model = AveragedModel(model)\nopt = optim.AdamW(model.parameters(), lr=<span class=\"number\">0.001</span>, weight_decay=<span class=\"number\">0.01</span>)\nscheduler = CosineAnnealingLR(opt, T_max=<span class=\"number\">50</span>)\nswa_start = <span class=\"number\">70</span>\nswa_scheduler = SWALR(opt, swa_lr=<span class=\"number\">0.005</span>)\ncriterion = nn.CrossEntropyLoss()\n\n<span class=\"comment\"># Training loop</span>\n<span class=\"keyword\">for</span> epoch in range(<span class=\"number\">100</span>):\n    model.train()\n    <span class=\"keyword\">for</span> inputs, targets in train_loader:\n        inputs, targets = inputs.to(device), targets.to(device)\n        opt.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        opt.step()\n\n    <span class=\"keyword\">if</span> epoch &gt;= swa_start:\n        swa_model.update_parameters(model)\n        swa_scheduler.step()\n    <span class=\"keyword\">else</span>:\n        scheduler.step()\n\n<span class=\"comment\"># Finalize model</span>\ntorch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\nmodel = swa_model.module\n\n<span class=\"comment\"># Validation</span>\nmodel.eval()\nval_probs = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> inputs, _ in val_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        val_probs.append(torch.softmax(outputs, dim=<span class=\"number\">1</span>).cpu().numpy())\n\nval_probs = np.concatenate(val_probs)\nlogloss = -np.mean(np.log(val_probs[np.arange(len(y_val)), y_val]))\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Validation Log Loss: </span><span class=\"string\">{</span>logloss<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Generate submission</span>\ntest_tensor = torch.FloatTensor(test_df[feature_cols].values).to(device)\ntest_probs = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> i in range(<span class=\"number\">0</span>, len(test_tensor), <span class=\"number\">256</span>):\n        batch = test_tensor[i : i + <span class=\"number\">256</span>]\n        outputs = model(batch)\n        test_probs.append(torch.softmax(outputs, dim=<span class=\"number\">1</span>).cpu().numpy())\n\nsubmission = pd.DataFrame(np.concatenate(test_probs), columns=species)\nsubmission.insert(<span class=\"number\">0</span>, <span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>, test_df[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>])\nsubmission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\n"
}
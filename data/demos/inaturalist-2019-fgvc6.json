{
    "title": "inaturalist-2019-fgvc6",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task inaturalist-2019-fgvc6 --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"inaturalist-2019-fgvc6\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> json\n<span class=\"keyword\">import</span> tarfile\n<span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn, optim\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, models\n<span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">clean_file_path</span>(file_path):\n    <span class=\"string\">&quot;&quot;&quot;Remove leading dataset directory prefixes from file paths&quot;&quot;&quot;</span>\n    parts = file_path.split(<span class=\"string\">&quot;</span><span class=\"string\">/</span><span class=\"string\">&quot;</span>)\n    <span class=\"keyword\">if</span> parts and parts[<span class=\"number\">0</span>] in [<span class=\"string\">&quot;</span><span class=\"string\">train_val2019</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">test2019</span><span class=\"string\">&quot;</span>]:\n        <span class=\"keyword\">return</span> <span class=\"string\">&quot;</span><span class=\"string\">/</span><span class=\"string\">&quot;</span>.join(parts[<span class=\"number\">1</span>:])\n    <span class=\"keyword\">return</span> file_path\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">extract_tar_files</span>():\n    train_val_path = <span class=\"string\">&quot;</span><span class=\"string\">input/train_val2019.tar.gz</span><span class=\"string\">&quot;</span>\n    test_path = <span class=\"string\">&quot;</span><span class=\"string\">input/test2019.tar.gz</span><span class=\"string\">&quot;</span>\n\n    <span class=\"keyword\">if</span> not os.path.exists(<span class=\"string\">&quot;</span><span class=\"string\">working/train_val2019</span><span class=\"string\">&quot;</span>):\n        print(<span class=\"string\">&quot;</span><span class=\"string\">Extracting train_val2019...</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">with</span> tarfile.open(train_val_path, <span class=\"string\">&quot;</span><span class=\"string\">r:*</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">as</span> tar:\n            tar.extractall(path=<span class=\"string\">&quot;</span><span class=\"string\">working</span><span class=\"string\">&quot;</span>)\n\n    <span class=\"keyword\">if</span> not os.path.exists(<span class=\"string\">&quot;</span><span class=\"string\">working/test2019</span><span class=\"string\">&quot;</span>):\n        print(<span class=\"string\">&quot;</span><span class=\"string\">Extracting test2019...</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">with</span> tarfile.open(test_path, <span class=\"string\">&quot;</span><span class=\"string\">r:*</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">as</span> tar:\n            tar.extractall(path=<span class=\"string\">&quot;</span><span class=\"string\">working</span><span class=\"string\">&quot;</span>)\n\n    <span class=\"keyword\">return</span> <span class=\"string\">&quot;</span><span class=\"string\">working/train_val2019</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">working/test2019</span><span class=\"string\">&quot;</span>\n\n\ntrain_root, test_root = extract_tar_files()\n\n<span class=\"comment\"># Load training and validation data</span>\n<span class=\"keyword\">with</span> open(<span class=\"string\">&quot;</span><span class=\"string\">input/train2019.json</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">as</span> f:\n    train_data = json.load(f)\ncategories = train_data[<span class=\"string\">&quot;</span><span class=\"string\">categories</span><span class=\"string\">&quot;</span>]\ncategory_id_to_label = {cat[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>]: idx <span class=\"keyword\">for</span> idx, cat in enumerate(categories)}\nnum_classes = len(categories)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">create_df</span>(data):\n    image_id_to_file = {\n        img[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>]: clean_file_path(img[<span class=\"string\">&quot;</span><span class=\"string\">file_name</span><span class=\"string\">&quot;</span>]) <span class=\"keyword\">for</span> img in data[<span class=\"string\">&quot;</span><span class=\"string\">images</span><span class=\"string\">&quot;</span>]\n    }\n    <span class=\"keyword\">return</span> pd.DataFrame(\n        [\n            {\n                <span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>: ann[<span class=\"string\">&quot;</span><span class=\"string\">image_id</span><span class=\"string\">&quot;</span>],\n                <span class=\"string\">&quot;</span><span class=\"string\">file_name</span><span class=\"string\">&quot;</span>: image_id_to_file[ann[<span class=\"string\">&quot;</span><span class=\"string\">image_id</span><span class=\"string\">&quot;</span>]],\n                <span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>: category_id_to_label[ann[<span class=\"string\">&quot;</span><span class=\"string\">category_id</span><span class=\"string\">&quot;</span>]],\n            }\n            <span class=\"keyword\">for</span> ann in data[<span class=\"string\">&quot;</span><span class=\"string\">annotations</span><span class=\"string\">&quot;</span>]\n        ]\n    )\n\n\ntrain_df = create_df(train_data)\n\n<span class=\"comment\"># Create validation split from training data</span>\nval_df = train_df.sample(frac=<span class=\"number\">0.2</span>, random_state=<span class=\"number\">42</span>)\ntrain_df = train_df.drop(val_df.index)\n\n<span class=\"comment\"># Data transforms</span>\ntrain_transform = transforms.Compose(\n    [\n        transforms.RandomResizedCrop(<span class=\"number\">380</span>),\n        transforms.RandomHorizontalFlip(),\n        transforms.ColorJitter(brightness=<span class=\"number\">0.2</span>, contrast=<span class=\"number\">0.2</span>, saturation=<span class=\"number\">0.2</span>),\n        transforms.ToTensor(),\n        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\nval_transform = transforms.Compose(\n    [\n        transforms.Resize(<span class=\"number\">456</span>),\n        transforms.CenterCrop(<span class=\"number\">380</span>),\n        transforms.ToTensor(),\n        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">INaturalistDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, root, transform=<span class=\"keyword\">None</span>):\n        self.df = df\n        self.root = root\n        self.transform = transform\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.df)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.root, row[<span class=\"string\">&quot;</span><span class=\"string\">file_name</span><span class=\"string\">&quot;</span>])\n        img = Image.open(img_path).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">return</span> self.transform(img), row[<span class=\"string\">&quot;</span><span class=\"string\">label</span><span class=\"string\">&quot;</span>] <span class=\"keyword\">if</span> self.transform <span class=\"keyword\">else</span> img\n\n\ntrain_ds = INaturalistDataset(train_df, train_root, train_transform)\nval_ds = INaturalistDataset(val_df, train_root, val_transform)\n\nbatch_size = <span class=\"number\">64</span>\ntrain_loader = DataLoader(\n    train_ds, batch_size=batch_size, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">8</span>, pin_memory=<span class=\"keyword\">True</span>\n)\nval_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=<span class=\"number\">8</span>, pin_memory=<span class=\"keyword\">True</span>)\n\nmodel = models.efficientnet_b3(pretrained=<span class=\"keyword\">True</span>)\nmodel.classifier[<span class=\"number\">1</span>] = nn.Linear(model.classifier[<span class=\"number\">1</span>].in_features, num_classes)\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=<span class=\"number\">3e-4</span>, weight_decay=<span class=\"number\">0.01</span>)\nscheduler = optim.lr_scheduler.OneCycleLR(\n    optimizer, max_lr=<span class=\"number\">3e-4</span>, steps_per_epoch=len(train_loader), epochs=<span class=\"number\">10</span>\n)\n\nbest_val_acc = <span class=\"number\">0</span>\n<span class=\"keyword\">for</span> epoch in range(<span class=\"number\">10</span>):\n    model.train()\n    <span class=\"keyword\">for</span> x, y in tqdm(train_loader, desc=<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>):\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        outputs = model(x)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n    model.eval()\n    correct = total = <span class=\"number\">0</span>\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> x, y in val_loader:\n            x, y = x.to(device), y.to(device)\n            outputs = model(x)\n            _, preds = torch.max(outputs, <span class=\"number\">1</span>)\n            correct += (preds == y).sum().item()\n            total += y.size(<span class=\"number\">0</span>)\n    val_acc = correct / total\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Val Accuracy: </span><span class=\"string\">{</span>val_acc<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n    <span class=\"keyword\">if</span> val_acc &gt; best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">working/best_model.pth</span><span class=\"string\">&quot;</span>)\n\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Best Validation Accuracy: </span><span class=\"string\">{</span>best_val_acc<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">TestDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, root, transform):\n        <span class=\"keyword\">with</span> open(<span class=\"string\">&quot;</span><span class=\"string\">input/test2019.json</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">as</span> f:\n            test_data = json.load(f)\n        self.images = [\n            {<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>: img[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>], <span class=\"string\">&quot;</span><span class=\"string\">file_name</span><span class=\"string\">&quot;</span>: clean_file_path(img[<span class=\"string\">&quot;</span><span class=\"string\">file_name</span><span class=\"string\">&quot;</span>])}\n            <span class=\"keyword\">for</span> img in test_data[<span class=\"string\">&quot;</span><span class=\"string\">images</span><span class=\"string\">&quot;</span>]\n        ]\n        self.root = root\n        self.transform = transform\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.images)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        img_info = self.images[idx]\n        img_path = os.path.join(self.root, img_info[<span class=\"string\">&quot;</span><span class=\"string\">file_name</span><span class=\"string\">&quot;</span>])\n        img = Image.open(img_path).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">return</span> self.transform(img), img_info[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>]\n\n\ntest_ds = TestDataset(test_root, val_transform)\ntest_loader = DataLoader(test_ds, batch_size=<span class=\"number\">128</span>, num_workers=<span class=\"number\">8</span>)\n\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">working/best_model.pth</span><span class=\"string\">&quot;</span>))\nmodel.eval()\n\npreds = []\nids = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> x, batch_ids in tqdm(test_loader):\n        x = x.to(device)\n        outputs = model(x)\n        _, top1 = outputs.topk(<span class=\"number\">1</span>, <span class=\"number\">1</span>)\n        preds.extend(top1.cpu().numpy())\n        ids.extend(batch_ids.numpy())\n\n<span class=\"comment\"># Fix the label to category mapping</span>\nlabel_to_category = {v: k <span class=\"keyword\">for</span> k, v in category_id_to_label.items()}\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\nsubmission = pd.DataFrame(\n    {<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>: ids, <span class=\"string\">&quot;</span><span class=\"string\">predicted</span><span class=\"string\">&quot;</span>: [str(label_to_category[p[<span class=\"number\">0</span>]]) <span class=\"keyword\">for</span> p in preds]}\n)\nsubmission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\n"
}
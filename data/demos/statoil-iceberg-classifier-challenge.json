{
    "title": "statoil-iceberg-classifier-challenge",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task statoil-iceberg-classifier-challenge --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"statoil-iceberg-classifier-challenge\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> json\n<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn, optim\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> log_loss\n\n<span class=\"comment\"># Data loading and preprocessing</span>\n<span class=\"keyword\">with</span> open(<span class=\"string\">&quot;</span><span class=\"string\">input/train.json</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">as</span> f:\n    train_data = json.load(f)\ntrain_df = pd.DataFrame(train_data)\n\n<span class=\"keyword\">with</span> open(<span class=\"string\">&quot;</span><span class=\"string\">input/test.json</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">as</span> f:\n    test_data = json.load(f)\ntest_df = pd.DataFrame(test_data)\n\n<span class=\"comment\"># Process incidence angles</span>\ntrain_angles = pd.to_numeric(train_df[<span class=\"string\">&quot;</span><span class=\"string\">inc_angle</span><span class=\"string\">&quot;</span>], errors=<span class=\"string\">&quot;</span><span class=\"string\">coerce</span><span class=\"string\">&quot;</span>)\nangle_mean = train_angles.mean()\ntrain_df[<span class=\"string\">&quot;</span><span class=\"string\">inc_angle</span><span class=\"string\">&quot;</span>] = train_angles.fillna(angle_mean)\ntest_angles = pd.to_numeric(test_df[<span class=\"string\">&quot;</span><span class=\"string\">inc_angle</span><span class=\"string\">&quot;</span>], errors=<span class=\"string\">&quot;</span><span class=\"string\">coerce</span><span class=\"string\">&quot;</span>)\ntest_df[<span class=\"string\">&quot;</span><span class=\"string\">inc_angle</span><span class=\"string\">&quot;</span>] = test_angles.fillna(angle_mean)\n\n\n<span class=\"comment\"># Image processing</span>\n<span class=\"keyword\">def</span> <span class=\"function\">process_bands</span>(df):\n    band1 = np.array([np.array(x).reshape(<span class=\"number\">75</span>, <span class=\"number\">75</span>) <span class=\"keyword\">for</span> x in df[<span class=\"string\">&quot;</span><span class=\"string\">band_1</span><span class=\"string\">&quot;</span>]])\n    band2 = np.array([np.array(x).reshape(<span class=\"number\">75</span>, <span class=\"number\">75</span>) <span class=\"keyword\">for</span> x in df[<span class=\"string\">&quot;</span><span class=\"string\">band_2</span><span class=\"string\">&quot;</span>]])\n    <span class=\"keyword\">return</span> np.stack([band1, band2], axis=<span class=\"number\">1</span>).astype(np.float32)\n\n\nX_train = process_bands(train_df)\nX_test = process_bands(test_df)\ny_train = train_df[<span class=\"string\">&quot;</span><span class=\"string\">is_iceberg</span><span class=\"string\">&quot;</span>].values\n\n<span class=\"comment\"># Normalization</span>\nmean1, std1 = X_train[:, <span class=\"number\">0</span>].mean(), X_train[:, <span class=\"number\">0</span>].std()\nmean2, std2 = X_train[:, <span class=\"number\">1</span>].mean(), X_train[:, <span class=\"number\">1</span>].std()\n\nX_train[:, <span class=\"number\">0</span>] = (X_train[:, <span class=\"number\">0</span>] - mean1) / std1\nX_train[:, <span class=\"number\">1</span>] = (X_train[:, <span class=\"number\">1</span>] - mean2) / std2\nX_test[:, <span class=\"number\">0</span>] = (X_test[:, <span class=\"number\">0</span>] - mean1) / std1\nX_test[:, <span class=\"number\">1</span>] = (X_test[:, <span class=\"number\">1</span>] - mean2) / std2\n\n<span class=\"comment\"># Data split</span>\nX_tr, X_val, y_tr, y_val, angle_tr, angle_val = train_test_split(\n    X_train,\n    y_train,\n    train_df[<span class=\"string\">&quot;</span><span class=\"string\">inc_angle</span><span class=\"string\">&quot;</span>].values,\n    test_size=<span class=\"number\">0.2</span>,\n    stratify=y_train,\n    random_state=<span class=\"number\">42</span>,\n)\n\n\n<span class=\"comment\"># Dataset class with enhanced augmentation</span>\n<span class=\"keyword\">class</span> <span class=\"class\">RadarDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, bands, angles, labels=<span class=\"keyword\">None</span>, augment=<span class=\"keyword\">False</span>):\n        self.bands = bands\n        self.angles = angles.reshape(-<span class=\"number\">1</span>, <span class=\"number\">1</span>).astype(np.float32)\n        self.labels = labels\n        self.augment = augment\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.bands)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        x = torch.tensor(self.bands[idx])\n        a = torch.tensor(self.angles[idx])\n\n        <span class=\"keyword\">if</span> self.augment:\n            <span class=\"comment\"># Spatial augmentations</span>\n            <span class=\"keyword\">if</span> torch.rand(<span class=\"number\">1</span>) &lt; <span class=\"number\">0.5</span>:\n                x = torch.flip(x, [-<span class=\"number\">1</span>])\n            <span class=\"keyword\">if</span> torch.rand(<span class=\"number\">1</span>) &lt; <span class=\"number\">0.5</span>:\n                x = torch.flip(x, [-<span class=\"number\">2</span>])\n            k = torch.randint(<span class=\"number\">0</span>, <span class=\"number\">4</span>, (<span class=\"number\">1</span>,)).item()\n            x = torch.rot90(x, k, [-<span class=\"number\">2</span>, -<span class=\"number\">1</span>])\n\n            <span class=\"comment\"># Spectral augmentations</span>\n            <span class=\"keyword\">if</span> torch.rand(<span class=\"number\">1</span>) &lt; <span class=\"number\">0.3</span>:\n                x += torch.randn_like(x) * <span class=\"number\">0.1</span>\n            <span class=\"keyword\">if</span> torch.rand(<span class=\"number\">1</span>) &lt; <span class=\"number\">0.3</span>:\n                x = x * torch.FloatTensor([<span class=\"number\">1</span>, <span class=\"number\">0.9</span> + <span class=\"number\">0.2</span> * torch.rand(<span class=\"number\">1</span>)]).view(<span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>)\n\n        <span class=\"keyword\">if</span> self.labels is not <span class=\"keyword\">None</span>:\n            <span class=\"keyword\">return</span> x, a, torch.tensor(self.labels[idx], dtype=torch.float)\n        <span class=\"keyword\">return</span> x, a\n\n\n<span class=\"comment\"># Enhanced model architecture</span>\n<span class=\"keyword\">class</span> <span class=\"class\">AngleResSEBlock</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, in_channels, out_channels, reduction=<span class=\"number\">8</span>):\n        super().<span class=\"function\">__init__</span>()\n        self.residual = in_channels == out_channels\n        self.conv1 = nn.Conv2d(in_channels, out_channels, <span class=\"number\">3</span>, padding=<span class=\"number\">1</span>)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, <span class=\"number\">3</span>, padding=<span class=\"number\">1</span>)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.angle_fc = nn.Sequential(\n            nn.Linear(<span class=\"number\">1</span>, out_channels // reduction),\n            nn.ReLU(),\n            nn.Linear(out_channels // reduction, out_channels),\n            nn.Sigmoid(),\n        )\n\n        <span class=\"keyword\">if</span> not self.residual:\n            self.shortcut = nn.Conv2d(in_channels, out_channels, <span class=\"number\">1</span>)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, x, angle):\n        residual = x\n        <span class=\"keyword\">if</span> not self.residual:\n            residual = self.shortcut(x)\n\n        x = torch.relu(self.bn1(self.conv1(x)))\n        x = self.bn2(self.conv2(x))\n\n        scale = self.angle_fc(angle).unsqueeze(-<span class=\"number\">1</span>).unsqueeze(-<span class=\"number\">1</span>)\n        x = x * scale\n\n        <span class=\"keyword\">return</span> torch.relu(x + residual)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">IcebergResNet</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self):\n        super().<span class=\"function\">__init__</span>()\n        self.initial = nn.Sequential(\n            nn.Conv2d(<span class=\"number\">2</span>, <span class=\"number\">64</span>, <span class=\"number\">3</span>, padding=<span class=\"number\">1</span>),\n            nn.BatchNorm2d(<span class=\"number\">64</span>),\n            nn.ReLU(),\n            nn.MaxPool2d(<span class=\"number\">2</span>),\n        )\n\n        self.block1 = AngleResSEBlock(<span class=\"number\">64</span>, <span class=\"number\">64</span>)\n        self.block2 = AngleResSEBlock(<span class=\"number\">64</span>, <span class=\"number\">128</span>)\n        self.pool = nn.MaxPool2d(<span class=\"number\">2</span>)\n        self.block3 = AngleResSEBlock(<span class=\"number\">128</span>, <span class=\"number\">128</span>)\n        self.block4 = AngleResSEBlock(<span class=\"number\">128</span>, <span class=\"number\">256</span>)\n\n        self.adaptive_pool = nn.AdaptiveAvgPool2d(<span class=\"number\">4</span>)\n        self.angle_processor = nn.Sequential(\n            nn.Linear(<span class=\"number\">1</span>, <span class=\"number\">64</span>), nn.ReLU(), nn.Dropout(<span class=\"number\">0.3</span>), nn.Linear(<span class=\"number\">64</span>, <span class=\"number\">128</span>), nn.ReLU()\n        )\n        self.head = nn.Sequential(\n            nn.Linear(<span class=\"number\">256</span> * <span class=\"number\">4</span> * <span class=\"number\">4</span> + <span class=\"number\">128</span>, <span class=\"number\">512</span>),\n            nn.ReLU(),\n            nn.Dropout(<span class=\"number\">0.5</span>),\n            nn.Linear(<span class=\"number\">512</span>, <span class=\"number\">1</span>),\n        )\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, x, angle):\n        x = self.initial(x)\n        x = self.block1(x, angle)\n        x = self.pool(x)\n        x = self.block2(x, angle)\n        x = self.pool(x)\n        x = self.block3(x, angle)\n        x = self.block4(x, angle)\n        x = self.adaptive_pool(x)\n\n        img_features = x.flatten(<span class=\"number\">1</span>)\n        angle_features = self.angle_processor(angle)\n        combined = torch.cat([img_features, angle_features], dim=<span class=\"number\">1</span>)\n        <span class=\"keyword\">return</span> self.head(combined)\n\n\n<span class=\"comment\"># Training configuration</span>\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\nmodel = IcebergResNet().to(device)\noptimizer = optim.AdamW(model.parameters(), lr=<span class=\"number\">1e-4</span>, weight_decay=<span class=\"number\">1e-5</span>)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, <span class=\"string\">&quot;</span><span class=\"string\">min</span><span class=\"string\">&quot;</span>, patience=<span class=\"number\">3</span>, factor=<span class=\"number\">0.5</span>\n)\ncriterion = nn.BCEWithLogitsLoss()\n\n<span class=\"comment\"># Data loaders</span>\ntrain_ds = RadarDataset(X_tr, angle_tr, y_tr, augment=<span class=\"keyword\">True</span>)\nval_ds = RadarDataset(X_val, angle_val, y_val)\ntest_ds = RadarDataset(X_test, test_df[<span class=\"string\">&quot;</span><span class=\"string\">inc_angle</span><span class=\"string\">&quot;</span>].values)\n\ntrain_loader = DataLoader(\n    train_ds, batch_size=<span class=\"number\">64</span>, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">4</span>, pin_memory=<span class=\"keyword\">True</span>\n)\nval_loader = DataLoader(val_ds, batch_size=<span class=\"number\">128</span>, num_workers=<span class=\"number\">4</span>, pin_memory=<span class=\"keyword\">True</span>)\ntest_loader = DataLoader(test_ds, batch_size=<span class=\"number\">128</span>, num_workers=<span class=\"number\">4</span>, pin_memory=<span class=\"keyword\">True</span>)\n\n<span class=\"comment\"># Training loop</span>\nbest_loss = float(<span class=\"string\">&quot;</span><span class=\"string\">inf</span><span class=\"string\">&quot;</span>)\npatience = <span class=\"number\">8</span>\nno_improve = <span class=\"number\">0</span>\n\n<span class=\"keyword\">for</span> epoch in range(<span class=\"number\">100</span>):\n    model.train()\n    <span class=\"keyword\">for</span> batch in train_loader:\n        x, a, y = [t.to(device, non_blocking=<span class=\"keyword\">True</span>) <span class=\"keyword\">for</span> t in batch]\n        optimizer.zero_grad()\n        pred = model(x, a).squeeze(-<span class=\"number\">1</span>)\n        loss = criterion(pred, y)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), <span class=\"number\">1.0</span>)\n        optimizer.step()\n\n    model.eval()\n    val_preds, val_true = [], []\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> batch in val_loader:\n            x, a, y = [t.to(device, non_blocking=<span class=\"keyword\">True</span>) <span class=\"keyword\">for</span> t in batch]\n            val_true.extend(y.cpu().numpy())\n            preds = torch.sigmoid(model(x, a).squeeze(-<span class=\"number\">1</span>)).cpu().numpy()\n            val_preds.extend(preds)\n\n    val_ll = log_loss(val_true, val_preds)\n    scheduler.step(val_ll)\n    print(\n        <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">: Val Loss </span><span class=\"string\">{</span>val_ll<span class=\"string\">:</span><span class=\"string\">.5f</span><span class=\"string\">}</span><span class=\"string\"> | LR </span><span class=\"string\">{</span>optimizer.param_groups[<span class=\"number\">0</span>][<span class=\"string\">&#x27;</span><span class=\"string\">lr</span><span class=\"string\">&#x27;</span>]<span class=\"string\">:</span><span class=\"string\">.2e</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>\n    )\n\n    <span class=\"keyword\">if</span> val_ll &lt; best_loss:\n        best_loss = val_ll\n        no_improve = <span class=\"number\">0</span>\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">best_model.pt</span><span class=\"string\">&quot;</span>)\n    <span class=\"keyword\">else</span>:\n        no_improve += <span class=\"number\">1</span>\n        <span class=\"keyword\">if</span> no_improve &gt;= patience:\n            print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Early stopping at epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n            <span class=\"keyword\">break</span>\n\n<span class=\"comment\"># Generate submission</span>\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">best_model.pt</span><span class=\"string\">&quot;</span>))\nmodel.eval()\ntest_preds = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> batch in test_loader:\n        x, a = [t.to(device, non_blocking=<span class=\"keyword\">True</span>) <span class=\"keyword\">for</span> t in batch]\n        preds = torch.sigmoid(model(x, a).squeeze(-<span class=\"number\">1</span>)).cpu().numpy()\n        test_preds.extend(preds)\n\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\nsubmission = pd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>: test_df[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>], <span class=\"string\">&quot;</span><span class=\"string\">is_iceberg</span><span class=\"string\">&quot;</span>: test_preds})\nsubmission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\n\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Final Validation Log Loss: </span><span class=\"string\">{</span>best_loss<span class=\"string\">:</span><span class=\"string\">.5f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n"
}
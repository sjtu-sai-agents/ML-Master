{
    "title": "text-normalization-challenge-english-language",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task text-normalization-challenge-english-language --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"text-normalization-challenge-english-language\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">from</span> transformers <span class=\"keyword\">import</span> (\n    T5ForConditionalGeneration,\n    T5Tokenizer,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n)\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset\n\n<span class=\"comment\"># Load data</span>\ntrain_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/en_train.csv</span><span class=\"string\">&quot;</span>, usecols=[<span class=\"string\">&quot;</span><span class=\"string\">before</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">after</span><span class=\"string\">&quot;</span>])\ntrain_df = train_df.dropna().sample(\n    frac=<span class=\"number\">0.3</span>, random_state=<span class=\"number\">42</span>\n)  <span class=\"comment\"># Use subset for faster training</span>\n\n<span class=\"comment\"># Split data</span>\ntrain, val = train_test_split(train_df, test_size=<span class=\"number\">0.1</span>, random_state=<span class=\"number\">42</span>)\n\n\n<span class=\"comment\"># Dataset class</span>\n<span class=\"keyword\">class</span> <span class=\"class\">TextNormDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, tokenizer, max_len=<span class=\"number\">32</span>):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.df)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        src = <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">normalize: </span><span class=\"string\">{</span>self.df.iloc[idx].before<span class=\"string\">}</span><span class=\"string\">&quot;</span>\n        tgt = self.df.iloc[idx].after\n\n        inputs = self.tokenizer(\n            src, max_length=self.max_len, truncation=<span class=\"keyword\">True</span>, padding=<span class=\"string\">&quot;</span><span class=\"string\">max_length</span><span class=\"string\">&quot;</span>\n        )\n        targets = self.tokenizer(\n            tgt, max_length=self.max_len, truncation=<span class=\"keyword\">True</span>, padding=<span class=\"string\">&quot;</span><span class=\"string\">max_length</span><span class=\"string\">&quot;</span>\n        )\n\n        <span class=\"keyword\">return</span> {\n            <span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>: torch.tensor(inputs[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>]),\n            <span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>: torch.tensor(inputs[<span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>]),\n            <span class=\"string\">&quot;</span><span class=\"string\">labels</span><span class=\"string\">&quot;</span>: torch.tensor(targets[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>]),\n        }\n\n\n<span class=\"comment\"># Initialize model</span>\nmodel_name = <span class=\"string\">&quot;</span><span class=\"string\">t5-small</span><span class=\"string\">&quot;</span>\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\n\n<span class=\"comment\"># Create datasets</span>\ntrain_dataset = TextNormDataset(train, tokenizer)\nval_dataset = TextNormDataset(val, tokenizer)\n\n<span class=\"comment\"># Training config</span>\nargs = Seq2SeqTrainingArguments(\n    output_dir=<span class=\"string\">&quot;</span><span class=\"string\">./results</span><span class=\"string\">&quot;</span>,\n    evaluation_strategy=<span class=\"string\">&quot;</span><span class=\"string\">steps</span><span class=\"string\">&quot;</span>,\n    eval_steps=<span class=\"number\">5000</span>,\n    learning_rate=<span class=\"number\">3e-4</span>,\n    per_device_train_batch_size=<span class=\"number\">128</span>,\n    per_device_eval_batch_size=<span class=\"number\">128</span>,\n    weight_decay=<span class=\"number\">0.01</span>,\n    num_train_epochs=<span class=\"number\">1</span>,\n    predict_with_generate=<span class=\"keyword\">True</span>,\n    fp16=<span class=\"keyword\">True</span>,\n    report_to=<span class=\"string\">&quot;</span><span class=\"string\">none</span><span class=\"string\">&quot;</span>,\n)\n\n<span class=\"comment\"># Trainer</span>\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n)\n\n<span class=\"comment\"># Train</span>\ntrainer.train()\n\n<span class=\"comment\"># Load test data</span>\ntest_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/en_test.csv</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Generate predictions</span>\nmodel.eval()\npreds = []\n<span class=\"keyword\">for</span> _, row in test_df.iterrows():\n    inputs = tokenizer(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">normalize: </span><span class=\"string\">{</span>row.before<span class=\"string\">}</span><span class=\"string\">&quot;</span>, return_tensors=<span class=\"string\">&quot;</span><span class=\"string\">pt</span><span class=\"string\">&quot;</span>).input_ids.to(\n        model.device\n    )\n    outputs = model.generate(inputs, max_length=<span class=\"number\">32</span>)\n    preds.append(tokenizer.decode(outputs[<span class=\"number\">0</span>], skip_special_tokens=<span class=\"keyword\">True</span>))\n\n<span class=\"comment\"># Create submission</span>\nsubmission = pd.DataFrame(\n    {\n        <span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>: test_df.sentence_id.astype(str) + <span class=\"string\">&quot;</span><span class=\"string\">_</span><span class=\"string\">&quot;</span> + test_df.token_id.astype(str),\n        <span class=\"string\">&quot;</span><span class=\"string\">after</span><span class=\"string\">&quot;</span>: preds,\n    }\n)\nsubmission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">./submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\n\n<span class=\"comment\"># Calculate validation accuracy</span>\nval_results = trainer.predict(val_dataset)\nval_preds = tokenizer.batch_decode(val_results.predictions, skip_special_tokens=<span class=\"keyword\">True</span>)\nval_labels = tokenizer.batch_decode(val_results.label_ids, skip_special_tokens=<span class=\"keyword\">True</span>)\naccuracy = sum(p == l <span class=\"keyword\">for</span> p, l in zip(val_preds, val_labels)) / len(val_labels)\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Validation Accuracy: </span><span class=\"string\">{</span>accuracy<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n"
}
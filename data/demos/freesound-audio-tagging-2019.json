{
    "title": "freesound-audio-tagging-2019",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task freesound-audio-tagging-2019 --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"freesound-audio-tagging-2019\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">import</span> torchaudio\n<span class=\"keyword\">from</span> torchaudio.transforms <span class=\"keyword\">import</span> (\n    MelSpectrogram,\n    Resample,\n    TimeMasking,\n    FrequencyMasking,\n)\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> label_ranking_average_precision_score\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">from</span> torch.optim.lr_scheduler <span class=\"keyword\">import</span> CosineAnnealingLR\n<span class=\"keyword\">import</span> timm\n\n<span class=\"comment\"># Clean previous files</span>\n<span class=\"keyword\">for</span> f in [<span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>]:\n    <span class=\"keyword\">if</span> os.path.exists(f):\n        os.remove(f)\n\n<span class=\"comment\"># Config</span>\nSR = <span class=\"number\">44100</span>\nDURATION = <span class=\"number\">5000</span>  <span class=\"comment\"># ms</span>\nN_MELS = <span class=\"number\">256</span>\nBATCH_SIZE = <span class=\"number\">64</span>\nEPOCHS = <span class=\"number\">20</span>\nCURATED_WEIGHT = <span class=\"number\">1.0</span>\nNOISY_WEIGHT = <span class=\"number\">0.3</span>\n\n<span class=\"comment\"># Data preparation</span>\ncurated = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/train_curated.csv</span><span class=\"string\">&quot;</span>)\nnoisy = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/train_noisy.csv</span><span class=\"string\">&quot;</span>)\nall_labels = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/sample_submission.csv</span><span class=\"string\">&quot;</span>).columns[<span class=\"number\">1</span>:].tolist()\nlabel2idx = {l: i <span class=\"keyword\">for</span> i, l in enumerate(all_labels)}\n\n<span class=\"comment\"># Split curated data</span>\ntrain_cur, val_cur = train_test_split(curated, test_size=<span class=\"number\">0.2</span>, random_state=<span class=\"number\">42</span>)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">AudioDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, df, path, is_train=<span class=\"keyword\">False</span>):\n        self.df = df\n        self.path = path\n        self.is_train = is_train\n        self.resample = Resample(orig_freq=SR, new_freq=SR)\n        self.mel = MelSpectrogram(\n            sample_rate=SR, n_mels=N_MELS, n_fft=<span class=\"number\">2048</span>, hop_length=<span class=\"number\">512</span>\n        )\n        self.time_mask = TimeMasking(time_mask_param=<span class=\"number\">20</span>)\n        self.freq_mask = FrequencyMasking(freq_mask_param=<span class=\"number\">20</span>)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.df)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        row = self.df.iloc[idx]\n        waveform, sr = torchaudio.load(os.path.join(self.path, row[<span class=\"string\">&quot;</span><span class=\"string\">fname</span><span class=\"string\">&quot;</span>]))\n        waveform = self.resample(waveform)\n\n        target_len = SR * DURATION // <span class=\"number\">1000</span>\n        <span class=\"keyword\">if</span> waveform.shape[<span class=\"number\">1</span>] &lt; target_len:\n            waveform = torch.nn.functional.pad(\n                waveform, (<span class=\"number\">0</span>, target_len - waveform.shape[<span class=\"number\">1</span>])\n            )\n        <span class=\"keyword\">else</span>:\n            waveform = waveform[:, :target_len]\n\n        <span class=\"keyword\">if</span> self.is_train:\n            <span class=\"keyword\">if</span> torch.rand(<span class=\"number\">1</span>) &lt; <span class=\"number\">0.8</span>:\n                waveform = torch.roll(\n                    waveform, torch.randint(<span class=\"number\">0</span>, target_len, (<span class=\"number\">1</span>,)).item()\n                )\n            <span class=\"keyword\">if</span> torch.rand(<span class=\"number\">1</span>) &lt; <span class=\"number\">0.5</span>:\n                waveform += torch.randn_like(waveform) * <span class=\"number\">0.008</span>\n\n        spec = self.mel(waveform)\n        spec = torch.log(torch.clamp(spec, min=<span class=\"number\">1e-10</span>))\n        spec = (spec - spec.mean()) / (spec.std() + <span class=\"number\">1e-8</span>)\n        spec = spec.squeeze().permute(<span class=\"number\">1</span>, <span class=\"number\">0</span>)\n\n        <span class=\"keyword\">if</span> self.is_train and torch.rand(<span class=\"number\">1</span>) &lt; <span class=\"number\">0.8</span>:\n            spec = spec.unsqueeze(<span class=\"number\">0</span>)\n            <span class=\"keyword\">if</span> torch.rand(<span class=\"number\">1</span>) &lt; <span class=\"number\">0.5</span>:\n                spec = self.time_mask(spec)\n            <span class=\"keyword\">if</span> torch.rand(<span class=\"number\">1</span>) &lt; <span class=\"number\">0.5</span>:\n                spec = self.freq_mask(spec)\n            spec = spec.squeeze(<span class=\"number\">0</span>)\n\n        spec = spec.unsqueeze(<span class=\"number\">0</span>).repeat(<span class=\"number\">3</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>)\n\n        <span class=\"keyword\">return</span> spec, self.labels_to_vector(row[<span class=\"string\">&quot;</span><span class=\"string\">labels</span><span class=\"string\">&quot;</span>])\n\n    <span class=\"keyword\">def</span> <span class=\"function\">labels_to_vector</span>(self, labels):\n        vec = torch.zeros(len(all_labels))\n        <span class=\"keyword\">for</span> l in labels.split(<span class=\"string\">&quot;</span><span class=\"string\">,</span><span class=\"string\">&quot;</span>):\n            <span class=\"keyword\">if</span> l in label2idx:\n                vec[label2idx[l]] = <span class=\"number\">1.0</span>\n        <span class=\"keyword\">return</span> vec\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">AudioModel</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self):\n        super().<span class=\"function\">__init__</span>()\n        self.backbone = timm.create_model(\n            <span class=\"string\">&quot;</span><span class=\"string\">efficientnet_b0</span><span class=\"string\">&quot;</span>, pretrained=<span class=\"keyword\">True</span>, in_chans=<span class=\"number\">3</span>\n        )\n        self.classifier = nn.Linear(\n            self.backbone.classifier.in_features, len(all_labels)\n        )\n        self.backbone.classifier = nn.Identity()\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, x):\n        x = self.backbone(x)\n        <span class=\"keyword\">return</span> self.classifier(x)\n\n\nmodel = AudioModel().cuda()\noptimizer = optim.AdamW(model.parameters(), lr=<span class=\"number\">1e-3</span>, weight_decay=<span class=\"number\">1e-4</span>)\nscheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n\ncur_dataset = AudioDataset(train_cur, <span class=\"string\">&quot;</span><span class=\"string\">input/train_curated</span><span class=\"string\">&quot;</span>, <span class=\"keyword\">True</span>)\nnoisy_dataset = AudioDataset(noisy, <span class=\"string\">&quot;</span><span class=\"string\">input/train_noisy</span><span class=\"string\">&quot;</span>, <span class=\"keyword\">True</span>)\nval_dataset = AudioDataset(val_cur, <span class=\"string\">&quot;</span><span class=\"string\">input/train_curated</span><span class=\"string\">&quot;</span>)\n\ncur_loader = DataLoader(\n    cur_dataset, BATCH_SIZE, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">4</span>, pin_memory=<span class=\"keyword\">True</span>\n)\nnoisy_loader = DataLoader(\n    noisy_dataset, BATCH_SIZE, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">4</span>, pin_memory=<span class=\"keyword\">True</span>\n)\nval_loader = DataLoader(val_dataset, BATCH_SIZE, num_workers=<span class=\"number\">4</span>)\n\nbest_score = <span class=\"number\">0</span>\n<span class=\"keyword\">for</span> epoch in range(EPOCHS):\n    model.train()\n    <span class=\"keyword\">for</span> (x_cur, y_cur), (x_noisy, y_noisy) in zip(cur_loader, noisy_loader):\n        x = torch.cat([x_cur, x_noisy]).cuda()\n        y = torch.cat([y_cur, y_noisy]).cuda()\n        weights = torch.cat(\n            [\n                torch.ones(x_cur.size(<span class=\"number\">0</span>)) * CURATED_WEIGHT,\n                torch.ones(x_noisy.size(<span class=\"number\">0</span>)) * NOISY_WEIGHT,\n            ]\n        ).cuda()\n\n        lam = np.random.beta(<span class=\"number\">0.4</span>, <span class=\"number\">0.4</span>)\n        index = torch.randperm(x.size(<span class=\"number\">0</span>)).cuda()\n        mixed_x = lam * x + (<span class=\"number\">1</span> - lam) * x[index]\n        y_a, y_b = y, y[index]\n        w_a, w_b = weights, weights[index]\n\n        preds = model(mixed_x)\n        loss_a = nn.BCEWithLogitsLoss(reduction=<span class=\"string\">&quot;</span><span class=\"string\">none</span><span class=\"string\">&quot;</span>)(preds, y_a)\n        loss_b = nn.BCEWithLogitsLoss(reduction=<span class=\"string\">&quot;</span><span class=\"string\">none</span><span class=\"string\">&quot;</span>)(preds, y_b)\n\n        <span class=\"comment\"># Fix dimension mismatch by expanding weights</span>\n        w_a_expanded = w_a.unsqueeze(<span class=\"number\">1</span>)\n        w_b_expanded = w_b.unsqueeze(<span class=\"number\">1</span>)\n        loss = (\n            lam * (w_a_expanded * loss_a) + (<span class=\"number\">1</span> - lam) * (w_b_expanded * loss_b)\n        ).mean()\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    scheduler.step()\n\n    model.eval()\n    y_true, y_pred = [], []\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> x, y in val_loader:\n            preds = torch.sigmoid(model(x.cuda()))\n            y_true.append(y.cpu().numpy())\n            y_pred.append(preds.cpu().numpy())\n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n    lwlrap = label_ranking_average_precision_score(y_true, y_pred)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\"> Val lwlrap: </span><span class=\"string\">{</span>lwlrap<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n    <span class=\"keyword\">if</span> lwlrap &gt; best_score:\n        best_score = lwlrap\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">TestDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, path):\n        self.files = [f <span class=\"keyword\">for</span> f in os.listdir(path) <span class=\"keyword\">if</span> f.endswith(<span class=\"string\">&quot;</span><span class=\"string\">.wav</span><span class=\"string\">&quot;</span>)]\n        self.path = path\n        self.resample = Resample(orig_freq=SR, new_freq=SR)\n        self.mel = MelSpectrogram(\n            sample_rate=SR, n_mels=N_MELS, n_fft=<span class=\"number\">2048</span>, hop_length=<span class=\"number\">512</span>\n        )\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.files)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        waveform, sr = torchaudio.load(os.path.join(self.path, self.files[idx]))\n        waveform = self.resample(waveform)\n        target_len = SR * DURATION // <span class=\"number\">1000</span>\n        <span class=\"keyword\">if</span> waveform.shape[<span class=\"number\">1</span>] &lt; target_len:\n            waveform = torch.nn.functional.pad(\n                waveform, (<span class=\"number\">0</span>, target_len - waveform.shape[<span class=\"number\">1</span>])\n            )\n        <span class=\"keyword\">else</span>:\n            waveform = waveform[:, :target_len]\n        spec = torch.log(torch.clamp(self.mel(waveform), min=<span class=\"number\">1e-10</span>))\n        spec = (spec - spec.mean()) / (spec.std() + <span class=\"number\">1e-8</span>)\n        spec = spec.squeeze().permute(<span class=\"number\">1</span>, <span class=\"number\">0</span>).unsqueeze(<span class=\"number\">0</span>).repeat(<span class=\"number\">3</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>)\n        <span class=\"keyword\">return</span> spec, self.files[idx]\n\n\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">best_model.pth</span><span class=\"string\">&quot;</span>))\nmodel.eval()\ntest_ds = TestDataset(<span class=\"string\">&quot;</span><span class=\"string\">input/test</span><span class=\"string\">&quot;</span>)\ntest_loader = DataLoader(test_ds, BATCH_SIZE, num_workers=<span class=\"number\">4</span>)\n\nsubmission = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> x, fnames in test_loader:\n        preds = torch.sigmoid(model(x.cuda())).cpu().numpy()\n        <span class=\"keyword\">for</span> fn, p in zip(fnames, preds):\n            submission.append([fn] + p.tolist())\n\nsub_df = pd.DataFrame(submission, columns=[<span class=\"string\">&quot;</span><span class=\"string\">fname</span><span class=\"string\">&quot;</span>] + all_labels)\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\nsub_df.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Validation lwlrap: </span><span class=\"string\">{</span>best_score<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n"
}
{
    "title": "iwildcam-2020-fgvc7",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task iwildcam-2020-fgvc7 --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"iwildcam-2020-fgvc7\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> json\n<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span> transforms\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">import</span> timm\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim\n\n<span class=\"comment\"># Load data with error handling</span>\n<span class=\"keyword\">with</span> open(<span class=\"string\">&quot;</span><span class=\"string\">input/iwildcam2020_megadetector_results.json</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">as</span> f:\n    megadetector = json.load(f)\ndetections = {\n    img[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>]: (\n        max(img[<span class=\"string\">&quot;</span><span class=\"string\">detections</span><span class=\"string\">&quot;</span>], key=<span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;</span><span class=\"string\">conf</span><span class=\"string\">&quot;</span>]) <span class=\"keyword\">if</span> img[<span class=\"string\">&quot;</span><span class=\"string\">detections</span><span class=\"string\">&quot;</span>] <span class=\"keyword\">else</span> <span class=\"keyword\">None</span>\n    )\n    <span class=\"keyword\">for</span> img in megadetector[<span class=\"string\">&quot;</span><span class=\"string\">images</span><span class=\"string\">&quot;</span>]\n}\n\n<span class=\"keyword\">with</span> open(<span class=\"string\">&quot;</span><span class=\"string\">input/iwildcam2020_train_annotations.json</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">as</span> f:\n    train_data = json.load(f)\n\n<span class=\"comment\"># Dynamically determine number of classes</span>\nall_categories = [ann[<span class=\"string\">&quot;</span><span class=\"string\">category_id</span><span class=\"string\">&quot;</span>] <span class=\"keyword\">for</span> ann in train_data[<span class=\"string\">&quot;</span><span class=\"string\">annotations</span><span class=\"string\">&quot;</span>]]\nnum_classes = max(all_categories) + <span class=\"number\">1</span>\n\n<span class=\"comment\"># Create training dataset</span>\ntrain_images = []\n<span class=\"keyword\">for</span> img in train_data[<span class=\"string\">&quot;</span><span class=\"string\">images</span><span class=\"string\">&quot;</span>]:\n    img_id = img[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>]\n    <span class=\"keyword\">for</span> ann in train_data[<span class=\"string\">&quot;</span><span class=\"string\">annotations</span><span class=\"string\">&quot;</span>]:\n        <span class=\"keyword\">if</span> ann[<span class=\"string\">&quot;</span><span class=\"string\">image_id</span><span class=\"string\">&quot;</span>] == img_id:\n            train_images.append(\n                (os.path.join(<span class=\"string\">&quot;</span><span class=\"string\">input/train</span><span class=\"string\">&quot;</span>, img[<span class=\"string\">&quot;</span><span class=\"string\">file_name</span><span class=\"string\">&quot;</span>]), ann[<span class=\"string\">&quot;</span><span class=\"string\">category_id</span><span class=\"string\">&quot;</span>])\n            )\n            <span class=\"keyword\">break</span>\n\nfile_paths, labels = zip(*train_images)\ntrain_files, val_files, train_labels, val_labels = train_test_split(\n    file_paths, labels, test_size=<span class=\"number\">0.2</span>, random_state=<span class=\"number\">42</span>\n)\n\n\n<span class=\"comment\"># Dataset class with error handling</span>\n<span class=\"keyword\">class</span> <span class=\"class\">WildCamDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, files, labels, transform):\n        self.files = files\n        self.labels = labels\n        self.transform = transform\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.files)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        img_path = self.files[idx]\n        <span class=\"keyword\">try</span>:\n            img = Image.open(img_path).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">except</span>:\n            img = Image.new(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>, (<span class=\"number\">224</span>, <span class=\"number\">224</span>))\n\n        det = detections.get(os.path.basename(img_path).split(<span class=\"string\">&quot;</span><span class=\"string\">.</span><span class=\"string\">&quot;</span>)[<span class=\"number\">0</span>])\n        <span class=\"keyword\">if</span> det and det[<span class=\"string\">&quot;</span><span class=\"string\">conf</span><span class=\"string\">&quot;</span>] &gt; <span class=\"number\">0.5</span>:\n            w, h = img.size\n            x, y, dx, dy = det[<span class=\"string\">&quot;</span><span class=\"string\">bbox</span><span class=\"string\">&quot;</span>]\n            img = img.crop((x * w, y * h, (x + dx) * w, (y + dy) * h))\n\n        img = self.transform(img)\n        label = torch.tensor(self.labels[idx]) <span class=\"keyword\">if</span> self.labels is not <span class=\"keyword\">None</span> <span class=\"keyword\">else</span> -<span class=\"number\">1</span>\n        <span class=\"keyword\">return</span> img, label\n\n\n<span class=\"comment\"># Model setup</span>\ntransform = transforms.Compose(\n    [\n        transforms.Resize((<span class=\"number\">380</span>, <span class=\"number\">380</span>)),\n        transforms.ToTensor(),\n        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n    ]\n)\n\ntrain_ds = WildCamDataset(train_files, train_labels, transform)\nval_ds = WildCamDataset(val_files, val_labels, transform)\n\nmodel = timm.create_model(\n    <span class=\"string\">&quot;</span><span class=\"string\">efficientnet_b4</span><span class=\"string\">&quot;</span>, pretrained=<span class=\"keyword\">True</span>, num_classes=num_classes\n).cuda()\nopt = optim.AdamW(model.parameters(), lr=<span class=\"number\">3e-5</span>)\ncriterion = nn.CrossEntropyLoss()\n\n<span class=\"comment\"># DataLoaders with increased workers</span>\ntrain_loader = DataLoader(\n    train_ds, batch_size=<span class=\"number\">32</span>, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">8</span>, pin_memory=<span class=\"keyword\">True</span>\n)\nval_loader = DataLoader(val_ds, batch_size=<span class=\"number\">64</span>, num_workers=<span class=\"number\">8</span>, pin_memory=<span class=\"keyword\">True</span>)\n\n<span class=\"comment\"># Training loop</span>\n<span class=\"keyword\">for</span> epoch in range(<span class=\"number\">3</span>):\n    model.train()\n    <span class=\"keyword\">for</span> x, y in train_loader:\n        opt.zero_grad()\n        y = y.cuda()\n        loss = criterion(model(x.cuda()), y)\n        loss.backward()\n        opt.step()\n\n    model.eval()\n    correct = total = <span class=\"number\">0</span>\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> x, y in val_loader:\n            y = y.cuda()\n            preds = model(x.cuda()).argmax(<span class=\"number\">1</span>)\n            correct += (preds == y).sum().item()\n            total += len(y)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Val Acc: </span><span class=\"string\">{</span>correct/total<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Generate submission</span>\n<span class=\"keyword\">with</span> open(<span class=\"string\">&quot;</span><span class=\"string\">input/iwildcam2020_test_information.json</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">as</span> f:\n    test_data = json.load(f)\n\ntest_files = [\n    os.path.join(<span class=\"string\">&quot;</span><span class=\"string\">input/test</span><span class=\"string\">&quot;</span>, img[<span class=\"string\">&quot;</span><span class=\"string\">file_name</span><span class=\"string\">&quot;</span>]) <span class=\"keyword\">for</span> img in test_data[<span class=\"string\">&quot;</span><span class=\"string\">images</span><span class=\"string\">&quot;</span>]\n]\ntest_ds = WildCamDataset(test_files, <span class=\"keyword\">None</span>, transform)\ntest_loader = DataLoader(test_ds, batch_size=<span class=\"number\">64</span>, num_workers=<span class=\"number\">8</span>)\n\npreds = []\nmodel.eval()\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> x, _ in test_loader:\n        preds.extend(model(x.cuda()).argmax(<span class=\"number\">1</span>).cpu().numpy())\n\n<span class=\"comment\"># Fix column name to &#x27;Category&#x27; for valid submission format</span>\nsubmission = pd.DataFrame(\n    {<span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>: [img[<span class=\"string\">&quot;</span><span class=\"string\">id</span><span class=\"string\">&quot;</span>] <span class=\"keyword\">for</span> img in test_data[<span class=\"string\">&quot;</span><span class=\"string\">images</span><span class=\"string\">&quot;</span>]], <span class=\"string\">&quot;</span><span class=\"string\">Category</span><span class=\"string\">&quot;</span>: preds}\n)\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\nsubmission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Final Validation Accuracy: </span><span class=\"string\">{</span>correct/total<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n"
}
{
    "title": "alaska2-image-steganalysis",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task alaska2-image-steganalysis --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"alaska2-image-steganalysis\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> os\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn\n<span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim\n<span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, models\n<span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image\n<span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> roc_curve, auc\n\n<span class=\"comment\"># Configuration</span>\nBATCH_SIZE = <span class=\"number\">64</span>\nIMG_SIZE = <span class=\"number\">256</span>\nEPOCHS = <span class=\"number\">3</span>\nSEED = <span class=\"number\">42</span>\ntorch.manual_seed(SEED)\n\n\n<span class=\"comment\"># Data preparation</span>\n<span class=\"keyword\">def</span> <span class=\"function\">get_image_paths</span>():\n    cover_ids = [f <span class=\"keyword\">for</span> f in os.listdir(<span class=\"string\">&quot;</span><span class=\"string\">input/Cover</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">if</span> f.endswith(<span class=\"string\">&quot;</span><span class=\"string\">.jpg</span><span class=\"string\">&quot;</span>)]\n    train_ids, val_ids = train_test_split(cover_ids, test_size=<span class=\"number\">0.2</span>, random_state=SEED)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">build_split</span>(ids):\n        paths, labels = [], []\n        <span class=\"keyword\">for</span> img_id in ids:\n            paths.extend(\n                [\n                    <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">input/Cover/</span><span class=\"string\">{</span>img_id<span class=\"string\">}</span><span class=\"string\">&quot;</span>,\n                    <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">input/JMiPOD/</span><span class=\"string\">{</span>img_id<span class=\"string\">}</span><span class=\"string\">&quot;</span>,\n                    <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">input/JUNIWARD/</span><span class=\"string\">{</span>img_id<span class=\"string\">}</span><span class=\"string\">&quot;</span>,\n                    <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">input/UERD/</span><span class=\"string\">{</span>img_id<span class=\"string\">}</span><span class=\"string\">&quot;</span>,\n                ]\n            )\n            labels += [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>]\n        <span class=\"keyword\">return</span> paths, labels\n\n    train_paths, train_labels = build_split(train_ids)\n    val_paths, val_labels = build_split(val_ids)\n    <span class=\"keyword\">return</span> (train_paths, train_labels), (val_paths, val_labels)\n\n\n<span class=\"comment\"># Dataset class</span>\n<span class=\"keyword\">class</span> <span class=\"class\">StegoDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, paths, labels, transform=<span class=\"keyword\">None</span>):\n        self.paths = paths\n        self.labels = labels\n        self.transform = (\n            transforms.Compose(\n                [\n                    transforms.Resize(IMG_SIZE),\n                    transforms.RandomHorizontalFlip(),\n                    transforms.RandomVerticalFlip(),\n                    transforms.ColorJitter(<span class=\"number\">0.1</span>, <span class=\"number\">0.1</span>, <span class=\"number\">0.1</span>),\n                    transforms.ToTensor(),\n                    transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n                ]\n            )\n            <span class=\"keyword\">if</span> transform\n            <span class=\"keyword\">else</span> transforms.Compose(\n                [\n                    transforms.Resize(IMG_SIZE),\n                    transforms.ToTensor(),\n                    transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]),\n                ]\n            )\n        )\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.paths)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        img = Image.open(self.paths[idx]).convert(<span class=\"string\">&quot;</span><span class=\"string\">RGB</span><span class=\"string\">&quot;</span>)\n        <span class=\"keyword\">return</span> self.transform(img), self.labels[idx]\n\n\n<span class=\"comment\"># Model setup</span>\nmodel = models.efficientnet_b0(pretrained=<span class=\"keyword\">True</span>)\nmodel.classifier[<span class=\"number\">1</span>] = nn.Linear(model.classifier[<span class=\"number\">1</span>].in_features, <span class=\"number\">1</span>)\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\nmodel = model.to(device)\n\n<span class=\"comment\"># Data loaders</span>\n(train_paths, train_labels), (val_paths, val_labels) = get_image_paths()\ntrain_dataset = StegoDataset(train_paths, train_labels, transform=<span class=\"keyword\">True</span>)\nval_dataset = StegoDataset(val_paths, val_labels)\n\ntrain_loader = DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">4</span>, pin_memory=<span class=\"keyword\">True</span>\n)\nval_loader = DataLoader(\n    val_dataset, batch_size=BATCH_SIZE, num_workers=<span class=\"number\">4</span>, pin_memory=<span class=\"keyword\">True</span>\n)\n\n<span class=\"comment\"># Training setup</span>\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.AdamW(model.parameters(), lr=<span class=\"number\">1e-4</span>, weight_decay=<span class=\"number\">1e-5</span>)\nscheduler = optim.lr_scheduler.OneCycleLR(\n    optimizer, max_lr=<span class=\"number\">1e-3</span>, steps_per_epoch=len(train_loader), epochs=EPOCHS\n)\n\n<span class=\"comment\"># Training loop</span>\n<span class=\"keyword\">for</span> epoch in range(EPOCHS):\n    model.train()\n    <span class=\"keyword\">for</span> images, labels in train_loader:\n        images, labels = images.to(device), labels.float().to(device)\n        optimizer.zero_grad()\n        outputs = model(images).squeeze()\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n<span class=\"comment\"># Validation and metric calculation</span>\nmodel.eval()\nval_preds, val_labels = [], []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> images, labels in val_loader:\n        outputs = model(images.to(device)).squeeze().cpu().numpy()\n        val_preds.extend(outputs)\n        val_labels.extend(labels.numpy())\n\nfpr, tpr, _ = roc_curve(val_labels, val_preds)\nsplit_idx = np.argmax(tpr &gt;= <span class=\"number\">0.4</span>)\n<span class=\"keyword\">if</span> split_idx == <span class=\"number\">0</span>:\n    weighted_auc = auc(fpr, tpr) * <span class=\"number\">2</span> / <span class=\"number\">1.4</span>\n<span class=\"keyword\">else</span>:\n    auc_low = auc(fpr[:split_idx], tpr[:split_idx])\n    auc_high = auc(fpr[split_idx:], tpr[split_idx:]) - <span class=\"number\">0.4</span> * (\n        fpr[split_idx] - fpr[split_idx - <span class=\"number\">1</span>]\n    )\n    weighted_auc = (auc_low * <span class=\"number\">2</span> + auc_high) / <span class=\"number\">1.4</span>\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Weighted Validation AUC: </span><span class=\"string\">{</span>weighted_auc<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Test predictions with corrected paths</span>\ntest_files = [f <span class=\"keyword\">for</span> f in os.listdir(<span class=\"string\">&quot;</span><span class=\"string\">input/Test</span><span class=\"string\">&quot;</span>) <span class=\"keyword\">if</span> f.endswith(<span class=\"string\">&quot;</span><span class=\"string\">.jpg</span><span class=\"string\">&quot;</span>)]\ntest_paths = [os.path.join(<span class=\"string\">&quot;</span><span class=\"string\">input/Test</span><span class=\"string\">&quot;</span>, f) <span class=\"keyword\">for</span> f in test_files]\ntest_dataset = StegoDataset(test_paths, [<span class=\"number\">0</span>] * len(test_paths))\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=<span class=\"number\">4</span>)\n\nmodel.eval()\ntest_preds = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> images, _ in test_loader:\n        outputs = model(images.to(device)).squeeze().cpu().numpy()\n        test_preds.extend(outputs)\n\n<span class=\"comment\"># Create submission with proper filenames</span>\npd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">Id</span><span class=\"string\">&quot;</span>: test_files, <span class=\"string\">&quot;</span><span class=\"string\">Label</span><span class=\"string\">&quot;</span>: test_preds}).to_csv(\n    <span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>\n)\n"
}
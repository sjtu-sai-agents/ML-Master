{
    "title": "google-quest-challenge",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task google-quest-challenge --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"google-quest-challenge\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">from</span> transformers <span class=\"keyword\">import</span> AutoTokenizer, AutoModel\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> OneHotEncoder\n<span class=\"keyword\">from</span> scipy.stats <span class=\"keyword\">import</span> spearmanr\n<span class=\"keyword\">import</span> os\n\n<span class=\"comment\"># Load data</span>\ntrain_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/train.csv</span><span class=\"string\">&quot;</span>)\ntest_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">input/test.csv</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Prepare meta features</span>\nencoder = OneHotEncoder(handle_unknown=<span class=\"string\">&quot;</span><span class=\"string\">ignore</span><span class=\"string\">&quot;</span>)\nmeta_features = pd.concat(\n    [train_df[[<span class=\"string\">&quot;</span><span class=\"string\">category</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">host</span><span class=\"string\">&quot;</span>]], test_df[[<span class=\"string\">&quot;</span><span class=\"string\">category</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">host</span><span class=\"string\">&quot;</span>]]], axis=<span class=\"number\">0</span>\n)\nencoder.fit(meta_features)\ntrain_meta = encoder.transform(train_df[[<span class=\"string\">&quot;</span><span class=\"string\">category</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">host</span><span class=\"string\">&quot;</span>]]).toarray()\ntest_meta = encoder.transform(test_df[[<span class=\"string\">&quot;</span><span class=\"string\">category</span><span class=\"string\">&quot;</span>, <span class=\"string\">&quot;</span><span class=\"string\">host</span><span class=\"string\">&quot;</span>]]).toarray()\nmeta_feature_size = train_meta.shape[<span class=\"number\">1</span>]\n\n<span class=\"comment\"># Prepare separate text inputs</span>\ntrain_questions = train_df.apply(\n    <span class=\"keyword\">lambda</span> x: <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">{</span>x[<span class=\"string\">&#x27;</span><span class=\"string\">question_title</span><span class=\"string\">&#x27;</span>]<span class=\"string\">}</span><span class=\"string\"> </span><span class=\"string\">{</span>x[<span class=\"string\">&#x27;</span><span class=\"string\">question_body</span><span class=\"string\">&#x27;</span>]<span class=\"string\">}</span><span class=\"string\">&quot;</span>, axis=<span class=\"number\">1</span>\n).tolist()\ntrain_answers = train_df[<span class=\"string\">&quot;</span><span class=\"string\">answer</span><span class=\"string\">&quot;</span>].tolist()\n\ntest_questions = test_df.apply(\n    <span class=\"keyword\">lambda</span> x: <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">{</span>x[<span class=\"string\">&#x27;</span><span class=\"string\">question_title</span><span class=\"string\">&#x27;</span>]<span class=\"string\">}</span><span class=\"string\"> </span><span class=\"string\">{</span>x[<span class=\"string\">&#x27;</span><span class=\"string\">question_body</span><span class=\"string\">&#x27;</span>]<span class=\"string\">}</span><span class=\"string\">&quot;</span>, axis=<span class=\"number\">1</span>\n).tolist()\ntest_answers = test_df[<span class=\"string\">&quot;</span><span class=\"string\">answer</span><span class=\"string\">&quot;</span>].tolist()\n\n<span class=\"comment\"># Extract targets</span>\ntarget_cols = train_df.columns[<span class=\"number\">11</span>:<span class=\"number\">41</span>].tolist()\ntargets = train_df[target_cols].values\n\n<span class=\"comment\"># Train-validation split</span>\n(\n    train_questions_split,\n    val_questions_split,\n    train_answers_split,\n    val_answers_split,\n    train_meta_split,\n    val_meta_split,\n    train_targets,\n    val_targets,\n) = train_test_split(\n    train_questions, train_answers, train_meta, targets, test_size=<span class=\"number\">0.2</span>, random_state=<span class=\"number\">42</span>\n)\n\n<span class=\"comment\"># Tokenization setup</span>\ntokenizer = AutoTokenizer.from_pretrained(<span class=\"string\">&quot;</span><span class=\"string\">microsoft/deberta-v3-base</span><span class=\"string\">&quot;</span>)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">QADataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, questions, answers, meta_features, targets=<span class=\"keyword\">None</span>):\n        self.questions = questions\n        self.answers = answers\n        self.meta_features = meta_features\n        self.targets = targets\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.questions)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        question_inputs = tokenizer(\n            self.questions[idx],\n            padding=<span class=\"string\">&quot;</span><span class=\"string\">max_length</span><span class=\"string\">&quot;</span>,\n            truncation=<span class=\"keyword\">True</span>,\n            max_length=<span class=\"number\">256</span>,\n            return_tensors=<span class=\"string\">&quot;</span><span class=\"string\">pt</span><span class=\"string\">&quot;</span>,\n        )\n        answer_inputs = tokenizer(\n            self.answers[idx],\n            padding=<span class=\"string\">&quot;</span><span class=\"string\">max_length</span><span class=\"string\">&quot;</span>,\n            truncation=<span class=\"keyword\">True</span>,\n            max_length=<span class=\"number\">256</span>,\n            return_tensors=<span class=\"string\">&quot;</span><span class=\"string\">pt</span><span class=\"string\">&quot;</span>,\n        )\n        inputs = {\n            <span class=\"string\">&quot;</span><span class=\"string\">question_input_ids</span><span class=\"string\">&quot;</span>: question_inputs[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>].squeeze(<span class=\"number\">0</span>),\n            <span class=\"string\">&quot;</span><span class=\"string\">question_attention_mask</span><span class=\"string\">&quot;</span>: question_inputs[<span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>].squeeze(<span class=\"number\">0</span>),\n            <span class=\"string\">&quot;</span><span class=\"string\">answer_input_ids</span><span class=\"string\">&quot;</span>: answer_inputs[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>].squeeze(<span class=\"number\">0</span>),\n            <span class=\"string\">&quot;</span><span class=\"string\">answer_attention_mask</span><span class=\"string\">&quot;</span>: answer_inputs[<span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>].squeeze(<span class=\"number\">0</span>),\n        }\n        meta = torch.FloatTensor(self.meta_features[idx])\n        <span class=\"keyword\">if</span> self.targets is not <span class=\"keyword\">None</span>:\n            <span class=\"keyword\">return</span> inputs, meta, torch.FloatTensor(self.targets[idx])\n        <span class=\"keyword\">return</span> inputs, meta\n\n\n<span class=\"comment\"># Create dataloaders</span>\ntrain_dataset = QADataset(\n    train_questions_split, train_answers_split, train_meta_split, train_targets\n)\nval_dataset = QADataset(\n    val_questions_split, val_answers_split, val_meta_split, val_targets\n)\ntest_dataset = QADataset(test_questions, test_answers, test_meta)\n\ntrain_loader = DataLoader(train_dataset, batch_size=<span class=\"number\">12</span>, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">8</span>)\nval_loader = DataLoader(val_dataset, batch_size=<span class=\"number\">12</span>, num_workers=<span class=\"number\">8</span>)\ntest_loader = DataLoader(test_dataset, batch_size=<span class=\"number\">12</span>, num_workers=<span class=\"number\">8</span>)\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">DualEncoderRegressor</span>(torch.nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, meta_feature_size):\n        super().<span class=\"function\">__init__</span>()\n        self.question_encoder = AutoModel.from_pretrained(<span class=\"string\">&quot;</span><span class=\"string\">microsoft/deberta-v3-base</span><span class=\"string\">&quot;</span>)\n        self.answer_encoder = AutoModel.from_pretrained(<span class=\"string\">&quot;</span><span class=\"string\">microsoft/deberta-v3-base</span><span class=\"string\">&quot;</span>)\n        self.meta_proj = torch.nn.Linear(meta_feature_size, <span class=\"number\">768</span>)\n        self.dropout = torch.nn.Dropout(<span class=\"number\">0.3</span>)\n        self.head = torch.nn.Sequential(\n            torch.nn.Linear(<span class=\"number\">768</span> * <span class=\"number\">2</span> + <span class=\"number\">768</span>, <span class=\"number\">1536</span>),\n            torch.nn.GELU(),\n            torch.nn.Linear(<span class=\"number\">1536</span>, <span class=\"number\">30</span>),\n        )\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, q_input_ids, q_attn_mask, a_input_ids, a_attn_mask, meta):\n        q_outputs = self.question_encoder(\n            input_ids=q_input_ids, attention_mask=q_attn_mask\n        )\n        a_outputs = self.answer_encoder(\n            input_ids=a_input_ids, attention_mask=a_attn_mask\n        )\n\n        q_pooled = q_outputs.last_hidden_state[:, <span class=\"number\">0</span>, :]\n        a_pooled = a_outputs.last_hidden_state[:, <span class=\"number\">0</span>, :]\n        meta_proj = self.meta_proj(meta)\n\n        combined = torch.cat([q_pooled, a_pooled, meta_proj], dim=<span class=\"number\">1</span>)\n        <span class=\"keyword\">return</span> self.head(self.dropout(combined))\n\n\ndevice = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\nmodel = DualEncoderRegressor(meta_feature_size).to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=<span class=\"number\">2e-5</span>, weight_decay=<span class=\"number\">0.01</span>)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=<span class=\"number\">5</span>)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">pearson_loss</span>(preds, targets):\n    preds_centered = preds - preds.mean(dim=<span class=\"number\">0</span>, keepdim=<span class=\"keyword\">True</span>)\n    targets_centered = targets - targets.mean(dim=<span class=\"number\">0</span>, keepdim=<span class=\"keyword\">True</span>)\n    covariance = (preds_centered * targets_centered).mean(dim=<span class=\"number\">0</span>)\n    pred_std = torch.sqrt((preds_centered**<span class=\"number\">2</span>).mean(dim=<span class=\"number\">0</span>) + <span class=\"number\">1e-6</span>)\n    target_std = torch.sqrt((targets_centered**<span class=\"number\">2</span>).mean(dim=<span class=\"number\">0</span>) + <span class=\"number\">1e-6</span>)\n    pearson = covariance / (pred_std * target_std)\n    <span class=\"keyword\">return</span> -pearson.mean()\n\n\nbest_score = -<span class=\"number\">1</span>\npatience = <span class=\"number\">2</span>\ncurrent_patience = <span class=\"number\">0</span>\n\n<span class=\"keyword\">for</span> epoch in range(<span class=\"number\">15</span>):\n    model.train()\n    total_loss = <span class=\"number\">0</span>\n    <span class=\"keyword\">for</span> batch in train_loader:\n        inputs, meta, targets = batch\n        q_ids = inputs[<span class=\"string\">&quot;</span><span class=\"string\">question_input_ids</span><span class=\"string\">&quot;</span>].to(device)\n        q_mask = inputs[<span class=\"string\">&quot;</span><span class=\"string\">question_attention_mask</span><span class=\"string\">&quot;</span>].to(device)\n        a_ids = inputs[<span class=\"string\">&quot;</span><span class=\"string\">answer_input_ids</span><span class=\"string\">&quot;</span>].to(device)\n        a_mask = inputs[<span class=\"string\">&quot;</span><span class=\"string\">answer_attention_mask</span><span class=\"string\">&quot;</span>].to(device)\n        meta, targets = meta.to(device), targets.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(q_ids, q_mask, a_ids, a_mask, meta)\n        preds = torch.sigmoid(outputs)\n\n        loss = pearson_loss(preds, targets) + <span class=\"number\">0.4</span> * torch.nn.functional.mse_loss(\n            preds, targets\n        )\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), <span class=\"number\">1.0</span>)\n        optimizer.step()\n        total_loss += loss.item()\n\n    scheduler.step()\n\n    <span class=\"comment\"># Validation</span>\n    model.eval()\n    preds, truths = [], []\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> batch in val_loader:\n            inputs, meta, targets = batch\n            q_ids = inputs[<span class=\"string\">&quot;</span><span class=\"string\">question_input_ids</span><span class=\"string\">&quot;</span>].to(device)\n            q_mask = inputs[<span class=\"string\">&quot;</span><span class=\"string\">question_attention_mask</span><span class=\"string\">&quot;</span>].to(device)\n            a_ids = inputs[<span class=\"string\">&quot;</span><span class=\"string\">answer_input_ids</span><span class=\"string\">&quot;</span>].to(device)\n            a_mask = inputs[<span class=\"string\">&quot;</span><span class=\"string\">answer_attention_mask</span><span class=\"string\">&quot;</span>].to(device)\n            meta = meta.to(device)\n\n            outputs = model(q_ids, q_mask, a_ids, a_mask, meta)\n            preds.append(torch.sigmoid(outputs).cpu())\n            truths.append(targets.cpu())\n\n    preds = torch.cat(preds).numpy()\n    truths = torch.cat(truths).numpy()\n    scores = [spearmanr(truths[:, i], preds[:, i]).correlation <span class=\"keyword\">for</span> i in range(<span class=\"number\">30</span>)]\n    mean_score = np.nanmean(scores)\n    print(\n        <span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\">: Loss=</span><span class=\"string\">{</span>total_loss/len(train_loader)<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">, Val Score=</span><span class=\"string\">{</span>mean_score<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>\n    )\n\n    <span class=\"keyword\">if</span> mean_score &gt; best_score:\n        best_score = mean_score\n        current_patience = <span class=\"number\">0</span>\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">best_model.pt</span><span class=\"string\">&quot;</span>)\n    <span class=\"keyword\">else</span>:\n        current_patience += <span class=\"number\">1</span>\n        <span class=\"keyword\">if</span> current_patience &gt;= patience:\n            print(<span class=\"string\">&quot;</span><span class=\"string\">Early stopping</span><span class=\"string\">&quot;</span>)\n            <span class=\"keyword\">break</span>\n\n<span class=\"comment\"># Generate submission</span>\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">best_model.pt</span><span class=\"string\">&quot;</span>, map_location=device), strict=<span class=\"keyword\">False</span>)\nmodel.eval()\ntest_preds = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> batch in test_loader:\n        inputs, meta = batch\n        q_ids = inputs[<span class=\"string\">&quot;</span><span class=\"string\">question_input_ids</span><span class=\"string\">&quot;</span>].to(device)\n        q_mask = inputs[<span class=\"string\">&quot;</span><span class=\"string\">question_attention_mask</span><span class=\"string\">&quot;</span>].to(device)\n        a_ids = inputs[<span class=\"string\">&quot;</span><span class=\"string\">answer_input_ids</span><span class=\"string\">&quot;</span>].to(device)\n        a_mask = inputs[<span class=\"string\">&quot;</span><span class=\"string\">answer_attention_mask</span><span class=\"string\">&quot;</span>].to(device)\n        meta = meta.to(device)\n\n        outputs = model(q_ids, q_mask, a_ids, a_mask, meta)\n        test_preds.append(torch.sigmoid(outputs).cpu().numpy())\n\nsubmission = pd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">qa_id</span><span class=\"string\">&quot;</span>: test_df.qa_id})\nsubmission = pd.concat(\n    [submission, pd.DataFrame(np.concatenate(test_preds), columns=target_cols)], axis=<span class=\"number\">1</span>\n)\nos.makedirs(<span class=\"string\">&quot;</span><span class=\"string\">submission</span><span class=\"string\">&quot;</span>, exist_ok=<span class=\"keyword\">True</span>)\nsubmission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\n\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Final Validation Score: </span><span class=\"string\">{</span>best_score<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n"
}
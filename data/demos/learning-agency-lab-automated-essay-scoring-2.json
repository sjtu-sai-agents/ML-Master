{
    "title": "learning-agency-lab-automated-essay-scoring-2",
    "steps": [
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> python ml_master.py --task learning-agency-lab-automated-essay-scoring-2 --time-limit 12h",
            "delay": 200
        },
        {
            "text": "<span class='info'>[INFO]</span>: Starting run \"learning-agency-lab-automated-essay-scoring-2\"",
            "delay": 200
        },
        {
            "text": "<span class='prompt'>ml-master@ai4ai:~$</span> ",
            "delay": 200
        }
    ],
    "code": "<span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd\n<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np\n<span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split\n<span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> cohen_kappa_score\n<span class=\"keyword\">import</span> torch\n<span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader\n<span class=\"keyword\">from</span> transformers <span class=\"keyword\">import</span> LongformerTokenizer, LongformerModel, AdamW\n<span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn\n<span class=\"keyword\">from</span> torch.cuda.amp <span class=\"keyword\">import</span> autocast, GradScaler\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">EssayDataset</span>(Dataset):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self, texts, scores, tokenizer, max_len):\n        self.texts = texts\n        self.scores = scores\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__len__</span>(self):\n        <span class=\"keyword\">return</span> len(self.texts)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">__getitem__</span>(self, idx):\n        text = str(self.texts[idx])\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=<span class=\"keyword\">True</span>,\n            max_length=self.max_len,\n            padding=<span class=\"string\">&quot;</span><span class=\"string\">max_length</span><span class=\"string\">&quot;</span>,\n            truncation=<span class=\"keyword\">True</span>,\n            return_attention_mask=<span class=\"keyword\">True</span>,\n            return_tensors=<span class=\"string\">&quot;</span><span class=\"string\">pt</span><span class=\"string\">&quot;</span>,\n        )\n        <span class=\"keyword\">return</span> {\n            <span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>: encoding[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>].flatten(),\n            <span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>: encoding[<span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>].flatten(),\n            <span class=\"string\">&quot;</span><span class=\"string\">score</span><span class=\"string\">&quot;</span>: torch.tensor(self.scores[idx], dtype=torch.float),\n        }\n\n\n<span class=\"keyword\">class</span> <span class=\"class\">EssayScorer</span>(nn.Module):\n    <span class=\"keyword\">def</span> <span class=\"function\">__init__</span>(self):\n        super(EssayScorer, self).<span class=\"function\">__init__</span>()\n        self.longformer = LongformerModel.from_pretrained(\n            <span class=\"string\">&quot;</span><span class=\"string\">allenai/longformer-base-4096</span><span class=\"string\">&quot;</span>\n        )\n        self.dropout = nn.Dropout(<span class=\"number\">0.1</span>)\n        self.regressor = nn.Linear(self.longformer.config.hidden_size, <span class=\"number\">1</span>)\n\n    <span class=\"keyword\">def</span> <span class=\"function\">forward</span>(self, input_ids, attention_mask):\n        outputs = self.longformer(input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, <span class=\"number\">0</span>, :]\n        output = self.dropout(pooled_output)\n        <span class=\"keyword\">return</span> self.regressor(output).squeeze(-<span class=\"number\">1</span>)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">quadratic_weighted_kappa</span>(y_true, y_pred):\n    <span class=\"keyword\">return</span> cohen_kappa_score(y_true, y_pred, weights=<span class=\"string\">&quot;</span><span class=\"string\">quadratic</span><span class=\"string\">&quot;</span>)\n\n\n<span class=\"keyword\">def</span> <span class=\"function\">validate</span>(model, dataloader, device):\n    model.eval()\n    predictions = []\n    true_scores = []\n    <span class=\"keyword\">with</span> torch.no_grad():\n        <span class=\"keyword\">for</span> batch in dataloader:\n            input_ids = batch[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>].to(device)\n            attention_mask = batch[<span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>].to(device)\n            scores = batch[<span class=\"string\">&quot;</span><span class=\"string\">score</span><span class=\"string\">&quot;</span>].cpu().numpy()\n\n            outputs = model(input_ids, attention_mask)\n            preds = torch.clamp(outputs.round(), <span class=\"number\">1</span>, <span class=\"number\">6</span>).cpu().numpy().astype(int)\n\n            predictions.extend(preds)\n            true_scores.extend(scores.astype(int))\n    <span class=\"keyword\">return</span> quadratic_weighted_kappa(true_scores, predictions)\n\n\n<span class=\"comment\"># Configuration</span>\nMAX_LEN = <span class=\"number\">4096</span>\nBATCH_SIZE = <span class=\"number\">4</span>\nEPOCHS = <span class=\"number\">5</span>\nLEARNING_RATE = <span class=\"number\">2e-5</span>\nDEVICE = torch.device(<span class=\"string\">&quot;</span><span class=\"string\">cuda</span><span class=\"string\">&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;</span><span class=\"string\">cpu</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Data preparation</span>\ntrain_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/train.csv</span><span class=\"string\">&quot;</span>)\ntest_df = pd.read_csv(<span class=\"string\">&quot;</span><span class=\"string\">./input/test.csv</span><span class=\"string\">&quot;</span>)\ntrain_df, val_df = train_test_split(\n    train_df, test_size=<span class=\"number\">0.2</span>, stratify=train_df[<span class=\"string\">&quot;</span><span class=\"string\">score</span><span class=\"string\">&quot;</span>], random_state=<span class=\"number\">42</span>\n)\n\ntokenizer = LongformerTokenizer.from_pretrained(<span class=\"string\">&quot;</span><span class=\"string\">allenai/longformer-base-4096</span><span class=\"string\">&quot;</span>)\n\ntrain_dataset = EssayDataset(\n    train_df[<span class=\"string\">&quot;</span><span class=\"string\">full_text</span><span class=\"string\">&quot;</span>].values, train_df[<span class=\"string\">&quot;</span><span class=\"string\">score</span><span class=\"string\">&quot;</span>].values, tokenizer, MAX_LEN\n)\nval_dataset = EssayDataset(\n    val_df[<span class=\"string\">&quot;</span><span class=\"string\">full_text</span><span class=\"string\">&quot;</span>].values, val_df[<span class=\"string\">&quot;</span><span class=\"string\">score</span><span class=\"string\">&quot;</span>].values, tokenizer, MAX_LEN\n)\ntest_dataset = EssayDataset(\n    test_df[<span class=\"string\">&quot;</span><span class=\"string\">full_text</span><span class=\"string\">&quot;</span>].values, np.zeros(len(test_df)), tokenizer, MAX_LEN\n)\n\ntrain_loader = DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">4</span>\n)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=<span class=\"number\">4</span>)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=<span class=\"number\">4</span>)\n\n<span class=\"comment\"># Model setup</span>\nmodel = EssayScorer().to(DEVICE)\noptimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\nscaler = GradScaler()\nbest_kappa = <span class=\"number\">0</span>\n\n<span class=\"comment\"># Training loop</span>\n<span class=\"keyword\">for</span> epoch in range(EPOCHS):\n    model.train()\n    <span class=\"keyword\">for</span> batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>].to(DEVICE)\n        attention_mask = batch[<span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>].to(DEVICE)\n        scores = batch[<span class=\"string\">&quot;</span><span class=\"string\">score</span><span class=\"string\">&quot;</span>].to(DEVICE)\n\n        <span class=\"keyword\">with</span> autocast():\n            outputs = model(input_ids, attention_mask)\n            loss = nn.MSELoss()(outputs, scores)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n    val_kappa = validate(model, val_loader, DEVICE)\n    print(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Epoch </span><span class=\"string\">{</span>epoch+<span class=\"number\">1</span><span class=\"string\">}</span><span class=\"string\"> - Validation Kappa: </span><span class=\"string\">{</span>val_kappa<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n    <span class=\"keyword\">if</span> val_kappa &gt; best_kappa:\n        best_kappa = val_kappa\n        torch.save(model.state_dict(), <span class=\"string\">&quot;</span><span class=\"string\">./working/best_model.pt</span><span class=\"string\">&quot;</span>)\n\n<span class=\"comment\"># Generate predictions</span>\nmodel.load_state_dict(torch.load(<span class=\"string\">&quot;</span><span class=\"string\">./working/best_model.pt</span><span class=\"string\">&quot;</span>))\nmodel.eval()\npredictions = []\n<span class=\"keyword\">with</span> torch.no_grad():\n    <span class=\"keyword\">for</span> batch in test_loader:\n        input_ids = batch[<span class=\"string\">&quot;</span><span class=\"string\">input_ids</span><span class=\"string\">&quot;</span>].to(DEVICE)\n        attention_mask = batch[<span class=\"string\">&quot;</span><span class=\"string\">attention_mask</span><span class=\"string\">&quot;</span>].to(DEVICE)\n        outputs = model(input_ids, attention_mask)\n        batch_preds = torch.clamp(outputs.round(), <span class=\"number\">1</span>, <span class=\"number\">6</span>).cpu().numpy().astype(int)\n        predictions.extend(batch_preds)\n\nsubmission = pd.DataFrame({<span class=\"string\">&quot;</span><span class=\"string\">essay_id</span><span class=\"string\">&quot;</span>: test_df[<span class=\"string\">&quot;</span><span class=\"string\">essay_id</span><span class=\"string\">&quot;</span>], <span class=\"string\">&quot;</span><span class=\"string\">score</span><span class=\"string\">&quot;</span>: predictions})\nsubmission.to_csv(<span class=\"string\">&quot;</span><span class=\"string\">./submission/submission.csv</span><span class=\"string\">&quot;</span>, index=<span class=\"keyword\">False</span>)\nprint(<span class=\"string\">f</span><span class=\"string\">&quot;</span><span class=\"string\">Best Validation Kappa: </span><span class=\"string\">{</span>best_kappa<span class=\"string\">:</span><span class=\"string\">.4f</span><span class=\"string\">}</span><span class=\"string\">&quot;</span>)\n"
}